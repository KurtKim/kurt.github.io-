<!doctype html><html lang=ko-kr dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='A Robustly Optimized BERT Pretraining Approach'><title>RoBERTa</title>
<link rel=canonical href=https://kurtkim.github.io/p/roberta/><link rel=stylesheet href=/scss/style.min.ff300df33b80e2ac49809c825614392ed1c7b27591d65d3c4043602cd162e25f.css><meta property='og:title' content='RoBERTa'><meta property='og:description' content='A Robustly Optimized BERT Pretraining Approach'><meta property='og:url' content='https://kurtkim.github.io/p/roberta/'><meta property='og:site_name' content="K2H'log"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='NLP'><meta property='article:published_time' content='2023-12-12T00:00:00+00:00'><meta property='article:modified_time' content='2023-12-12T00:00:00+00:00'><meta name=twitter:title content="RoBERTa"><meta name=twitter:description content="A Robustly Optimized BERT Pretraining Approach"><link rel="shortcut icon" href=favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="메뉴 여닫기">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/k2h_hud72815e7fea33e555ee8ed75e79e7624_40760_300x0_resize_q75_box.jpg width=300 height=306 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>K2H'log</a></h1><h2 class=site-description>넓고 얕은 지식을 위한</h2></div></header><ol class=social-menu><li><a href=https://github.com/kurtkim/ target=_blank title=1 rel=me><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li><a href=https://www.linkedin.com/in/kyeong-hun-kim-430ba075/ target=_blank title=2 rel=me><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></li><li><a href=https://www.instagram.com/kurt_k2h/ target=_blank title=3 rel=me><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="2" y="2" width="20" height="20" rx="5" ry="5"/><path d="M16 11.37A4 4 0 1112.63 8 4 4 0 0116 11.37z"/><line x1="17.5" y1="6.5" x2="17.5" y2="6.5"/></svg></a></li><li><a href=https://brunch.co.kr/@bigevlt target=_blank title=4 rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-pencil-minus" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 20h4L18.5 9.5a2.828 2.828.0 10-4-4L4 16v4"/><path d="M13.5 6.5l4 4"/><path d="M16 19h6"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://kurtkim.github.io/ selected></option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>다크 모드</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">목차</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#background>Background</a><ol><li><a href=#setup>Setup</a></li><li><a href=#architecture>Architecture</a><ol><li><a href=#masked-language-model-mlm>Masked Language Model (MLM)</a></li><li><a href=#next-sentence-prediction-nsp>Next Sentence Prediction (NSP)</a></li></ol></li><li><a href=#optimization>Optimization</a></li><li><a href=#data>Data</a></li></ol></li><li><a href=#experimental-setup>Experimental Setup</a><ol><li><a href=#implementation>Implementation</a></li><li><a href=#data-1>Data</a></li><li><a href=#evaluation>Evaluation</a><ol><li><a href=#glue>GLUE</a></li><li><a href=#squad>SQuAD</a></li><li><a href=#race>RACE</a></li></ol></li></ol></li><li><a href=#training-procedure-analysis>Training Procedure Analysis</a><ol><li><a href=#static-vs-dynamic-masking>Static vs. Dynamic Masking</a></li><li><a href=#model-input-format-and-next-sentence-prediction>Model Input Format and Next Sentence Prediction</a></li><li><a href=#training-with-large-batches>Training with large batches</a></li><li><a href=#text-encoding>Text Encoding</a></li></ol></li><li><a href=#roberta>RoBERTa</a><ol><li><a href=#glue-results>GLUE Results</a></li><li><a href=#squad-results>SQuAD Results</a></li><li><a href=#race-results>RACE Results</a></li></ol></li><li><a href=#related-work>Related Work</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#reference>Reference</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/paper-review/>Paper Review</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/roberta/>RoBERTa</a></h2><h3 class=article-subtitle>A Robustly Optimized BERT Pretraining Approach</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Dec 12, 2023</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>9 분 정도</time></div></footer></div></header><section class=article-content><h2 id=abstract>Abstract</h2><p>언어 모델의 사전 학습은 큰 성능 향상을 가져왔지만, 다른 접근법 간의 비교는 어렵다. 학습 과정은 비용이 많이 들며, hyperparameter 선택이 결과에 큰 영향을 미친다. 이 연구는 BERT 학습을 재현하고, 핵심 hyperparameter와 학습 데이터 크기의 영향을 측정하는데, 이를 통해 BERT가 undertrained 상태였으며, 그 이후의 모든 모델의 성능을 맞추거나 능가할 수 있다는 것을 발견했다. RoBERTa는 여러 테스트에서 state-of-the-art를 달성하였고, 이는 이전에 간과된 설계의 중요성을 보여준다.</p><hr><h2 id=introduction>Introduction</h2><p>이 연구는 BERT의 사전 학습 방법을 재현하고, 그 효과를 평가했다. 연구 결과 BERT는 상당히 학습이 부족했으며, 이를 개선하기 위한 새로운 학습 방법 RoBERTa를 제안했다. RoBERTa는 더 큰 배치와 더 많은 데이터에서 모델을 더 오래 학습시키고, 다음 문장 예측 목표를 제거하며, 더 긴 시퀀스에서 학습시키고, 학습 데이터에 적용되는 마스킹 패턴을 동적으로 변경한다. 이 개선된 학습 방법은 GLUE와 SQuAD에서 BERT의 성능을 뛰어넘었다. 또한, 새로운 데이터셋인 CCN EWS를 사용하고, 사전 학습에 더 많은 데이터를 사용하면 성능이 더욱 향상된다는 것을 확인하였다.</p><hr><h2 id=background>Background</h2><p>BERT의 사전 학습 방식과 실험적으로 검토할 학습 선택 사항에 대해 간단히 소개한다.</p><h3 id=setup>Setup</h3><p>BERT는 두 개의 토큰 시퀀스인 $x_1, &mldr;, x_N$과 $y_1, &mldr;, y_M$을 연결하여 입력으로 사용한다. 이 두 세그먼트는 특별한 토큰들로 구분되어 BERT에 하나의 입력 시퀀스로 제공된다:</p><p>$$ [CLS], x_1, &mldr;, x_N, [SEP], y_1, &mldr;, y_M, [EOS]. $$</p><p>$M$과 $N$은 $M + N &lt; T$라는 제약하에 있으며, 여기서 $T$는 최대 시퀀스 길이를 제어하는 parameter이다. 모델은 대량의 레이블이 없는 텍스트 말뭉치로 사전 학습된 후, 최종 목표 레이블 데이터를 사용하여 미세 조정된다.</p><h3 id=architecture>Architecture</h3><p>사전 학습 동안, BERT는 masked language modeling과 next sentence prediction 두 가지 작업을 사용한다.</p><h4 id=masked-language-model-mlm>Masked Language Model (MLM)</h4><p>입력 시퀀스의 토큰 중 무작위로 선택된 일부가 특별한 토큰 [MASK]로 대체된다. masked language modeling 목표는 마스크된 토큰을 예측하는 것이다. 입력 토큰의 15%가 선택되어 대체되며, 이 중 80%는 [MASK]로, 10%는 그대로 두고, 나머지 10%는 임의의 어휘 토큰으로 대체된다. 이 과정은 학습 기간 동안 한 번만 수행되지만, 실제로는 데이터가 복제되어 모든 학습 문장에 동일한 마스크가 적용되지 않는다.</p><h4 id=next-sentence-prediction-nsp>Next Sentence Prediction (NSP)</h4><p>NSP(Next Sentence Prediction)는 원문에서 두 세그먼트가 이어지는지 예측하는 방법이다. 긍정 예시는 연속된 문장을, 부정 예시는 다른 문서의 세그먼트를 사용해 만든다. NSP 목표는 문장 쌍 간의 관계를 파악하는 자연어 추론 등의 downstream task에서 성능을 향상시키기 위해 설계되었다.</p><h3 id=optimization>Optimization</h3><p>BERT는 Adam 최적화를 사용하며, learning rate는 처음 10,000 step 동안 서서히 높아진 후 선형적으로 감소한다. 모든 레이어와 attention weights에 대해 0.1의 dropout을 사용하고, GELU 활성화 함수를 활용한다. 모델은 1,000,000 업데이트 동안 사전 학습되며, 최대 512 토큰의 256 시퀀스를 포함하는 미니배치를 사용한다.</p><h3 id=data>Data</h3><p>BERT는 총 16GB의 압축되지 않은 텍스트인 BOOK CORPUS와 영어 WIKIPEDIA 조합으로 학습된다.</p><hr><h2 id=experimental-setup>Experimental Setup</h2><p>BERT의 복제 연구에 대한 실험적 설정을 설명한다.</p><h3 id=implementation>Implementation</h3><p>FAIRSEQ에서 BERT를 재구현하고, 대부분의 원래 BERT 최적화 hyperparameter를 따랐다. 하지만 peak learning rate과 warmup step 수는 각 설정에 따라 별도로 조정했다. 또한, Adam epsilon 항에 따라 학습이 매우 민감하며, 이를 조정하여 성능을 개선했다.</p><h3 id=data-1>Data</h3><p>BERT 스타일의 사전 학습은 대량의 텍스트에 크게 의존하며, 데이터 크기를 늘릴수록 최종 작업 성능이 향상될 수 있다. 이 연구에서는, 가능한 많은 데이터를 수집하여 실험을 진행하고, 각 비교에 적절한 데이터의 전체적인 품질과 양을 맞출 수 있도록 했다. 압축되지 않은 텍스트로 총 160GB를 넘는 다양한 크기와 도메인의 5개의 영어 말뭉치를 사용하였다:</p><ul><li>BOOK CORPUS와 영어 WIKIPEDIA. BERT를 학습시키는데 사용된 원래 데이터이다. (16GB).</li><li>CC-N EWS, CommonCrawl News dataset의 영어 부분에서 수집한 것. 이 데이터는 2016년 9월부터 2019년 2월까지 크롤링된 6300만 개의 영어 뉴스 기사를 포함하고 있다. (필터링 후 76GB).</li><li>OPEN WEB TEXT, WebText 코퍼스의 오픈 소스 재현, 텍스트는 Reddit에서 최소 세 번 이상의 추천을 받은 URL에서 추출된 웹 콘텐츠이다. (38GB)</li><li>STORIES, Winograd 스키마의 스토리 같은 스타일을 맞추기 위해 필터링된 CommonCrawl 데이터의 부분 집합을 포함하고 있다. (31GB).</li></ul><h3 id=evaluation>Evaluation</h3><p>다음 세 가지 benchmark를 사용하여 사전 학습된 모델을 평가한다.</p><h4 id=glue>GLUE</h4><p>GLUE 벤치마크는 자연어 이해 시스템을 평가하기 위한 9개의 dataset 모음이다. 이는 단문 분류 또는 문장 쌍 분류 작업으로 구성되며, 참가자들은 제출 서버와 리더보드를 통해 자신의 시스템을 평가하고 비교할 수 있다.</p><p>학습 데이터에서 사전 학습된 모델을 미세 조정하여 개발 세트에서 결과를 보고하였으며, 이 절차는 원래의 BERT 논문을 따른다.</p><h4 id=squad>SQuAD</h4><p>Stanford Question Answering Dataset(SQuAD)는 문맥과 질문을 제공하며, 작업은 문맥에서 관련 부분을 추출하여 질문에 답한다. SQuAD는 V1.1과 V2.0 두 버전이 있으며, V2.0 버전은 제공된 문맥에서 답하지 않는 질문도 포함하여 작업이 더 도전적이다.</p><p>SQuAD V1.1에서는 BERT와 같은 방법으로 범위를 예측하며, SQuAD V2.0에서는 추가적인 이진 분류기를 사용하여 질문이 답변 가능한지를 예측한다. 이는 분류와 span loss terms를 합산하여 훈련되며, 평가 시 답변 가능으로 분류된 쌍에만 범위 인덱스를 예측한다.</p><h4 id=race>RACE</h4><p>ReAding Comprehension from Examinations(RACE)은 28,000개 이상의 지문과 100,000개 가까운 질문을 포함한 대규모 독해 dataset이다. 이 dataset은 중국의 중고등학생들을 대상으로 한 영어 시험에서 수집되었다. RACE에서는 각 지문에 대해 여러 질문을 풀고, 네 가지 선택지 중 정답을 고르는 작업을 수행한ㄴ다. RACE는 다른 dataset에 비해 긴 문맥을 가지고 있으며, 대부분의 질문에서 추론 능력을 요구한다.</p><hr><h2 id=training-procedure-analysis>Training Procedure Analysis</h2><p>BERT 모델을 성공적으로 사전 학습하기 위해 중요한 선택 사항들을 탐색하고 정량화한다. $BERT_{BASE}$와 동일한 구성 (L = 12, H = 768, A = 12, 110M params)으로 BERT 모델을 학습한다.</p><h3 id=static-vs-dynamic-masking>Static vs. Dynamic Masking</h3><p>BERT는 무작위로 토큰을 마스킹하고 예측한다. 각 학습 인스턴스에서 동일한 마스크를 계속 사용하는 것을 피하기 위해, 학습 데이터를 10번 복제하여 각 시퀀스가 40회의 학습 동안 다양하게 마스킹될 수 있게 했다. 이를 모델에 시퀀스를 제공할 때마다 새로운 마스킹 패턴을 생성하는 동적 마스킹과 비교하였다.</p><p><img src=/p/roberta/images/table1.png width=590 height=260 srcset="/p/roberta/images/table1_huefe28a59b1c5340118d249d8656f3095_34810_480x0_resize_box_3.png 480w, /p/roberta/images/table1_huefe28a59b1c5340118d249d8656f3095_34810_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=226 data-flex-basis=544px></p><p>재구현에서 정적 마스킹은 원래 BERT와 유사한 성능을 보였고, 동적 마스킹은 정적 마스킹과 비슷하거나 약간 더 좋은 성능을 보여주었다. 이 결과와 동적 마스킹의 효율성을 고려하여, 이 후 실험에서는 동적 마스킹을 사용하였다.</p><h3 id=model-input-format-and-next-sentence-prediction>Model Input Format and Next Sentence Prediction</h3><p>원래 BERT 사전 학습에서는 모델이 두 개의 연결된 문서 세그먼트를 관찰하며, 이들은 같은 문서에서 연속적으로 추출되거나 다른 문서에서 추출된다. 모델은 Next Sentence Prediction(NSP) loss를 통해 관찰한 문서 세그먼트가 같은 문서에서 왔는지, 다른 문서에서 왔는지 예측하도록 훈련된다.</p><p>NSP loss의 중요성은 원래 BERT 모델 훈련에서 중요한 요소로 가정되었으며, NSP를 제거하면 성능이 저하되는 것이 관찰되었다. 그러나 최근의 일부 연구에서는 NSP loss의 필요성에 의문을 제기하였다. 이러한 차이점을 더 잘 이해하기 위해, 다양한 훈련 형식을 비교하고 있다.</p><ul><li>SEGMENT - PAIR + NSP: BERT의 원래 입력 형식을 따르며 NSP loss를 포함한다. 각 입력은 여러 자연스러운 문장을 포함한 세그먼트 쌍이 있으며, 총 길이는 512 토큰 이하여야 한다.</li><li>SENTENCE - PAIR + NSP: 각 입력은 하나의 문서의 연속적인 부분 또는 별개의 문서에서 추출된 자연스러운 문장 쌍을 포함한다. 이러한 입력은 512 토큰보다 훨씬 짧으므로, 총 토큰 수가 SEGMENT - PAIR + NSP와 비슷하게 유지되도록 배치 크기를 늘린다. NSP loss는 유지된다.</li><li>FULL - SENTENCES: 각 입력은 하나 이상의 문서에서 연속적으로 샘플링된 문장으로 채워져 있으며, 총 길이는 최대 512 토큰이다. 문서가 끝나면 다음 문서에서 샘플링을 시작하고, 문서 사이에는 추가 구분자 토큰을 넣는다. NSP loss는 제거된다.</li><li>DOC - SENTENCES: 입력은 FULL - SENTENCES와 유사하게 구성된다. 문서 끝 부분에서 샘플링된 입력은 512 토큰보다 짧을 수 있어, 이런 경우에는 배치 크기를 동적으로 늘려 FULL SENTENCES와 같은 총 토큰 수를 유지한다. NSP loss는 제거한다.</li></ul><p><img src=/p/roberta/images/table2.png width=854 height=448 srcset="/p/roberta/images/table2_hu68613bddb48bed701794d1b66c589053_103697_480x0_resize_box_3.png 480w, /p/roberta/images/table2_hu68613bddb48bed701794d1b66c589053_103697_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=190 data-flex-basis=457px></p><p>원래의 SEGMENT - PAIR 입력 형식과 SENTENCE - PAIR 형식을 비교했으며, 둘 다 NSP loss를 유지하되 후자는 단일 문장을 사용한다. 개별 문장 사용은 모델이 장거리 의존성을 학습하지 못함으로써 성능을 저하시킨다는 것을 발견하였다.</p><p>NSP loss 없이 훈련과 단일 문서의 텍스트 블록을 사용한 학습(DOC - SENTENCES)을 비교했을 때, 이 설정이 $BERT_{BASE}$ 결과를 능가하며, NSP loss를 제거하면 downstream task 성능이 향상된다는 것을 발견하였다.</p><p>마지막으로, 단일 문서의 시퀀스(DOC - SENTENCES)가 여러 문서의 시퀀스(FULL - SENTENCES)보다 약간 더 나은 성능을 보이지만, DOC - SENTENCES 형식은 배치 크기가 변동적이므로, 나머지 실험에서는 FULL SENTENCES를 사용하였다.</p><h3 id=training-with-large-batches>Training with large batches</h3><p>Neural Machine Translation의 이전 연구에 따르면, earning rate가 적절하게 증가할 때 아주 큰 mini-batches를 사용한 학습은 최적화 속도와 성능 모두를 개선시킬 수 있다는 것이 증명되었다. 최근의 연구는 BERT 또한 큰 배치 학습에 적합하다는 것이 밝혀졌다.</p><p><img src=/p/roberta/images/table3.png width=604 height=194 srcset="/p/roberta/images/table3_hubaf80ecf6afab50cb0332dd70f744a28_32896_480x0_resize_box_3.png 480w, /p/roberta/images/table3_hubaf80ecf6afab50cb0332dd70f744a28_32896_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=311 data-flex-basis=747px></p><p>배치 크기를 증가시키면서 $BERT_{BASE}$의 Perplexity와 성능을 비교하였고, 큰 배치로 훈련하면 마스크 언어 모델링 목표의 Perplexity와 정확도가 향상된다는 것을 관찰했다. 또한, 큰 배치는 분산 데이터 병렬 훈련을 통해 더 쉽게 병렬화할 수 있다.</p><h3 id=text-encoding>Text Encoding</h3><p>Byte-Pair Encoding(BPE)는 자연어 말뭉치의 큰 어휘를 처리하기 위해 문자와 단어 수준 표현의 중간 형태를 사용한다. BPE는 훈련 말뭉치의 통계 분석을 통해 추출된 subword unit를 사용한다. byte를 사용한 BPE는, Unknown 토큰 없이도, 50K units의 서브워드 사전으로 학습을 진행할 수 있다.</p><p>기존의 BERT는 character level의 BPE를 사용했다. RoBERTa는 추가 전처리나 토크나이징 없이 larger byte-level BPE로 학습을 진행한다.</p><p>Byte level BPE는 몇 개의 태스크에서 성능이 떨어진다는 단점이 있지만, 성능 하락폭이 크지 않고 universal 인코딩의 장점이 있다고 판단하여 본 연구에서 Byte level BPE를 적용하였다.</p><hr><h2 id=roberta>RoBERTa</h2><p>BERT 사전 학습 절차를 수정하여 end-task 성능을 향상시키는 방안을 제안한다. 이를 모두 합쳐서 그 효과를 평가한 결과, RoBERTa라는 새로운 설정이 만들어졌다. RoBERTa는 동적 마스킹, NSP loss 없는 전체 문장, 큰 미니 배치, 더 큰 바이트 수준 BPE를 사용하여 학습된다.</p><p>또한, 사전 학습에 사용된 데이터와 데이터를 통한 학습 통과 횟수라는 두 가지 중요한 요소를 조사했다. 이를 검증하기 위해 $BERT_{LARGE}$ 아키텍처를 따라 RoBERTa를 훈련시켰고, BOOK CORPUS와 WIKIPEDIA dataset을 사용하여 100K 단계 동안 사전 학습 하였다.</p><p><img src=/p/roberta/images/table4.png width=1034 height=498 srcset="/p/roberta/images/table4_hu5396c4466a3949f8b298043e563fba53_107966_480x0_resize_box_3.png 480w, /p/roberta/images/table4_hu5396c4466a3949f8b298043e563fba53_107966_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=207 data-flex-basis=498px></p><p>RoBERTa는 원래의 $BERT_{LARGE}$ 결과에 비해 크게 향상된 성능을 보여준다. 추가로, 다양한 데이터셋을 결합하여 훈련시킨 결과, 모든 downstream task에서 성능이 더욱 개선되었다.</p><p>또한, 사전 학습 단계를 100K에서 300K, 그리고 500K로 늘렸을 때, downstream task 성능에서 상당한 향상을 보여주었다. 이렇게 학습된 모델들은 대부분의 작업에서 $XLNet_{LARGE}$를 능가하였다.</p><p>마지막으로, GLUE, SQuaD, 그리고 RACE라는 세 가지 다른 benchmark에서 최적의 RoBERTa 모델을 평가하였다. 이는 모든 다섯 가지 dataset에 대해 500K 단계로 훈련된 RoBERTa를 기준으로 한 것이다.</p><h3 id=glue-results>GLUE Results</h3><p>GLUE에 대해 두 가지 미세 조정 설정을 고려했다. 첫 번째는 각 GLUE 작업에 대해 RoBERTa를 별도로 미세조정 했으며, 각 작업에 대한 중간 개발 세트 결과를 앙상블 없이 측정했다. 두 번째는 GLUE 리더보드를 통해 RoBERTa를 다른 모델과 비교했다. 단일 작업 미세 조정에만 의존하였다. 특히, RTE, STS, 그리고 MRPC에서는 MNLI 단일 작업 모델에서 시작하여 미세 조정 하는 것이 도움이 되었다. 각 작업에 대해 5에서 7개의 모델을 앙상블하였다.</p><p><img src=/p/roberta/images/table5.png width=1216 height=434 srcset="/p/roberta/images/table5_huadd96c22cf129e9e57bfc748b9ec272f_127632_480x0_resize_box_3.png 480w, /p/roberta/images/table5_huadd96c22cf129e9e57bfc748b9ec272f_127632_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=280 data-flex-basis=672px></p><p>RoBERTa가 GLUE 작업 개발 세트 9개 모두에서 state-of-the-art를 달성하였다. $BERT_{LARGE}$와 동일한 구조를 사용하면서도, $BERT_{LARGE}$와 $XLNet_{LARGE}$를 능가하였다. 이는 모델 구조와 사전학습 목표 이외의 요인들이 중요할 수 있다는 점을 시사한다.</p><p>앙상블 설정에서는, RoBERTa를 GLUE 리더보드에 제출하여 9개 작업 중 4개에서 state-of-the-art를 달성하였고, 가장 높은 평균 점수를 얻었다. 이는 RoBERTa가 다중 작업 미세 조정에 의존하지 않는다는 점에서 특히 주목할만하다.</p><h3 id=squad-results>SQuAD Results</h3><p>SQuAD에 대해 과거의 복잡한 접근법 대신 단순한 방법을 채택하였다. BERT와 XLNet이 추가 QA 데이터셋을 훈련 데이터에 포함시킨 반면, 이 연구에서는 제공된 SQuAD 훈련 데이터만으로 RoBERTa를 미세조정 하였다. 모든 레이어에 대해 동일한 learning rate를 사용하였다.</p><p><img src=/p/roberta/images/table6.png width=578 height=432 srcset="/p/roberta/images/table6_hu481d86a4cd9c9a51bdc3b68dcd698e3f_79878_480x0_resize_box_3.png 480w, /p/roberta/images/table6_hu481d86a4cd9c9a51bdc3b68dcd698e3f_79878_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=133 data-flex-basis=321px></p><p>RoBERTa는 SQuAD v1.1 개발 세트에서 XLNet과 동일한 성능을 보여주며, SQuAD v2.0에서는 XLNet을 약간 상회하는 새로운 state-of-the-art를 달성하였다.</p><p>RoBERTa를 공개 SQuAD 2.0 리더보드에 제출했고, 추가적인 학습 데이터를 사용하지 않았음에도 불구하고, 단일 모델 제출 중 거의 모든 시스템을 능가하는 성과를 보여주었다. 데이터 증강에 의존하지 않는 시스템 중에서는 가장 높은 점수를 받았다.</p><h3 id=race-results>RACE Results</h3><p>RACE에서는 텍스트, 관련 질문, 네 개의 후보 답변이 제공되며, 시스템은 정답을 분류해야 한다. RoBERTa를 이 작업에 맞게 수정했으며, 각 후보 답변을 해당 질문과 텍스트에 연결하여 처리하였다. 전체 길이가 512 토큰을 초과하지 않도록 조정했다.</p><p><img src=/p/roberta/images/table7.png width=560 height=248 srcset="/p/roberta/images/table7_hu659b09db86c53974d5e6a7a79677b569_44262_480x0_resize_box_3.png 480w, /p/roberta/images/table7_hu659b09db86c53974d5e6a7a79677b569_44262_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=225 data-flex-basis=541px></p><p>RACE 테스트 세트에서의 결과는 RoBERTa가 중학교와 고등학교 환경 모두에서 state-of-the-art를 달성하였다.</p><hr><h2 id=related-work>Related Work</h2><p>다양한 사전 학습 방법들은 언어 모델링, 기계 번역, 마스킹된 언어 모델링 등의 목표를 가지고 설계되었다. 최근 연구에서는 마스킹된 언어 모델 목표를 사용해 사전 학습하고, 각 작업에 대해 모델을 미세 조정하는 방법을 사용하였다. 그러나 새로운 방법들은 다중 작업 미세 조정, 엔티티 임베딩 통합, 범위 예측, 자동회귀 사전 학습의 변형 등을 통해 성능을 향상시켰다. 일반적으로, 더 큰 모델을 더 많은 데이터로 훈련함으로써 성능이 향상되었다.</p><hr><h2 id=conclusion>Conclusion</h2><p>BERT 모델을 사전 학습시키는데 있어 다양한 디자인 결정을 신중하게 평가했다. 모델을 더 오래 훈련하고, 더 큰 배치로 더 많은 데이터를 사용하며, 다음 문장 예측 목표를 제거하고, 더 긴 시퀀스를 훈련하며, 훈련 데이터에 적용된 마스킹 패턴을 동적으로 변경하면 성능이 크게 향상됨을 발견했다. 이러한 개선된 사전 학습 절차를 RoBERTa라 부르며, GLUE, RACE, SQuAD에서 state-of-the-art를 달성하였다.</p><hr><h2 id=reference>Reference</h2><ul><li><a class=link href=https://arxiv.org/pdf/1907.11692.pdf target=_blank rel=noopener>Paper</a></li><li><a class=link href=https://github.com/facebookresearch/fairseq target=_blank rel=noopener>Github</a></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/nlp/>NLP</a></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>관련 글</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/direct-preference-optimization/><div class=article-details><h2 class=article-title>Direct Preference Optimization</h2></div></a></article><article><a href=/p/p-tuning-v2/><div class=article-details><h2 class=article-title>P-Tuning v2</h2></div></a></article><article><a href=/p/rwkv/><div class=article-details><h2 class=article-title>RWKV</h2></div></a></article><article><a href=/p/p-tuning/><div class=article-details><h2 class=article-title>P-Tuning</h2></div></a></article><article><a href=/p/palm-2/><div class=article-details><h2 class=article-title>PaLM 2</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=KurtKim/kurtkim.github.io issue-term=pathname crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2023 -
2024 K2H'log</section><section class=powerby><a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a>로 만듦<br><a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a>의 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.17.0>Stack</a></b> 테마 사용 중</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script></body></html>