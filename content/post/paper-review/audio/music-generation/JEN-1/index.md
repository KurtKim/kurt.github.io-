+++
author = "Kurt"
title = "JEN-1"
date = "2024-07-20"
description = "Text-Guided Universal Music Generation with Omnidirectional Diffusion Models"
categories = [
    "Paper Review"
]
tags = [
    "Audio",
    "Music Generation",
]
draft = true
+++

## Abstract

음악 생성은 심층 생성 모델의 발전과 함께 많은 관심을 받고 있지만, 텍스트에서 음악으로의 변환은 여전히 음악 구조의 복잡성과 높은 샘플링 속도 요구 때문에 어려운 과제이다. 이 논문에서는 JEN-1이라는 범용 고해상도 모델을 소개한다. JEN-1은 autoregressive와 non-autoregressive 학습을 통합한 diffusion 모델로, 텍스트로 가이드된 음악 생성 및 음악 인페인팅과 같은 다양한 작업을 수행할 수 있다. 평가 결과는 JEN-1이 텍스트와 음악의 정렬 및 품질에서 최신 기법들보다 우수한 성능을 보이면서도 계산 효율성을 유지한다는 것을 보여준다.

---

## Introduction

---

## Reference

* [Paper](https://arxiv.org/pdf/2308.04729)
* [GitHub](https://github.com/0417keito/JEN-1-pytorch)
* [Demo](https://www.jenmusic.ai/research)