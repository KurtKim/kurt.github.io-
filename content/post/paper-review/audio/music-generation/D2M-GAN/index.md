+++
author = "Kurt"
title = "D2M-GAN"
date = "2024-08-20"
description = "Quantized GAN for Complex Music Generation from Dance Videos"
categories = [
    "Paper Review"
]
tags = [
    "Audio",
    "Music Generation",
]
draft = true
+++

## Abstract

Dance2Music-GAN (D2M-GAN)을 소개한다. D2M-GAN은 댄스 비디오에 맞춰 복잡한 음악을 생성하는 새로운 프레임워크로, 댄스 비디오 프레임과 신체 움직임을 입력으로 받아 적합한 음악을 생성한다. 기존의 조건부 음악 생성 방식과 달리, VQ 오디오 표현을 사용하여 다양한 스타일의 댄스 음악을 생성하며, 광범위한 실험과 평가를 통해 효과성을 입증하였다. 실제 TikTok 비디오를 포함한 데이터셋을 제공하며, 향후 연구에 유용한 출발점이 될 것이다. 

---

## Introduction





---

## Reference

* [Paper](https://arxiv.org/pdf/2204.00604)
* [GitHub](https://github.com/L-YeZhu/D2M-GAN)