+++
author = "Kurt"
title = "MuseGAN"
date = "2024-07-10"
description = "Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment"
categories = [
    "Paper Review"
]
tags = [
    "Audio",
    "Music Generation",
]
draft = true
+++

## Abstract

음악 생성과 이미지, 비디오 생성 사이의 주요 차이점은 다음과 같다: 음악은 시간적 예술이므로 시간 모델이 필수적이다. 일반적으로 여러 악기/트랙이 상호작용하면서 발전하며, 음악적 음표들은 다양한 형태로 그룹화되어 시간적 순서는 자연스럽게 정렬되지 않는다. 이 논문에서는 생성적 적대 신경망(GANs)을 이용하여 심볼릭 다중 트랙 음악 생성을 위한 세 가지 모델을 제안하며, 록 음악 데이터셋을 사용하여 훈련하고 평가하였다. 이 모델들은 인간의 입력 없이도 일관된 음악을 생성할 수 있으며, 인간-AI 협력 음악 생성으로도 확장 가능함을 보여준다.

---

## Introduction


---

## Reference

* [Paper](https://arxiv.org/pdf/1709.06298)
* [GitHub](https://github.com/salu133445/musegan)
* [Demo](https://hermandong.com/musegan/)