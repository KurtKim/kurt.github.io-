+++
author = "Kurt"
title = "QLoRA"
date = "2024-04-20"
description = "Efficient Finetuning of Quantized LLMs"
categories = [
    "Paper Review"
]
tags = [
    "LLM",
    "Quantization",
]
draft = true
+++

## Abstract

QLoRA는 단일 48GB GPU에서 65B parameter 모델을 효율적으로 미세 조정 할 수 있는 방법으로, 메모리 사용량을 줄이면서도 전체 16비트 미세 조정 성능을 유지한다. 이 방법은 동결된 4비트 양자화 사전 학습 모델을 통해 gradient를 LoRA로 backpropagate 한다. Guanaco 모델은 Vicuna 벤치마크에서 기존 모델들을 능가하며, 단일 GPU를 사용해 24시간만에 ChatGPT의 99.3% 성능에 도달한다. QLoRA는 성능 저하 없이 메모리를 절약하는 여러 혁신을 도입했으며, 1,000개 이상의 모델을 미세 조정 해 다양한 데이터셋과 모델 규모에서 상세한 분석을 제공한다. 이 연구는 작은 고품질 데이터셋에서 최신 기술 결과를 달성할 수 있음을 보여주며, GPT-4 평가가 인간 평가의 합리적 대안임을 보여준다. 또한, 현재 챗봇 벤치마크의 신뢰성 문제를 지적하고, 모든 모델과 코드를 공개한다.

---

## Introduction

대규모 언어 모델(LLMs)을 미세 조정하는 것은 성능 향상과 바람직한 행동 조정에 효과적이지만, 매우 비용이 많이 든다. 예를 들어, 65B parameter 모델을 16비트로 미세 조정하려면 780GB 이상의 GPU 메모리가 필요하다. 양자화 기술로 메모리 사용량을 줄일 수 있으나, 이는 추론 시에만 유효하고 학습 시에는 적용되지 않는다.

QLORA 방법을 통해, 처음으로 4비트 양자화 모델을 성능 저하 없이 미세 조정할 수 있음을 입증하였다. 이는 새로운 고정밀 기술로 모델을 4비트로 양자화하고, 양자화된 가중치를 통한 backpropagating gradient로 조정 가능한 Low-rank Adapter 가중치를 추가하는 방식이다.

QLORA는 65B parameter 모델의 GPU 메모리 요구량을 780GB에서 48GB 미만으로 대폭 줄였다. 이를 통해 최대 규모의 공개 모델을 단일 GPU에서 세부 조정할 수 있게 되었으며, 실행 시간과 예측 성능은 기존 16비트 기준선과 동일하다. QLORA를 사용해 Guanaco 모델을 훈련시켜 ChatGPT와의 성능 격차를 거의 해소했으며, 가장 작은 Guanaco 모델은 5GB 메모리로 Vicuna 벤치마크에서 Alpaca 모델을 크게 앞섰다.

QLORA는 성능 손실 없이 메모리 사용을 줄이기 위해 여러 혁신을 적용한다: (1) 정규 분포 데이터에 최적화된 4비트 NormalFloat는 기존의 4비트 정수 및 부동 소수점보다 우수한 결과를 제공한다. (2) 이중 양자화는 양자화 상수를 추가로 양자화하여 parameter 당 평균 0.37비트를 절약한다. (3) 페이지 옵티마이저는 긴 시퀀스를 처리할 때 메모리 스파이크를 방지한다. 이러한 기법들을 통합해, QLORA는 네트워크의 모든 계층에 어댑터를 적용하며 이전 방법들에서의 정확도 타협을 대부분 해결한다.

QLORA의 효율성 덕분에 기존 세부 조정 방식으로는 불가능한 크기의 모델들에 대한 지시사항 세부 조정과 챗봇 성능 연구를 수행할 수 있다. 이를 통해 80M에서 65B 파라미터 범위의 다양한 데이터셋과 모델 구조에서 1,000개 이상의 모델을 학습시켰다. 주요 발견으로, 데이터 품질이 크기보다 중요하며, 예를 들어 작은 데이터셋이 큰 데이터셋을 성능 면에서 능가하였다. 또한, 언어 이해 벤치마크에서의 성능이 챗봇 벤치마크에서의 성능을 보장하지 않음을 확인하였다. 이는 작업에 적합한 데이터셋의 중요성을 강조한다.

인간 평가자와 GPT-4를 사용한 챗봇 성능 분석에서, 토너먼트 방식을 통해 모델 간 경쟁이 이루어졌다. 이 경쟁에서는 Elo 점수로 순위가 결정되며, 대체로 GPT-4와 인간 평가의 순위가 일치하지만 강한 불일치 사례도 발견되었다. 이는 모델 기반 평가가 비용 효율적이긴 하지만, 일정한 불확실성을 가지고 있음을 시사한다.

Guanaco 모델에 대한 질적 분석을 통해 챗봇 벤치마크 결과를 보완하며, 이를 통해 정량적 평가에서 놓친 성공 및 실패 사례를 드러낸다.

인간 평가자와 GPT-4 주석이 달린 모든 모델 생성물을 공개하고, 코드베이스와 CUDA 커널을 오픈 소스로 제공한다. 또한, Hugging Face 트랜스포머 스택에 이 연구의 방법을 통합하여 접근성을 높였다. 7/13/33/65B 크기의 모델용 어댑터와 8개 지시사항 데이터셋에서 학습된 32개의 미세 조정 모델을 공개한다.

---

## Background




---

## Reference

* [Paper](https://arxiv.org/pdf/2305.14314.pdf)
* [GitHub](https://github.com/artidoro/qlora)