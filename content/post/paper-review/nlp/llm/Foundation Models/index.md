+++
author = "Kurt"
title = "Foundation Models"
date = "2024-01-01"
description = "On the Opportunities and Risks of Foundation Models"
categories = [
    "Paper Review"
]
tags = [
    "NLP",
    "LLM",
]
draft = true
+++

## Abstract

AI는 넓은 범위의 데이터에서 학습된 다양한 모델(BERT, DALL-E, GPT-3 등)이 등장하며 패러다임 변화를 겪고 있다. 이런 모델들을 "foundation model"이라 부르며, 그들의 중요성과 불완전성을 강조한다. 이 모델들은 많은 작업에 효과적이어서 동질화를 촉진하지만, 그 결함은 모든 하위 모델에 상속되므로 주의가 필요하다. foundation model의 작동 방식, 실패 시점, 그리고 가능성에 대한 명확한 이해는 아직 부족하며, 이에 대한 연구는 그들의 사회기술적 성질에 맞게 깊은 학제간 협력을 필요로 한다.

---

## Introduction

이 보고서는 "foundation model"이라는 일반적인 AI 모델 클래스를 기반으로 하는 시스템 구축에 대한 새로운 패러다임을 조사한다. foundation model은 광범위한 데이터에서 학습되어 다양한 downstream task에 적용될 수 있다. 이는 기존의 deep neural network와 self-supervised 학습에 기반하지만, 그 규모와 범위는 우리의 상상력을 넘어섰다. 예를 들어, GPT-3 같은 모델은 막대한 parameter를 가지고 있고, 특정 작업에 대한 명확한 학습 없이도 다양한 작업을 수행할 수 있다. 그러나, 이런 모델들의 특성은 잘 이해되지 않았고, 잠재적인 해를 악화시킬 수 있다. 이러한 모델들이 널리 배포될 예정이므로, 심도 있는 조사가 필요하다.

### Emergence and homogenization

foundation model의 중요성은 "emergence"과 "homogenization" 두 가지 개념으로 요약된다. "emergence"는 시스템 행동이 명시적으로 구축되지 않고 암시적으로 유도되는 것을 의미하며, 이는 흥분과 예상치 못한 결과에 대한 불안을 가져온다. "homogenization"는 다양한 응용 분야에서 기계 학습 시스템 구축 방법론을 통합하는 것을 가리키며, 많은 작업에 대한 leverage를 제공하지만 단일 실패 지점을 만들 수 있다. 이 두 개념은 최근 30년 동안 AI 연구에서 점점 중요해지고 있다.

![](images/figure1.png)

**Machine learning.** 오늘날 대부분의 AI 시스템은 과거 데이터를 학습하여 미래를 예측하는 기계 학습에 의해 구동된다. 1990년대부터 시작된 AI에서의 기계 학습의 부상은 작업 해결 방법을 명시하는 대신 데이터를 바탕으로 학습 알고리즘이 이를 유도하는 새로운 방식을 나타냈다. 이는 "how"가 학습 과정에서 발생하는 것을 의미한다. 또한, 기계 학습은 로지스틱 회귀와 같은 일반적인 학습 알고리즘을 통해 다양한 응용 분야를 통합하는 동질화로 나아가는 한 걸음을 나타냈다.

AI에서 기계 학습이 널리 사용되지만, 자연어 처리나 컴퓨터 비전 등의 복잡한 작업에서는 도메인 전문가가 "feature engineering"을 수행해야 했다. 이는 raw 데이터를 더 고수준의 특징으로 변환하는 과정으로, 기계 학습 방법에 더 적합하게 만드는 역할을 한다.

**Deep learning.** 2010년경, 딥러닝이라는 이름 아래에 deep neural network의 부활이 이루어졌다. 이는 더 큰 데이터셋, 더 많은 계산 능력, 그리고 대담함에 의해 추진되었다. raq 입력에 대한 학습을 통해 고수준의 특징이 발생하였고, 이는 성능 향상을 가져왔다. 딥러닝은 homogenization를 향한 또 다른 전환을 나타냈는데, 맞춤형 feature engineering 대신 동일한 deep neural network 아키텍처가 다양한 응용 프로그램에 사용될 수 있게 되었다.

**Foundation models.** foundation model은 주로 자연어 처리(NLP)에 초점을 맞추지만, 일반적인 AI 패러다임으로 볼 수 있다. 이러한 모델은 전이 학습과 규모의 확장을 통해 가능하게 되었으며, 한 작업에서 배운 지식을 다른 작업에 적용하는 것을 목표로 한다. 주로, 모델은 대리 작업에서 사전 학습을 받고, 그 후에는 미세조정을 통해 특정 작업에 적용된다.

foundation model의 강력함은 전이 학습의 가능성과 규모의 확장성에서 비롯된다. 규모 확장에는 컴퓨터 하드웨어의 개선, 표현력 높은 모델을 훈련시키는 Transformer 아키텍처의 개발, 그리고 대량의 학습 데이터의 활용이 필요하다.

데이터의 가용성과 활용 능력은 매우 중요하며, 주석이 달린 데이터셋을 사용한 전이 학습은 이미 10년 동안 일반적으로 이루어지고 있다. 그러나 주석 작성의 비용은 사전학습의 이점에 제한을 두게 된다.

self-supervised 학습에서는 주석이 없는 데이터에서 사전학습 작업이 자동으로 이루어진다. 이 방식은 레이블이 없는 데이터에 의존하므로 확장성이 뛰어나며, 모델이 입력의 일부를 예측하게 함으로써 한정된 레이블 공간에서 학습된 모델보다 더 풍부하고 유용할 수 있다.

단어 임베딩 이후로, self-supervised 학습은 크게 발전했다. 이는 각 단어를 문맥에 독립적인 벡터로 표현하며, 다양한 NLP 모델의 기반이 되었다. 또한, autoregressive 언어 모델링을 기반으로 한 self-supervised 학습이 인기를 끌었으며, 이를 통해 문맥 속 단어를 표현하는 GPT, ELMo, ULMFiT와 같은 모델들이 생성되었다.

self-supervised 학습의 다음 단계는 BERT, GPT-2, RoBERTa, T5, BART 등이 빠르게 따라왔으며, 이들은 Transformer 아키텍처를 채택하고, 문장의 강력한 bidirectional encoder를 통합하며, 더 큰 모델과 데이터셋으로 확장하였다.

BERT의 등장은 self-supervised 학습에 대한 사회학적 변곡점이었다. 2019년 이전에는 NLP의 하위 분야였지만, 2019년 이후로는 NLP의 핵심 부분이 되었다. 단일 모델이 넓은 범위의 작업에 유용하다는 인식은 foundation model의 시대의 시작을 의미한다.

foundation model들은 NLP 모델의 homogenization를 가져왔고, 이는 높은 지렛대 효과를 제공하지만 동시에 위험성도 내포하고 있다. 모든 AI 시스템이 foundation model의 문제적인 편향을 상속받을 수 있기 때문이다.

연구 커뮤니티 간에 homogenization가 점차 진행되고 있다. Transformer-based sequence 모델링 방법론이 텍스트, 이미지, 음성, 표 데이터, 단백질 시퀀스, 유기 분자, 강화 학습 등 다양한 분야에 적용되고 있다. 이러한 예시들은 다양한 형태의 foundation model을 개발할 수 있는 통합 도구 세트를 가질 미래를 예상하게 한다.

![](images/figure2.png)

접근법뿐만 아니라 실제 모델 역시 여러 연구 커뮤니티에서 통일되고 있다. 이는 언어와 시각 데이터를 학습하는 multimodal 모델의 형태로 나타난다. 일부 영역에서는 데이터가 자연스럽게 multimodal이며, 이는 의료 이미지, 구조화된 데이터, 의료 텍스트 등에서 볼 수 있다. 따라서, multimodal foundation model은 도메인에 대한 모든 관련 정보를 통합하고 다양한 모드를 아우르는 업무에 적응하는 자연스러운 방법이다.

규모의 증가로 인해 foundation model들은 놀라운 발전을 이끌어냈다. GPT-3는 175B 개의 parameter를 가지고 있어, 프롬프트(업무의 자연어 설명)만 제공하면 하위 업무에 쉽게 적응할 수 있는 문맥 내 학습이 가능하다. 이는 특별히 학습되지 않았지만 예상치 못하게 발생한 특성이다.

homogenization와 emergence은 잠재적으로 불안정한 방식으로 상호 작용한다. homogenization는 특정 과제 데이터가 제한된 많은 분야에서 큰 이익을 가져올 수 있지만, 모델의 결함은 모든 적응된 모델에게 그대로 상속된다. foundation model의 힘은 그들의 명시적인 구성보다는 출현적 특성에서 나오므로, 이해하기 어렵고 예측하지 못한 실패 모드를 가진다. 이런 emergence이 foundation model의 능력과 결함에 대한 불확실성을 증가시키므로, 이러한 모델을 통한 공격적인 homogenization는 위험하다. 윤리적 및 AI 안전성 관점에서 볼 때, 위험을 줄이는 것이 foundation model의 추가 개발에서 중요한 도전 과제이다.

#### Naming.

"foundation model"이라는 용어는 지금 목격하고 있는 패러다임의 변화를 설명하는 데 필요한 용어이다. 기존의 용어들은 이러한 모델들의 기술적 면을 부분적으로 포착하지만, 기계 학습을 넘어서는 사람들에게 패러다임 변화의 중요성을 적절하게 전달하지 못한다. foundation model은 그들의 사회적 영향과 AI 연구와 배포에 있어서의 광범위한 변화를 특징으로 하는 독특한 모델 클래스를 지칭한다. 반면에, 사전 학습과 자기 감독 같은 방식은 foundation model이 예고한 기술적 변화를 명확하게 설명하지 못한다.

현재 대표적인 foundation model들 대부분이 언어 모델이지만, "language model"이라는 용어는 이 목적에는 너무 좁다. foundation model의 범위는 언어를 훨씬 넘어선다. "general-purpose model"이나 "multi-purpose model" 같은 용어는 여러 하위 과제에 적용될 수 있다는 점을 포착하지만, 그들이 미완성된 특성을 가지고 있고 적응이 필요하다는 점을 포착하지 못한다. "task-agnostic model"은 학습 방식을 포착하지만, downstream 응용에 대한 중요한 영향을 포착하지 못한다.

"foundation model"이라는 새로운 용어를 도입하여 현재 등장하고 있는 모델과 패러다임을 식별하였다. foundation model은 자체적으로는 불완전하지만, 다양한 과제에 적응하여 공통의 기반을 제공한다. "foundation"이라는 용어는 architectural stability, safety, security의 중요성을 강조한다. 현재로서는, foundation model의 본질이나 품질을 완전히 이해하지 못하고 있으며, 이는 연구자, 모델 제공자, 응용 프로그램 개발자, 정책 입안자, 그리고 사회 전체가 고민해야 할 중요한 문제이다.

### Social impact and the foundation models ecosystem

기초 모델들은 높은 성능 때문에 과학적으로 중요하며, 실제 AI 시스템에 빠르게 통합되어 사람들에게 큰 영향을 미치기 때문에 연구가 필요하다. 예를 들어, 40억 명의 사용자를 가진 구글 검색은 BERT와 같은 기초 모델을 사용하고 있다.

기초 모델의 사회적 영향에 대해 깊이 생각해봐야 한다. 이 보고서에서는 사회 불평등, 경제적 영향, 환경 영향, 오용 가능성, 법적 문제, 윤리적 문제 다양한 측면을 다룬다. 특정 시스템의 사회적 영향을 추론하는 것이 기초 모델의 사회적 영향을 추론하는 것보다 더 쉽다는 점이 반복적으로 나타난다. 기초 모델의 변화무쌍한 성질로 인해, 그들이 제기하는 윤리적, 사회적 고려사항을 책임감 있게 예측하고 다루는 것이 중요하다.

기초 모델에 대한 연구와 배포는 구분되어야 한다. 대부분의 공개적인 정보는 학술 논문이나 데모를 통한 연구에 관한 것이다. 이런 지식의 생산은 중요하지만, 실제로 사회에 영향을 미치는 것은 모델의 배포이다. 배포는 새 제품, 예를 들어 GitHub의 Copilot 같은 것을 통해 이루어지거나 기존 제품을 업그레이드하는 형태로 일어난다. 연구 모델은 광범위한 테스트 없이 알려지지 않은 실패를 가질 수 있어, 배포에 적합하지 않다는 경고를 요구하며, 실제로 사람들에게 영향을 주는 모델은 엄격한 테스트와 감사가 필요하다.

기초 모델의 연구와 배포를 이해하려면 데이터 생성부터 실제 배포에 이르는 전체 생태계를 고려해야 한다. 기초 모델은 AI 시스템의 한 부분이며, 사회적 영향을 고려할 때 사람들이 파이프라인의 양 끝에 위치해 있다는 것은 중요하다. 이러한 관점을 통해, 기초 모델에 대한 다양한 질문들이 실제로는 다른 단계에 대해 답변되어야 함을 알 수 있다.

1. **Data creation:** 데이터 생성은 사람 중심의 과정으로, 모든 데이터는 사람에 의해 만들어지고 대부분 사람에 대한 정보를 담고 있다. 이는 이메일, 기사, 사진 등을 통한 정보 제공이거나, 사람이나 그들의 환경에 대한 측정일 수 있다. 모든 데이터는 소유자가 있으며 특정 목적을 위해 생성되며, 이 목적은 기초 모델 학습을 포함할 수도, 포함하지 않을 수도 있다.
2. **Data curation:** 데이터는 데이터세트로 정리되는데, 이 과정은 선택과 후처리 필터링이 필요하다. 데이터의 관련성과 품질을 보장하면서 법적, 윤리적 제약을 준수하는 것은 중요하지만 어렵다. 이 점은 산업에서는 인식되고 있지만, AI 연구에서는 충분히 인식되지 않고 있다.
3. **Training:** 정리된 데이터셋에서 기초 모델을 학습시키는 것은 AI 연구의 중요한 단계이지만, 이는 전체 과정 중 일부일 뿐이다.
4. **Adaptation:** 기계 학습 연구에서의 적응은 특정 작업을 수행하는 새 모델을 생성하는 것이다. 배포를 위한 적응은 다양한 모듈, 사용자 정의 규칙, 분류기 등을 필요로 하는 시스템을 만드는 것이다. 예를 들어, 유해한 콘텐츠를 생성할 수 있는 모델도 적절한 예방 조치가 취해진다면 문제가 되지 않는다. 이러한 추가적인 응용 특화 로직은 해를 줄이는 데 중요하다.
5. **Deployment:** AI 시스템이 사람들에게 배포될 때 직접적인 사회적 영향이 발생한다. 논란의 여지가 있는 데이터를 기반으로 한 잠재적으로 해로운 기초 모델을 배포하길 원치 않지만, 이를 연구에 사용하여 과학적 이해를 향상시키는 것에는 가치가 있을 수 있다. 대규모 배포에서는 점진적으로 릴리스를 실시하는 것이 표준적인 관행이며, 이는 잠재적인 해를 부분적으로 완화할 수 있다.

이 보고서는 기초 모델에 대한 것이지만, 파이프라인의 다른 단계에서의 결정으로 인한 영향을 간과할 수 없다. 모든 단계에서 주의 깊은 모니터링과 개입이 필요하다. 대형 조직이 전체 파이프라인을 소유할 수 있지만, 각 단계는 다른 조직이 수행할 수 있다. 예를 들어, 응용 프로그램 개발자가 사용할 수 있는 맞춤형 기초 모델을 만드는 전문 회사가 될 수 있다.

**Think ecosystem, act model.** 사회적 영향은 전체 생태계에 따라 달라지지만, 많은 연구자와 실무자가 학습 단계에 집중하고 있기 때문에 기초 모델의 사회적 함의를 이해하는 것이 중요하다. 이는 기초 모델이 완성되지 않은 중간 단계이며, 예측하지 못한 목적으로 다른 엔티티에 의해 다양하게 적용될 수 있기 때문에 어렵다. 이를 위해 필요한 것은 잠재적인 downstream 평가를 대표하는 대리 메트릭과 이러한 메트릭을 문서화하는 데의 헌신이다. 이는 다양한 downstream 사용 사례에 적응할 수 있는 금속이나 플라스틱 같은 재료의 데이터 시트와 유사하다.

기초 모델의 잠재적인 사회적 영향을 파악하는 것은 기술 생태계와 사회에 대한 깊은 이해를 필요로 하며, 도전적이다. 모델의 배포 방식을 이해하지 않고서는 그 해를 완전히 평가할 수 없으며, 사회적, 역사적 맥락을 고려하지 않고서는 자동 메트릭을 정의할 수 없다.

### The future of foundation models

---

## Reference

* [Paper](https://arxiv.org/pdf/2108.07258.pdf)