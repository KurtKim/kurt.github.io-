+++
author = "Kurt"
title = "Foundation Models"
date = "2024-01-01"
description = "On the Opportunities and Risks of Foundation Models"
categories = [
    "Paper Review"
]
tags = [
    "NLP",
    "LLM",
]
draft = true
+++

## Abstract

AI는 넓은 범위의 데이터에서 학습된 다양한 모델(BERT, DALL-E, GPT-3 등)이 등장하며 패러다임 변화를 겪고 있다. 이런 모델들을 "foundation model"이라 부르며, 그들의 중요성과 불완전성을 강조한다. 이 모델들은 많은 작업에 효과적이어서 동질화를 촉진하지만, 그 결함은 모든 하위 모델에 상속되므로 주의가 필요하다. foundation model의 작동 방식, 실패 시점, 그리고 가능성에 대한 명확한 이해는 아직 부족하며, 이에 대한 연구는 그들의 사회기술적 성질에 맞게 깊은 학제간 협력을 필요로 한다.

---

## INTRODUCTION

이 보고서는 "foundation model"이라는 일반적인 AI 모델 클래스를 기반으로 하는 시스템 구축에 대한 새로운 패러다임을 조사한다. foundation model은 광범위한 데이터에서 학습되어 다양한 downstream task에 적용될 수 있다. 이는 기존의 deep neural network와 self-supervised 학습에 기반하지만, 그 규모와 범위는 우리의 상상력을 넘어섰다. 예를 들어, GPT-3 같은 모델은 막대한 parameter를 가지고 있고, 특정 작업에 대한 명확한 학습 없이도 다양한 작업을 수행할 수 있다. 그러나, 이런 모델들의 특성은 잘 이해되지 않았고, 잠재적인 해를 악화시킬 수 있다. 이러한 모델들이 널리 배포될 예정이므로, 심도 있는 조사가 필요하다.

### Emergence and homogenization

foundation model의 중요성은 "emergence"과 "homogenization" 두 가지 개념으로 요약된다. "emergence"는 시스템 행동이 명시적으로 구축되지 않고 암시적으로 유도되는 것을 의미하며, 이는 흥분과 예상치 못한 결과에 대한 불안을 가져온다. "homogenization"는 다양한 응용 분야에서 기계 학습 시스템 구축 방법론을 통합하는 것을 가리키며, 많은 작업에 대한 leverage를 제공하지만 단일 실패 지점을 만들 수 있다. 이 두 개념은 최근 30년 동안 AI 연구에서 점점 중요해지고 있다.

![](images/figure1.png)

**Machine learning.** 오늘날 대부분의 AI 시스템은 과거 데이터를 학습하여 미래를 예측하는 기계 학습에 의해 구동된다. 1990년대부터 시작된 AI에서의 기계 학습의 부상은 작업 해결 방법을 명시하는 대신 데이터를 바탕으로 학습 알고리즘이 이를 유도하는 새로운 방식을 나타냈다. 이는 "how"가 학습 과정에서 발생하는 것을 의미한다. 또한, 기계 학습은 로지스틱 회귀와 같은 일반적인 학습 알고리즘을 통해 다양한 응용 분야를 통합하는 동질화로 나아가는 한 걸음을 나타냈다.

AI에서 기계 학습이 널리 사용되지만, 자연어 처리나 컴퓨터 비전 등의 복잡한 작업에서는 도메인 전문가가 "feature engineering"을 수행해야 했다. 이는 raw 데이터를 더 고수준의 특징으로 변환하는 과정으로, 기계 학습 방법에 더 적합하게 만드는 역할을 한다.

**Deep learning.** 2010년경, 딥러닝이라는 이름 아래에 deep neural network의 부활이 이루어졌다. 이는 더 큰 데이터셋, 더 많은 계산 능력, 그리고 대담함에 의해 추진되었다. raq 입력에 대한 학습을 통해 고수준의 특징이 발생하였고, 이는 성능 향상을 가져왔다. 딥러닝은 homogenization를 향한 또 다른 전환을 나타냈는데, 맞춤형 feature engineering 대신 동일한 deep neural network 아키텍처가 다양한 응용 프로그램에 사용될 수 있게 되었다.

**Foundation models.** foundation model은 주로 자연어 처리(NLP)에 초점을 맞추지만, 일반적인 AI 패러다임으로 볼 수 있다. 이러한 모델은 전이 학습과 규모의 확장을 통해 가능하게 되었으며, 한 작업에서 배운 지식을 다른 작업에 적용하는 것을 목표로 한다. 주로, 모델은 대리 작업에서 사전 학습을 받고, 그 후에는 미세조정을 통해 특정 작업에 적용된다.

foundation model의 강력함은 전이 학습의 가능성과 규모의 확장성에서 비롯된다. 규모 확장에는 컴퓨터 하드웨어의 개선, 표현력 높은 모델을 훈련시키는 Transformer 아키텍처의 개발, 그리고 대량의 학습 데이터의 활용이 필요하다.

데이터의 가용성과 활용 능력은 매우 중요하며, 주석이 달린 데이터셋을 사용한 전이 학습은 이미 10년 동안 일반적으로 이루어지고 있다. 그러나 주석 작성의 비용은 사전학습의 이점에 제한을 두게 된다.

self-supervised 학습에서는 주석이 없는 데이터에서 사전학습 작업이 자동으로 이루어진다. 이 방식은 레이블이 없는 데이터에 의존하므로 확장성이 뛰어나며, 모델이 입력의 일부를 예측하게 함으로써 한정된 레이블 공간에서 학습된 모델보다 더 풍부하고 유용할 수 있다.

단어 임베딩 이후로, self-supervised 학습은 크게 발전했다. 이는 각 단어를 문맥에 독립적인 벡터로 표현하며, 다양한 NLP 모델의 기반이 되었다. 또한, autoregressive 언어 모델링을 기반으로 한 self-supervised 학습이 인기를 끌었으며, 이를 통해 문맥 속 단어를 표현하는 GPT, ELMo, ULMFiT와 같은 모델들이 생성되었다.

self-supervised 학습의 다음 단계는 BERT, GPT-2, RoBERTa, T5, BART 등이 빠르게 따라왔으며, 이들은 Transformer 아키텍처를 채택하고, 문장의 강력한 bidirectional encoder를 통합하며, 더 큰 모델과 데이터셋으로 확장하였다.

BERT의 등장은 self-supervised 학습에 대한 사회학적 변곡점이었다. 2019년 이전에는 NLP의 하위 분야였지만, 2019년 이후로는 NLP의 핵심 부분이 되었다. 단일 모델이 넓은 범위의 작업에 유용하다는 인식은 foundation model의 시대의 시작을 의미한다.

foundation model들은 NLP 모델의 homogenization를 가져왔고, 이는 높은 지렛대 효과를 제공하지만 동시에 위험성도 내포하고 있다. 모든 AI 시스템이 foundation model의 문제적인 편향을 상속받을 수 있기 때문이다.

연구 커뮤니티 간에 homogenization가 점차 진행되고 있다. Transformer-based sequence 모델링 방법론이 텍스트, 이미지, 음성, 표 데이터, 단백질 시퀀스, 유기 분자, 강화 학습 등 다양한 분야에 적용되고 있다. 이러한 예시들은 다양한 형태의 foundation model을 개발할 수 있는 통합 도구 세트를 가질 미래를 예상하게 한다.

![](images/figure2.png)

접근법뿐만 아니라 실제 모델 역시 여러 연구 커뮤니티에서 통일되고 있다. 이는 언어와 시각 데이터를 학습하는 multimodal 모델의 형태로 나타난다. 일부 영역에서는 데이터가 자연스럽게 multimodal이며, 이는 의료 이미지, 구조화된 데이터, 의료 텍스트 등에서 볼 수 있다. 따라서, multimodal foundation model은 도메인에 대한 모든 관련 정보를 통합하고 다양한 모드를 아우르는 업무에 적응하는 자연스러운 방법이다.

규모의 증가로 인해 foundation model들은 놀라운 발전을 이끌어냈다. GPT-3는 175B 개의 parameter를 가지고 있어, 프롬프트(업무의 자연어 설명)만 제공하면 하위 업무에 쉽게 적응할 수 있는 문맥 내 학습이 가능하다. 이는 특별히 학습되지 않았지만 예상치 못하게 발생한 특성이다.

homogenization와 emergence은 잠재적으로 불안정한 방식으로 상호 작용한다. homogenization는 특정 과제 데이터가 제한된 많은 분야에서 큰 이익을 가져올 수 있지만, 모델의 결함은 모든 적응된 모델에게 그대로 상속된다. foundation model의 힘은 그들의 명시적인 구성보다는 출현적 특성에서 나오므로, 이해하기 어렵고 예측하지 못한 실패 모드를 가진다. 이런 emergence이 foundation model의 능력과 결함에 대한 불확실성을 증가시키므로, 이러한 모델을 통한 공격적인 homogenization는 위험하다. 윤리적 및 AI 안전성 관점에서 볼 때, 위험을 줄이는 것이 foundation model의 추가 개발에서 중요한 도전 과제이다.

#### Naming.

"foundation model"이라는 용어는 지금 목격하고 있는 패러다임의 변화를 설명하는 데 필요한 용어이다. 기존의 용어들은 이러한 모델들의 기술적 면을 부분적으로 포착하지만, 기계 학습을 넘어서는 사람들에게 패러다임 변화의 중요성을 적절하게 전달하지 못한다. foundation model은 그들의 사회적 영향과 AI 연구와 배포에 있어서의 광범위한 변화를 특징으로 하는 독특한 모델 클래스를 지칭한다. 반면에, 사전 학습과 자기 감독 같은 방식은 foundation model이 예고한 기술적 변화를 명확하게 설명하지 못한다.

현재 대표적인 foundation model들 대부분이 언어 모델이지만, "language model"이라는 용어는 이 목적에는 너무 좁다. foundation model의 범위는 언어를 훨씬 넘어선다. "general-purpose model"이나 "multi-purpose model" 같은 용어는 여러 하위 과제에 적용될 수 있다는 점을 포착하지만, 그들이 미완성된 특성을 가지고 있고 적응이 필요하다는 점을 포착하지 못한다. "task-agnostic model"은 학습 방식을 포착하지만, downstream 응용에 대한 중요한 영향을 포착하지 못한다.

"foundation model"이라는 새로운 용어를 도입하여 현재 등장하고 있는 모델과 패러다임을 식별하였다. foundation model은 자체적으로는 불완전하지만, 다양한 과제에 적응하여 공통의 기반을 제공한다. "foundation"이라는 용어는 architectural stability, safety, security의 중요성을 강조한다. 현재로서는, foundation model의 본질이나 품질을 완전히 이해하지 못하고 있으며, 이는 연구자, 모델 제공자, 응용 프로그램 개발자, 정책 입안자, 그리고 사회 전체가 고민해야 할 중요한 문제이다.

### Social impact and the foundation models ecosystem

기초 모델들은 높은 성능 때문에 과학적으로 중요하며, 실제 AI 시스템에 빠르게 통합되어 사람들에게 큰 영향을 미치기 때문에 연구가 필요하다. 예를 들어, 40억 명의 사용자를 가진 구글 검색은 BERT와 같은 기초 모델을 사용하고 있다.

기초 모델의 사회적 영향에 대해 깊이 생각해봐야 한다. 이 보고서에서는 사회 불평등, 경제적 영향, 환경 영향, 오용 가능성, 법적 문제, 윤리적 문제 다양한 측면을 다룬다. 특정 시스템의 사회적 영향을 추론하는 것이 기초 모델의 사회적 영향을 추론하는 것보다 더 쉽다는 점이 반복적으로 나타난다. 기초 모델의 변화무쌍한 성질로 인해, 그들이 제기하는 윤리적, 사회적 고려사항을 책임감 있게 예측하고 다루는 것이 중요하다.

기초 모델에 대한 연구와 배포는 구분되어야 한다. 대부분의 공개적인 정보는 학술 논문이나 데모를 통한 연구에 관한 것이다. 이런 지식의 생산은 중요하지만, 실제로 사회에 영향을 미치는 것은 모델의 배포이다. 배포는 새 제품, 예를 들어 GitHub의 Copilot 같은 것을 통해 이루어지거나 기존 제품을 업그레이드하는 형태로 일어난다. 연구 모델은 광범위한 테스트 없이 알려지지 않은 실패를 가질 수 있어, 배포에 적합하지 않다는 경고를 요구하며, 실제로 사람들에게 영향을 주는 모델은 엄격한 테스트와 감사가 필요하다.

기초 모델의 연구와 배포를 이해하려면 데이터 생성부터 실제 배포에 이르는 전체 생태계를 고려해야 한다. 기초 모델은 AI 시스템의 한 부분이며, 사회적 영향을 고려할 때 사람들이 파이프라인의 양 끝에 위치해 있다는 것은 중요하다. 이러한 관점을 통해, 기초 모델에 대한 다양한 질문들이 실제로는 다른 단계에 대해 답변되어야 함을 알 수 있다.

1. **Data creation:** 데이터 생성은 사람 중심의 과정으로, 모든 데이터는 사람에 의해 만들어지고 대부분 사람에 대한 정보를 담고 있다. 이는 이메일, 기사, 사진 등을 통한 정보 제공이거나, 사람이나 그들의 환경에 대한 측정일 수 있다. 모든 데이터는 소유자가 있으며 특정 목적을 위해 생성되며, 이 목적은 기초 모델 학습을 포함할 수도, 포함하지 않을 수도 있다.
2. **Data curation:** 데이터는 데이터세트로 정리되는데, 이 과정은 선택과 후처리 필터링이 필요하다. 데이터의 관련성과 품질을 보장하면서 법적, 윤리적 제약을 준수하는 것은 중요하지만 어렵다. 이 점은 산업에서는 인식되고 있지만, AI 연구에서는 충분히 인식되지 않고 있다.
3. **Training:** 정리된 데이터셋에서 기초 모델을 학습시키는 것은 AI 연구의 중요한 단계이지만, 이는 전체 과정 중 일부일 뿐이다.
4. **Adaptation:** 기계 학습 연구에서의 적응은 특정 작업을 수행하는 새 모델을 생성하는 것이다. 배포를 위한 적응은 다양한 모듈, 사용자 정의 규칙, 분류기 등을 필요로 하는 시스템을 만드는 것이다. 예를 들어, 유해한 콘텐츠를 생성할 수 있는 모델도 적절한 예방 조치가 취해진다면 문제가 되지 않는다. 이러한 추가적인 응용 특화 로직은 해를 줄이는 데 중요하다.
5. **Deployment:** AI 시스템이 사람들에게 배포될 때 직접적인 사회적 영향이 발생한다. 논란의 여지가 있는 데이터를 기반으로 한 잠재적으로 해로운 기초 모델을 배포하길 원치 않지만, 이를 연구에 사용하여 과학적 이해를 향상시키는 것에는 가치가 있을 수 있다. 대규모 배포에서는 점진적으로 릴리스를 실시하는 것이 표준적인 관행이며, 이는 잠재적인 해를 부분적으로 완화할 수 있다.

이 보고서는 기초 모델에 대한 것이지만, 파이프라인의 다른 단계에서의 결정으로 인한 영향을 간과할 수 없다. 모든 단계에서 주의 깊은 모니터링과 개입이 필요하다. 대형 조직이 전체 파이프라인을 소유할 수 있지만, 각 단계는 다른 조직이 수행할 수 있다. 예를 들어, 응용 프로그램 개발자가 사용할 수 있는 맞춤형 기초 모델을 만드는 전문 회사가 될 수 있다.

**Think ecosystem, act model.** 사회적 영향은 전체 생태계에 따라 달라지지만, 많은 연구자와 실무자가 학습 단계에 집중하고 있기 때문에 기초 모델의 사회적 함의를 이해하는 것이 중요하다. 이는 기초 모델이 완성되지 않은 중간 단계이며, 예측하지 못한 목적으로 다른 엔티티에 의해 다양하게 적용될 수 있기 때문에 어렵다. 이를 위해 필요한 것은 잠재적인 downstream 평가를 대표하는 대리 메트릭과 이러한 메트릭을 문서화하는 데의 헌신이다. 이는 다양한 downstream 사용 사례에 적응할 수 있는 금속이나 플라스틱 같은 재료의 데이터 시트와 유사하다.

기초 모델의 잠재적인 사회적 영향을 파악하는 것은 기술 생태계와 사회에 대한 깊은 이해를 필요로 하며, 도전적이다. 모델의 배포 방식을 이해하지 않고서는 그 해를 완전히 평가할 수 없으며, 사회적, 역사적 맥락을 고려하지 않고서는 자동 메트릭을 정의할 수 없다.

### The future of foundation models

foundation model들은 많은 잠재력을 가지고 있지만, 아직 초기 단계이고 완전히 이해되지 않고 있다. 모델이 안전하게 배포될 수 있는 시점이나, 방법론적 위반에 대한 대응 등에 대한 합의가 부족한 상태이다. 그래서 foundation model의 미래는 불확실하며, 이를 결정할 주체가 누구인지는 아직 미지수이다.

**Disciplinary diversity.** foundation model의 기술은 여러 분야에서 수십 년 동안의 연구를 기반으로 하며, 이러한 기여는 학계와 산업 연구소 모두에서 이루어졌다. 그러나 foundation model을 직접 구축하는 연구는 주로 Google, Facebook, Microsoft, Huawei와 같은 대형 기술 회사와 OpenAI, AI21 Labs와 같은 스타트업에서 이루어졌다. AI2는 이러한 흐름에서 예외적인 경우이다.

기술의 빠른 발전과 중앙집중화로 인한 문제는 기술자뿐만 아니라 인문학자와 사회 과학자의 주목을 필요로 한다. 기술 개발 초기 단계부터 사회적 고려사항과 윤리적 디자인을 반영해야 한다. 학문적 다양성이 문제 해결에 중요하므로, 학계는 foundation model의 개발과 그 생태계에 대한 결정 과정에서 핵심적인 역할을 할 것으로 보인다. 이는 사회적 이익을 증진하고 해를 완화하는 데 필요한 과정이다.

**Incentives.** foundation model의 설계, 개발, 배포는 모든 단계에서 결정을 내리는 데 인센티브 구조를 제공한다. 상업적 인센티브는 사회적 이익과 일치할 수 있지만, 시장 실패와 혁신 가치를 확보할 수 없는 영역에서의 투자 부족을 초래할 수도 있다. 특히, 빈곤하고 소외된 사람들을 위한 기술에 대한 투자 인센티브는 부족하며, 사회적 외부성을 무시하는 경향이 있다. 또한, 넓은 참여를 장려하는 foundation model의 개방적이고 분산화된 생태계를 만드는 것에 대한 인센티브는 거의 없다.

대학의 깊이 뿌리내린 연구 사명은 지식의 생산과 전파, 그리고 글로벌 공공재의 창출이다. 이러한 사명으로 인해 학계는 산업계에서는 우선순위를 두지 않을 수 있는, 사회적 이익을 가져올 수 있는 방향의 foundation model 개발을 주도할 수 있는 독특한 위치에 있다고 봅니다.

**Loss in accessibility.** 접근성의 감소로 인해 학계는 완전히 참여하지 못하였다. 딥러닝 혁명의 한 결과는 재현성과 공개 과학의 증가였다. 코드와 데이터셋 공개가 표준화되었으며, TensorFlow와 PyTorch 같은 패키지는 협업을 용이하게 했다. ML Reproducibility Challenge 등의 이니셔티브와 재현성 체크리스트, CodaLab Worksheets 같은 플랫폼은 재현성 표준을 향상시켰고, 이로 인해 기술 혁신과 진보가 크게 증가하였다.

foundation model은 긍정적인 과학 공개 추세를 되돌리고 있다. 일부 모델(GPT-3 등)은 전혀 공개되지 않으며, 심지어 데이터셋도 공개되지 않는다. 학습 모델은 사용할 수 있지만, 높은 계산 비용과 복잡한 엔지니어링 요구사항으로 인해 대다수 AI 연구자들은 실제 foundation model 학습을 수행할 수 없다.

학계 예산 내에서 작은 모델을 학습시키면서도 의미 있는 연구를 할 수 있다. 스케일링 법칙에 따라 양적인 차이(예: 정확도 상승)를 보이는 경우에는 이런 방식이 실행 가능하다. 그러나 foundation model의 특성상, 문맥 내 학습 같은 기능은 충분한 크기의 모델에서만 나타나므로, 올바른 질문을 하려면 모델의 스케일이 필요하다.

공개된 모델을 연구하는 것은 유용하며, 이는 NLP 내에서 큰 부분집단을 만들어냈다. 기존 모델에 접근하는 것은 downstream 응용 프로그램을 지원하거나 결함을 찾는 데 도움이 되지만, 이것만으로는 결함을 수정하는 더 나은 구조나 학습 목표를 가진 foundation model을 만드는 데는 부족하다. 사회적 인식과 윤리적 설계를 모델에 불어넣는 필요성을 감안하면, 필요로 하는 foundation model은 현재와 매우 다를 수 있으며, 이는 대규모 실험을 요구한다.

EleutherAI와 Hugging Face의 BigScience 프로젝트 같은 커뮤니티 노력들이 큰 foundation model을 학습하려 하지만, 산업과 공개 커뮤니티 사이의 모델 학습 능력 격차는 계속 커질 것이다. 스타트업들이 더 많은 자원을 활용해 큰 모델을 학습할 수 있지만, 대형 기술 회사들은 시장 위치로 인한 인프라, 사용자, 데이터 등의 자원이 훨씬 많다. 이로 인해 foundation model 개발에 대한 진입 장벽은 더욱 높아져, 심지어 빠르게 대응하는 스타트업들조차 경쟁하기 어려워질 것이다. 이는 검색 엔진 개발 추세에도 반영되어 있다.

자원 격차를 줄이기 위해, 정부가 공공 인프라에 투자하는 방법을 고려할 수 있다. 허블 우주 망원경과 대형 하드론 충돌기 같은 빅 사이언스 프로젝트를 본받아, 컴퓨팅 인프라를 구축하면 foundation model에 대한 학계 연구에 큰 도움이 될 것이다. 미국에서는 이런 방향으로 National Research Cloud 이니셔티브를 시작하였다.

volunteer 컴퓨팅을 활용하는 것은 또 다른 접근법이다. 이 방법은 수십억 개의 컴퓨팅 장치가 중앙 서버에 연결하여 계산을 제공한다. Folding@home 프로젝트는 이 방법을 단백질 동역학 시뮬레이션에 성공적으로 적용했고, 최근에는 Learning@home 프로젝트가 foundation model 학습에 이를 활용하려고 하고 있다. 그러나 노드 간의 고지연 연결과 고대역폭 요구 사항은 이를 어렵게 만드는 기술적인 도전 과제이다.

**Summary.** foundation model의 능력과 규모를 확장하는 것에 대한 경제적 동기로 인해 다음 몇 년 동안 기술적 발전이 계속될 것으로 예상된다. 그러나 대부분의 행동이 신흥적인 행동에 의존하는 이러한 기술이 널리 배포될 적합성은 불확실하다. 신중해야 하며, 지금이 foundation model의 책임 있는 연구와 배포를 가능하게 하는 전문적인 규범을 세우는 시기이다. 이를 위해 학계와 산업계가 협력해야 하며, foundation model의 개발과 배포에 대한 기술적이고 윤리적인 지침을 제공해야 한다.

### Overview of this report

2021년 3월, 스탠포드 대학에서는 foundation model에 대한 다양한 관심을 가진 학생, 교수, 연구자들의 커뮤니티를 만들었다. 이 커뮤니티는 AI 연구, 의료와 법률 등의 분야에서의 적용, 그리고 윤리와 경제와 같은 사회적 이슈에 대한 관심을 포괄하였다. 하지만 기술 이해와 윤리적 문제 등에 대한 상호 이해의 차이가 있었고, 이를 해소하기 위해 foundation model에 대한 전체적인 그림을 제공하며, 기회와 위험을 파악하고, 미래의 책임 있는 개발에 대한 비전을 설정하려는 노력을 하였다.

이 보고서는 100명 이상의 다양한 배경의 사람들이 모여 foundation model의 여러 측면을 다루는 실험적인 작업이다. 대부분 기존 연구를 조사하지만, 여러 논의를 통해 한 보고서로 통합하고 모든 학문 간 연결성을 강조하였다.

**Structure.** 이 보고서는 foundation model의 다양한 측면을 논의하는 26개의 섹션으로 구성되어 있다. 이들은 기능, 응용, 기술, 사회의 네 부분으로 나뉘어 있으며, 섹션 간 많은 연결성을 보여준다. 이 연결성은 기술과 기능이 실제 사회적 고려사항에 민감하게 반응하고 응용에서 영감을 얻는 통합적 접근법을 강조한다.

이 보고서는 foundation model에 대한 중요한 주제들을 대부분 다루려고 노력했지만, 이 분야가 빠르게 발전하므로 불가피하게 불완전하게 남을 것이다. 일부 응용 분야(예: 자연 과학, 음악, 금융, 농업)는 포함되지 않았지만, 논의된 분야만큼 영향을 받을 가능성이 있다. 또한, foundation model이 신경과학, 인지과학, 심리학 등과 어떻게 연관되는지 연구하는 것도 흥미롭다.

#### Overview of capabilities.

foundation model들은 다양한 능력을 키워 응용 프로그램을 지원한다. 다양한 모달리티 처리, 물리적 세계에의 영향, 추론 수행, 사람과의 상호작용 등 다섯 가지 잠재 능력을 논의하였다. 마지막으로, 이들 능력의 잠재적 한계에 대한 철학적 논의로 마무리하였다.

**§2.1: Language.** 자연어 처리 분야는 foundation model의 선구자 역할을 하였다. 이 모델들이 표준 벤치마크에서 선도적이지만, 현재 모델의 능력과 언어가 인간 커뮤니케이션과 사고의 복잡한 시스템을 대표하는 능력 사이에는 차이가 있다. 이에 대응해, 언어의 다양성을 강조하였고, 아동의 언어 습득이 foundation model 학습보다 효율적임을 지적하며, 텍스트 외의 신호와 그라운딩이 이 차이를 줄일 수 있음을 검토하였다. 이러한 언어의 특성은 미래의 foundation model 연구 방향을 제시한다.

**§2.2: Vision.** 컴퓨터 비전 분야는 AI에서 딥러닝 적용을 선도하였고, 대규모 주석 데이터셋에 사전 학습된 모델이 다양한 환경에 적용될 수 있다는 것을 보여주었다. 지금은 웹 규모의 raw 데이터에 사전 학습하는 것이 컴퓨터 비전에서 foundation model의 성장을 이끌고 있다. 이 모델들은 표준 작업에 대해 유망한 결과를 보여주며, multimodal과 실제 데이터에 대한 학습은 중요한 도전 과제에 대한 진전을 가능하게 한다. 또한 모델링과 평가의 주요 도전과제, 응용 사례, 사회적 고려사항을 논의하며, 이들이 앞으로 컴퓨터 비전을 위한 foundation model의 영향을 결정하는 데 중요한 역할을 할 것이다.

**§2.3: Robotics.** 로보틱스 연구의 목표는 다양한 환경에서 다양한 작업을 수행할 수 있는 "generalist" 로봇 개발이다. 언어와 비전 분야에서는 풍부한 원시 데이터를 활용한 foundation model이 주도적인 역할을 하고 있지만, 물리적 세계에 연결된 로보틱스는 특별한 도전과제에 직면하고 있다. 로보틱스를 위한 새로운 유형의 foundation model 개발의 핵심 도전은 학습에 적합한 충분한 데이터를 확보하는 것이다. 이를 위해 특정 환경에 한정되지 않는 다양한 데이터와 모달리티를 활용하는 방안을 탐구하고 있다. 이러한 새로운 로봇 foundation model은 작업 지정과 학습을 용이하게 하며, 새로운 응용 분야를 도입하고, 안전성의 중요성을 높일 것으로 기대된다.

**§2.4: Reasoning and search.** AI의 오랜 과제인 정리 증명이나 프로그램 합성같은 추론 및 검색 문제는 전통적인 검색 방법으로는 해결이 어렵다. 하지만 사람들은 직관적으로 작동하며, 작업 간 지식을 전달하여 효율적인 적응과 추상적인 추론을 가능하게 한다. 이러한 점에서 foundation model은 이 차이를 줄일 수 있는 가능성을 제시하며, 다목적성과 강력한 생성 및 multimodal 능력을 통해 복잡한 검색을 제어하는 새로운 방법을 제공한다.

**§2.5: Interaction.** foundation model은 AI 시스템의 개발 및 사용 경험을 혁신적으로 변화시킬 수 있는 잠재력을 가지고 있다. 이 모델들은 적응에 있어서의 효율성으로 AI 응용 프로그램 개발의 난이도를 낮추고, multimodal 및 생성 능력으로 새로운 사용자 상호작용의 가능성을 높인다. 이러한 특성은 개발자들이 사용자의 필요와 가치에 더욱 부합하는 응용 프로그램을 제공하고, 동적인 상호작용과 피드백 기회를 확장하는 데 도움이 될 것이다.

**§2.6: Philosophy of understanding.** foundation model이 학습 데이터에 대해 어떤 이해를 가질 수 있는지에 대해, 자연어를 중심으로 다양한 입장을 탐색하였다. 특히 multimodal 데이터에 학습된 모델의 경우, 미래의 foundation model이 자연어를 이해할 수 있다는 점에 대한 회의론은 성급할 수 있다는 결론을 내렸다.

#### Overview of applications.

현재, foundation model 연구는 주로 컴퓨터 과학과 AI 분야에 집중되어 있지만, 앞으로는 기술 산업을 넘어 다양한 분야에서 AI의 영향력을 확장시킬 잠재력이 있다. 이를 위해, 사회의 핵심 분야인 건강보험, 법률, 교육을 중점으로 살펴보았다. 이러한 영역에서 foundation model을 성공적으로 적용하기 위해서는 특정 능력과 기술 혁신이 필요하며, 데이터, 보안, 해석 가능성, 공정성, 윤리 등의 사회 기술적 문제를 주의 깊게 다루어야 합니다.

**§3.1: Healthcare and biomedicine.** 건강관리와 생물의학 분야는 전문 지식이 필요하며, 이는 제한적이고 비싸다. foundation model은 다양한 형태의 데이터를 활용하여 이러한 영역에서 큰 기회를 제공하며, 전문가의 시간과 지식의 비용을 줄이는 데 도움이 될 수 있다. 하지만, 이러한 모델들은 의료 데이터의 역사적 편향을 악화시키는 등의 위험을 내포하고 있다. 이 잠재력을 책임감 있게 활용하기 위해서는, 데이터, 개인 정보 보호, 모델의 해석 가능성과 설명 가능성 등의 사회 기술적 문제를 깊게 이해하고 적절한 규제가 필요하다.

**§3.2: Law.** 법률 분야에서는 변호사들이 긴, 일관된 서술을 읽고 생성해야 하는데, 이것은 변화하는 맥락을 포함하고 모호한 법률 표준을 해독해야 하는 작업이다. foundation model은 이런 작업에 잘 맞는 생성 능력과 법률 문서라는 풍부한 데이터 덕분에 이 분야에서 유용할 수 있다. 그러나, 다양한 정보 출처를 신뢰할 수 있게 처리하고, 정확한 장문의 문서를 생성할 수 있도록 모델을 개선하는 것이 필요하다. 또한, 개인 정보 보호, 행동의 출처, 생성의 사실성 등에 대한 깊은 고려가 필요하며, 이런 문제들은 foundation model의 핵심 한계를 강조하고 있다.

**§3.3: Education.** 교육은 복잡한 분야이며, 효과적인 교육은 학생의 인식과 목표를 반영해야 한다. foundation model은 교육 데이터를 종합적으로 활용하여 교육에 적용될 수 있는 AI를 제안한다. 이 모델이 교육능력을 향상시킨다면, 문제 생성이나 교사 피드백 등의 새로운 응용 프로그램이 가능해질 것이다. 또한 이는 개인화된 학습과 적응 학습을 강화시킬 수 있다. 하지만, 이러한 기술 적용에는 학생 정보의 개인화, 기술 접근 불평등, 표절 등의 문제도 함께 고려해야 한다.

#### Overview of technology.

더 나은 모델 구조를 만들고, 학습 및 적응 과정을 향상시키며, 시스템을 확장하는 기술에 대해 논의하려 한다. 데이터의 출처와 구성에 대한 이해, 분포 변화에 대한 강건성 및 공격자에 대한 보안, 그리고 수학적이나 경험적 관점에서 foundation model의 작동 원리에 대한 이해가 중요하다.

**§4.1: Modeling.** foundation model을 만드는 데 기여하는 구조적 속성에는 계산 모델의 표현력과 확장성이 있으며, 이는 대부분의 foundation model에서 사용하는 transformer 네트워크를 통해 실현된다. 다음 세대 모델에 필요한 속성으로는 다양한 출처와 도메인의 콘텐츠를 처리하는 다중 모달리티, 획득한 지식을 저장하고 검색하는 메모리 용량, 그리고 새로운 환경에 성공적으로 적용하는 구성성이 있습니다. 이러한 요소들이 foundation model의 전체 잠재력을 실현하는 데 중요하다.

**§4.2: Training.** 학습 목표는 모델이 학습 데이터로부터 학습하고 능력을 얻는 방법을 수학적으로 정의한다. 현재 foundation model 학습은 대부분 직관적으로 선택된 모달리티 특정 목표를 사용한다. 그러나 미래의 foundation model 학습은 체계적인 증거와 평가에 기반한 선택과, 다양한 데이터 소스와 모달리티에 걸쳐 풍부하고 확장 가능한 학습 신호를 제공하는 방식을 반영할 것으로 예상된다. 또한 생성적 대 비판별적 학습, 입력 데이터 표현의 선택 등의 디자인 상의 타협점과 목표의 명시적 표현을 포함하는 미래의 학습 목표의 가능성에 대해서도 논의된다.

**§4.3: Adaptation.** foundation model은 일반적으로 특정 작업에 맞게 적응이 필요한 미완성의 중간 자산이다. 현재는 미세 조정이 주로 사용되지만, 경량 미세 조정 대안과 프롬프팅 기반 방법이 효율성과 정확성을 균형있게 달성할 수 있다는 연구 결과도 있다. 미래에는 foundation model의 결함을 완화하거나 제약조건을 도입하는 등, 적응의 넓은 시각이 필요할 것으로 보인다. 이는 새로운 평가 프로토콜이 필요하게 되며, 이를 통해 적응 방법을 체계적으로 평가하면서 자원과 접근 요구 사항을 통제할 수 있다.

**§4.3: Adaptation.** 평가는 foundation model의 진행 상황을 추적하고, 모델을 이해하며, 능력과 편향을 기록함으로써 맥락을 제공한다. 그러나 foundation model은 특정 작업에서 한 단계 떨어져 있어 표준 기계 학습 평가 패러다임의 한계를 드러낸다. 이를 해결하기 위해, foundation model의 본질적 능력을 측정하고 학습 방식을 이해하는 평가, 적응 자원과 접근을 통제하여 과제 특정 모델을 평가하는 방법, 그리고 정확성 이상의 맥락을 제공하는 평가 디자인(강건성, 공정성, 효율성, 환경 영향 등)을 논의한다. 평가 관행의 개혁을 통해, 다양한 목표와 이해관계자를 충족시키는 평가가 가능해질 것이다.

**§4.5: Systems.** 학습 데이터는 foundation model에 대한 이론적 정보를 제공하고, 모델 아키텍처와 학습 목표는 이 정보의 추출 가능성을 결정한다. 컴퓨터 시스템은 이러한 것들을 실제로 실행할 수 있는지를 결정하며, 데이터와 모델 크기 측면에서 스케일링의 주요 제한 요소이다. 다음 세대의 foundation model을 효율적으로 학습하기 위해 알고리즘, 모델, 소프트웨어, 하드웨어의 공동 설계가 필요하며, 이런 과정은 이미 다양한 형태로 진행 중이다. 또한, foundation model 위에 응용 프로그램을 배포하는 것에 필요한 요소도 고려하고 있다.

**§4.6: Data.** 데이터는 foundation model의 생명력으로, 모델이 획득할 수 있는 능력을 결정한다. 최근 데이터 중심의 AI 요구사항은 데이터 관리와 이해, 문서화의 중요성을 강조하며, foundation model에 대한 투명성 부족 문제를 지적한다. 이를 해결하기 위해, 데이터 시각화와 관리 연구를 기반으로 foundation model을 위한 데이터 허브를 제안하며, 이는 선택, 큐레이션, 문서화, 접근, 시각화와 검사, 품질 평가, 법적 규제 등의 데이터 중심 고려사항과 관련이 있다.

**§4.7: Security and privacy.** 현재 foundation model의 보안과 개인정보 보호는 대부분 미개척 상태이다. 이 모델들은 고위험의 단일 실패 지점으로, 다양한 보안 취약점과 개인정보 보호 위험이 존재한다. foundation model의 일반성은 이러한 문제를 확대시키며, 이를 안전한 foundation model로 보완하는 방향으로 논의하고 있다. 또한, 공개 데이터에서 지식을 전송함으로써, foundation model은 개인정보 보호 응용 프로그램의 정확성 저하를 줄일 수 있다.

**§4.8: Robustness to distribution shifts.** 표준 머신러닝의 한계는 학습 분포와 테스트 분포가 일치하지 않을 때 강인하지 않은 모델을 생성한다는 것이다. 기존 연구에서는 레이블이 없는 다양한 데이터에 학습된 foundation model을 적응시키면 다양한 변화에 대한 강인성이 향상된다고 보여준다. 하지만, foundation model이 강인성에 대한 만병통치약이라고는 생각하지 않으며, 시간에 따른 extrapolation과 허위 상관관계 같은 문제는 완전히 해결되지 않을 것으로 예상한다.

**§4.9: AI safety and alignment.** foundation model이 신뢰성 있고, 강인하며, 해석 가능해야 하는 것이 점점 더 중요해지고 있다. 또한, 모델 능력이 발전함에 따라 foundation model과 큰 규모의 위험, 위험 요소, 피해 사이의 관계를 고려해야 한다. 예를 들어, foundation model을 명확하지 않은 목표나 가치로 배포하지 않도록 정렬하는 것이 중요하며, foundation model의 긴발적인 행동을 예측하는 것이 특정 작업에 대한 적응을 복잡하게 만들 수 있다. 이는 해석 가능성 또는 평가에 대한 새로운 접근 방식을 필요로 한다.

**§4.10: Theory.** 학습 이론은 적용 머신러닝의 다양한 맥락에 대한 폭넓은 기초를 제공한다. 현재 foundation model의 연구는 대체로 경험적이며, 표준 감독 학습 이론이 foundation model을 완전히 설명하기에는 부족하다. 특히, 학습 단계와 적응 단계 사이의 차이는 기존 이론의 불충분함을 보여주는데, 이는 이 단계들이 완전히 다른 작업과 데이터 분포를 대응할 수 있음을 의미한다. 그러나 이 차이를 해결하기 위한 이론적 발전은 제한된 설정에서도 유용한 인사이트를 제공할 것으로 기대하고 있다.

**§4.11: Interpretability.** 해석 가능성은 foundation model의 이해를 돕는 중요한 요소이다. 이는 모델의 행동을 해석하고 설명하는 데 필요하며, 특히 다양한 작업에 유익하고 예상치 못한 특성을 가진 모델의 특성 때문에 중요하다. foundation model과 그 파생 모델 사이의 의사결정 구성 요소를 공유하는 정도를 결정하는 "the one model-many models" 패러다임을 제안한다. 또한, 모델이 생성하는 설명의 타당성과 모델 행동을 이끄는 메커니즘에 대해서도 더 깊이 논의한다. 이 모든 것을 통해 foundation model의 해석 가능성과 그 사회적 영향에 대한 평가를 마무리한다.

### Overview of society.

foundation model의 발전은 다양한 분야에 적용되며, 이로 인해 사회에 큰 영향을 미칠 것으로 예상된다. 이러한 AI 모델들이 흥미롭지만 동시에 고민거리인 이유는 과제에 대한 중립성 때문이다. 특정 시스템의 사회적 영향을 이해하는 것은 상대적으로 쉽지만, foundation model을 개발하면서 가능한 모든 시스템과 사용 사례의 사회적 영향을 어떻게 고려할지는 복잡한 문제이다.

**§5.1: Inequity and fairness.** 기계 학습은 종종 사회적 불평등을 증폭시키는 경향이 있다. foundation model은 이러한 문제를 확대할 수 있으며, 이는 역사적으로 차별 받은 사람들에게 더욱 불공정한 상황을 만들 수 있다. foundation model은 사용자에게 영향을 미치는 응용 프로그램에 적응하도록 설계된 중간 자산으로, 이로 인해 편향과 해가 발생할 수 있다. 이러한 문제를 해결하기 위해, 다양한 원인을 분류하고, 기술적인 개입과 반응적인 구제를 동시에 고려하며, 불공정함이 foundation model 패러다임에서 불가피하지 않다고 주장한다.

**§5.2: Misuse.** foundation model의 오용은 기술적으로 의도된 방식으로 이를 사용하지만, 사회적 해를 끼치는 목표(예: 디스인포메이션 생성, 딥페이크 개발 등)를 가지고 이루어진다. foundation model의 발전은 오용을 위한 더 높은 품질의 기계 생성 콘텐츠를 더 쉽게 만들고 개인화하는 것을 가능하게 한다. 이는 기존의 해로운 콘텐츠 감지 방법을 제한할 수 있지만, foundation model 자체가 자동 오용 감지의 가능성을 제공할 수 있다.

**§5.3: Environment.** foundation model은 계산 비용이 많이 드는 학습 과정에서 생성되며, 이로 인해 대기 중에 탄소가 더 많이 방출되고 환경이 저하된다. 현재의 논의는 큰 학습 비용과 이러한 비용을 반복 사용에 분산시킬 수 있는 가능성에 초점을 맞추고 있다. 이에 대해, 환경적 영향을 계산하는 가정을 식별하여 이 논의를 명확히 하려고 한다. 또한, foundation model의 환경적 영향을 줄이기 위해 더 효율적인 모델과 하드웨어, 에너지 그리드의 필요성, 환경 비용을 평가 요소로 포함시키는 것, 그리고 환경 영향에 대한 cost-benefit 분석을 위한 더 큰 문서화와 측정의 필요성을 주장한다.

**§5.4: Legality.** 현재 foundation model은 불확실한 법적 상태에 있으며, 이 모델의 개발과 사용에 대한 법적 영향은 대체로 불명확하다. AI 기술과 특히 foundation model에 대한 법률 및 규제 체계가 필요하며, 이는 연구, 개발, 배포의 관행을 제어하고 촉진하는 데 중요하다. 알고리즘 도구에 대한 법적 판단이 불확실한 미국을 중심으로, 모델 예측의 책임과 모델 행동에 대한 보호 문제가 중요하다는 것을 강조하며, 이 두 문제를 해결하기 위해 법적 기준이 발전해야 한다고 설명하고 있다.

**§5.5: Economics.** foundation model은 그들의 혁신적인 능력과 다양한 분야에서의 잠재적 응용으로 인해 큰 경제적 영향을 미칠 것으로 예상된다. 이는 생산성, 임금 불평등, 소유권 집중 등의 측면에서 미국 및 전 세계 경제의 미래에 영향을 미칠 것이다.

**§5.6: Ethics of scale.** foundation model의 널리 퍼진 적용은 불평등 증가의 위험 외에도 다른 윤리적, 정치적, 사회적 우려를 불러일으킨다. 이에는 응용 규모와 관련된 윤리적 문제인 동질화와 권력의 집중, 그리고 이를 해결하기 위한 적절한 규범과 출시 전략이 포함된다.

---

## CAPABILITIES

foundation model은 학습 과정에서 생겨난 능력을 통해 다양한 응용 프로그램을 지원한다. 이에는 언어와 시각 능력, 물리적 세계에 영향을 미치는 능력, 추론 및 검색을 수행하는 능력, 그리고 인간과의 상호 작용 능력이 포함되며, 이 모든 것은 자기 감독이라는 기술적 접근법과 철학적으로 연결된다.

### Language

#### The nature of human language.

언어는 인간의 사고, 사회적·감정적 관계 형성, 자아식별, 지식 기록 및 사회적 지능 발전에 중추적인 역할을 한다. 모든 인간 사회에서 발생하는 말하거나 수화하는 언어는 놀라운 다양성과 풍부함을 보여준다. 언어는 복잡하면서도 효율적인 시스템이며, 어린이들은 이를 짧은 시간 동안 습득한다. 이러한 언어의 중요성 때문에, 자연어 처리(NLP)는 인공지능 연구에서 핵심 요소로, 컴퓨터가 인간 언어를 이해하고 생성하는 능력을 부여하는 것을 목표로 한다.

2021년까지, 자연어 처리(NLP)는 foundation model에 큰 영향을 받았다. 첫 세대 foundation model들은 다양한 언어 능력과 광범위한 언어 상황에 대한 적응성을 보였다. 2018년 초기 foundation model인 ELMo와 BERT 소개 이후, NLP 분야는 foundation model을 중심으로 발전하였고, 일반화된 언어 학습을 주요 목표로 삼았다. 이에 따라, foundation model이 언어용 머신러닝 모델 학습의 전반적인 과정을 변화시키며, 보다 넓은 범위의 언어와 복잡한 언어 상황에 적용될 때 직면하는 도전에 대해 논의하고 있다.

#### Impact of foundation models on NLP

foundation model들은 NLP 분야에 큰 영향을 미치고 있으며, 뛰어난 언어 생성 능력을 갖추고 있다. 하지만 그들의 가장 큰 특징은 원시적인 생성 능력이 아니라 놀라운 일반성과 적응성으로, 단일 foundation model이 다양한 방식으로 적응되어 여러 언어 작업을 수행할 수 있다는 것이다.

자연어 처리(NLP) 분야는 전통적으로 복잡한 언어 작업을 위한 시스템을 정의하고 구축하는 데 초점을 맞추었다. 이러한 작업에 능숙한 모델이 downstream 응용 프로그램에 대한 유능한 언어 시스템이 될 것이라는 전망이었다. NLP 작업은 문장이나 문서를 분류하는 작업, 시퀀스 라벨링 작업, 범위 관계 분류, 그리고 입력에 기반한 새로운 텍스트를 생성하는 작업 등을 포함하며, 과거에는 각 NLP 작업에 대해 고유한 연구 커뮤니티가 작업 특정 아키텍처를 개발하였다.

현대적인 접근법은 하나의 foundation model을 사용하고, 각 작업(감정 분류, 엔티티 태깅, 번역, 요약 등)에 특화된 소량의 주석이 달린 데이터로 약간 수정하여 적응 모델을 만드는 것이다. 이 방식은 대부분의 작업에서 특정 작업에 약간 적응한 foundation model이 특정 작업을 수행하기 위해 특별히 만들어진 이전 모델이나 모델 파이프라인을 크게 능가하는 것으로 입증되었다. 예를 들어, 2019년에는 적응된 foundation model이 NY Regents 8학년 과학 시험에서 91.6%를 기록하여 2018년의 73.1%보다 크게 향상되었다.

언어를 생성하도록 학습된 foundation model의 등장은 NLP에서의 언어 생성 역할에 중요한 변화를 가져왔다. 이전에는 일반적인 목적의 언어 생성이 매우 어려운 문제로 여겨졌지만, 현재는 "predict the next word in this sentence"와 같은 간단한 언어 생성 목표를 가진 foundation model을 학습시킬 수 있다. 이러한 생성 모델은 언어에 대한 기계 학습의 주요 수단이 되었으며, 요약과 대화 생성과 같은 언어 생성 작업에 대한 연구를 촉진하였다. 또한, foundation model 패러다임은 구어와 문어 모두에 걸쳐 비슷한 역할을 하게 되었으며, 대규모 음성 오디오 데이터셋에서 학습된 automatic speech recognition(ASR) 모델은 ASR 작업에 적응하게 되었다.

foundation model 패러다임의 변화로 인해, NLP 분야의 연구와 실무는 개별 작업을 위한 맞춤형 아키텍처 개발에서 foundation model을 최대한 활용하는 방향으로 전환되었다. 적응 방법에 대한 연구가 확대되었고, foundation model의 놀라운 성공으로 인해 foundation model을 분석하고 이해하는 연구에 대한 관심이 증가하였다.

#### Language variation and multilinguality.

foundation model은 사전 학습을 통해 얻은 언어 지식을 통해 다양한 작업을 수행할 수 있지만, 이 적응성에는 한계가 있다. 언어는 세계에 수천 가지가 넘는 다양한 언어, 한 언어 내의 다양성, 심지어 한 사람이 사용하는 언어의 변이 등 매우 다양하다. 이런 다양성을 공정하게 대표하고 각 언어의 독특함을 존중하고 정확하게 표현하는 foundation model을 만들 수 있는지는 여전히 해결해야 할 연구 과제이다. 그러나 언어 정보를 학습하고 유연하게 적응하는 능력을 가진 foundation model은 NLP를 더 많은 언어 다양성을 포괄하게 확장하는데 유망하다.

영어를 넘어 비영어 언어에 대한 성공을 확장하기 위해 다양한 언어를 지원하는 foundation model이 개발되었다. 대부분의 세계 언어는 대규모 foundation model을 학습시키기에 충분한 텍스트 데이터가 없지만, 이 문제는 여러 언어를 동시에 학습하는 다양한 언어를 지원하는 foundation model로 해결하려고 노력하고 있다. 이러한 모델은 언어 간에 공유되는 구조와 패턴을 바탕으로, 자원이 많은 언어에서 자원이 적은 언어로 지식을 전달하며, 이로 인해 독립 모델을 학습시킬 수 없는 언어에 대해서도 기초 모델을 가능하게 한다. 이런 접근 방식은 다양한 언어 간에 놀랄 만큼 많은 양의 지식 전달과 병렬 인코딩이 가능함을 실험적으로 입증하였다.

다양한 언어를 지원하는 모델이 얼마나 견고한지, 영어와 크게 다른 언어나 언어 자원이 적은 언어를 얼마나 잘 대표할 수 있는지는 아직 미해결된 문제이다. 이러한 모델들은 학습 데이터에서 가장 많은 자원을 가진 언어와 유사한 언어에서 더 높은 성능을 보이는 경향이 있다. 또한, 다양한 언어를 지원하는 모델에서 언어들이 모델 parameter를 경쟁하며, 이로 인해 하나의 모델이 얼마나 많은 언어 변이를 수용할 수 있는지는 불확실하다. 이런 문제는 학습 데이터의 불균형에서 기인하는데, 영어 데이터가 다른 언어에 비해 월등히 많고, 더 깨끗하며, 더 깊이 있는 언어적 복잡성을 보여주는 예시를 포함하고 있기 때문이다. 그러나 답은 단순히 더 균형잡힌 코퍼스를 만드는 것이 아니라, 불균형한 데이터에도 불구하고 언어 변이를 견고하게 처리하는 데에 있다.

현재의 다양한 언어를 지원하는 foundation model들은 언어의 미묘한 부분을 완전히 모델링하지 못할 수 있음에도 불구하고, 일부 다양한 언어 응용 프로그램에 유용하게 사용된다. 특히, 자원이 적은 언어에 대한 다양한 언어 모델을 적용하는 데 효과적이다. 그러나 연구 커뮤니티는 foundation model이 언어 변이를 어떻게 처리하는지, 그리고 NLP에 공정성과 대표성을 어떻게 가져오는지에 대해 비판적으로 검토해야 하며, 언어 변이를 지우고 학습 데이터의 언어적 다수에 부합하는 foundation model을 단순히 추진하는 것에 안주해서는 안 된다.

#### Inspiration from human language acquisition.

foundation model들은 인간처럼 행동하는 NLP 시스템을 만드는 데 큰 진전을 이루었지만, 그들이 습득하는 언어 시스템과 학습 과정은 여전히 인간의 언어와 중요한 차이를 보인다. 이 차이점의 영향을 이해하는 것은 foundation model의 언어적 한계와 가능성에 대해 알고 있는 연구 커뮤니티를 발전시키는데 필요하다.

인간의 언어 습득은 매우 효율적인 반면, foundation model들은 인간보다 훨씬 많은 언어 데이터를 학습한다. 인간의 언어는 실제 세계에 근거를 두고 있지만, foundation model들은 원시적이고 근거 없는 텍스트의 분포 정보를 학습한다. 이 차이를 이해하고 근거 있는 언어 학습을 발전시키는 것은 foundation model 연구의 중요한 미래 방향이다. 또한, foundation model의 귀납적 편향과 인간의 마음의 귀납적 편향 사이의 관계를 조사하는 것도 중요한 연구 방향이다.

인간의 언어 습득은 체계적이고 일반화 가능한 시스템을 효율적으로 배우는 것이다. 반면, foundation model은 이러한 체계적 추상화를 항상 습득하지 않는다. 실제로, 모델이 한 번 언어 구조를 정확하게 생성했다 해도, 특히 주제가 크게 변했을 때 그 구조의 일관성이 보장되지 않는다. 따라서, NLP는 foundation model에 대한 체계적인 언어 습득 방법을 개발하는 도전을 직면하고 있다.

인간의 언어 학습은 생애 동안 계속되고, 새로운 언어 상황에 유연하게 적응하며 언어 문법을 진화시킨다. 반면, foundation model의 언어 시스템은 학습 데이터에 의해 설정되며, 상대적으로 고정적이다. 대량의 학습 없이 foundation model의 언어적 기반을 바꾸는 방법은 아직 불확실하며, 이는 foundation model의 미래 연구 분야에서 중요한 과제이다.

foundation model들은 NLP 분야를 크게 변화시켰고, 많은 새로운 연구 방향을 제시하였다. 이들은 언어 생성의 이해, foundation model의 효과적인 활용 및 이해, NLP에서의 불평등 증가 가능성, 언어 변화와 다양성의 포괄, 그리고 인간의 언어 학습 동적을 활용하는 방법 등에 대한 연구를 촉진하였다. 그러나 foundation model의 성능과 복잡한 하류 환경에서의 유용하고 안전한 배포를 위한 요구 사항 사이에는 여전히 큰 차이가 있다.

### Vision

비전은 생물체가 환경을 이해하는 주요 방법 중 하나이다. 이를 기계에 적용하는 것은 어려운 문제로 여겨졌지만, 실제로는 AI에서는 어려운 문제가 쉽고, 쉬운 문제가 어렵다는 역설이 있다. 이 역설 중 가장 쉬운 문제는 매일 수 밀리초 동안 복잡한 장면을 해석하는 시각 능력이다.

컴퓨터 비전은 자율주행 차량, 의료 분야의 AI 도구, 멀티미디어 생성 및 편집 도구 등 혁신적인 응용 프로그램에 필수적이다. 이는 교통 체증 해소, 희귀한 의료 사건 감지, 차세대 멀티미디어 도구 개발 등에서 변화를 가져올 수 있음을 보여준다.

컴퓨터 비전 분야는 인간의 인지 능력에서 많은 영감을 얻는다. 여러 고전 이론들은 인간이 부분들을 더 큰 전체로 맥락화하여 실세계를 인식하며, 이는 컴퓨터 비전 기법이 물리적 세계를 점차 더 높은 수준의 추상화로 모델링하게 한다. 또한 인간의 시각은 본질적으로 신체화되어 있으며 상호작용적인 생태환경이 중요한 역할을 할 수 있다. 이러한 아이디어는 세계에 대한 맥락적이고 상호작용적인 인식을 향해 컴퓨터 비전 시스템의 지속적인 발전을 이끌고 있다.

컴퓨터 비전의 foundation model은 다양한 소스와 센서에서 얻은 원시 인식 정보를 시각적 지식으로 변환한다. 이는 ImageNet의 도입과 지도 학습 사전학습의 시작에 따른 딥 러닝 패러다임의 전환을 반영하며, 이는 고전적인 접근법을 넘어 대량의 데이터를 한 번에 학습하고 다양한 작업에 적용할 수 있는 모델로 전환하였다. 이런 아이디어는 여전히 foundation model의 핵심이다.

전통적인 지도 학습 기법의 한계로부터 foundation model이 등장하였다. 이는 비싼 비용과 세밀한 레이블링에 의존하는 대신, 대량의 원시 데이터를 활용해 시각적 세계를 이해하는 자기 지도 학습의 진보를 반영한다. 현재 비전 foundation model의 능력은 초기 단계에 있지만, 일반화 능력 향상 등의 전통적인 컴퓨터 비전 작업에서의 개선이 관찰되고 있다. 장기적으로 보면, foundation model은 명시적 주석의 의존성을 줄이고, 상식적 추론과 같은 핵심 인지 능력의 발전을 가능하게 할 수 있다. 이는 앞으로의 중요한 도전과 연구 전선을 정의하는 데 중요한 역할을 한다.

#### Key capabilities and approaches.

컴퓨터 비전은 기계가 시각적 세계를 이해하고 해석하는 능력을 부여하는 인공지능의 핵심 분야이다. 이는 이미지 분류, 객체 감지, 시맨틱 세그멘테이션 등의 시맨틱 이해 작업, 깊이 추정, 모션 구조 등의 기하학적 및 3D 작업, 그리고 시각적 질문 답변, 이미지 캡션 등의 다중 모드 통합 작업을 포함한다. 이 분야는 지난 수십 년 동안 지속적으로 발전해 왔다.

컴퓨터 비전 작업을 해결하는 주요 방식은 큰 데이터셋에서 모델을 사전 학습한 후, 작업 특정 데이터셋과 도메인에 맞게 모델을 미 조정하는 것이다. 이 접근법은 외부 감독 주석에 의하며, 이는 모델이 다양한 시각적 입력을 확장 가능고, 견고하고, 일반화 가능한 방식으로 캡처할 수 있는 한계를 제한한다. 이에 대한 대안으로, GAN 같은 비감독 학습 기술이 등장하였고, 이는 이미지 컬렉션만으로 고품질의 시각적 콘텐츠를 생성하는 방법을 배울 수 있다. 또한, 변이형 자동 인코딩, 대조 학습 등의 self-supervision을 사용하여 객체와 장면의 시각적 속성을 명시적인 감독 없이 추론하는 신경 모델도 발전하고 있다.

foundation model과 self-supervision은 큰 규모의 시각 데이터에서 학습을 가능하게 해, 범위와 다양성을 모두 증가시켰다. 이로 인해 이미지 분류와 객체 감지 등의 작업에서 향상된 성능을 보고하였고, 이는 학습 중 명시적인 주석 없이, 적응 중 더 큰 샘플 효율성을 보여준다. 또한 DALL-E와 CLIP 가이드 생성과 같은 시각적 합성에서 주목할 만한 발전이 있었다. 단기적으로, 학습 목표 개선과 아키텍처 설계 개선을 통해 foundation model의 능력이 계속해서 개선될 것으로 예상된다.

현재 컴퓨터 비전을 위한 foundation model은 초기 단계에 있지만, 물리적 장면 이해, 시각적 상식과 시간적 이벤트에 대한 추론, 사회적 affordance를 위한 지각 등의 고차 목표에 대한 진전을 보이고 있다. 이러한 작업은 대규모로 주석 처리하는 것이 어려워 도전적이지만, 명시적인 주석에 의존성을 줄이는 foundation model은 이러한 목표에 대한 더 많은 진전을 가능하게 할 수 있다. 언어 이벤트에 대한 상식을 어느 정도 포착한 언어 foundation model의 진전이 비슷한 능력을 시각 입력에 대해 달성하는 가능성을 보여주며, 새로운 아키텍처, 대규모 학습, self-supervision, few-shot 적응 체계의 결합은 이전에 도달하기 어려웠던 능력을 향해 문을 열 수 있다.

#### Central research challenges.

연구 과제는 foundation model이 비전 모델의 통합과 영향을 확대시킬 수 있는 응용 도메인에 초점을 맞추고 있다. 건강 관리와 가정 환경을 위한 주변 지능, 모바일 및 소비자 응용 프로그램, 실체화된 상호작용 에이전트 등이 주요 영역이다. foundation model은 인간 활동과 의료 이벤트의 세밀한 감지, 보조 상호작용의 개선에 잠재력을 가지며, 다중 모드 기반의 강화는 모바일 환경에서의 서비스 상호작용을 개선하고, 비전과 언어 입력에서의 생성 능력의 개선은 컴퓨터 사진술과 콘텐츠 편집에 이점을 줄 수 있다. 로봇 설정에서 이미 입증된 지각 모델은, 대규모의 시선 중심 비주얼 데이터 학습을 통해 비전 장면, 객체, 행동의 더 넓은 분포를 포착하여 진전을 촉진시킬 수 있다.

foundation model이 이러한 응용 설정에 얼마나 더 큰 영향을 미칠 수 있는지는 §2.2.1: 비전 능력에서 개요한 능력이 어느 정도 실현되는지에 달려 있다. 현재, 단기, 장기 예상 능력 사이의 큰 차이를 메우기 위해서는, 비전을 위한 foundation model의 현재의 한계, 그중에서도 그들의 학습과 평가를 다루어야 한다. 아래에는 해당하는 주요 도전 과제의 일부를 나열하였다:

**Semantic systematicity and perceptual robustness.** 인간은 보이지 않는 구성 요소에 대한 이해를 일반화하고, 새로운 객체와 장면의 물리적, 기하학적 특성에 대해 추론하는 능력을 가지고 있다. 현재 foundation model들은 이미지 합성과 세밀한 언어 입력에 대한 일반화에서 초기 성과를 보이고 있지만, 단순한 형태와 색상의 구성 요소에 대한 일반화는 여전히 어렵다. foundation model은 장면과 객체의 기하학적 이해에 대한 초기 단계를 보여주었으며, 다양한 모드(예: 오디오)의 지속적인 통합은 이러한 목표를 위해 유익할 수 있다. 그러나, 초기에 관찰된 능력을 인간 수준의 자연 장면과 객체에 대해 견고하게 일반화하는 기법은 여전히 개방된 연구 과제이다.

**Computational efficiency and dynamics modeling.** 인간은 이벤트의 동력학을 이해하기 위해 필요한 시각적 흐름을 놀랍도록 효율적으로 처리한다. 언어에 대한 foundation model들은 이벤트의 장기적일관성을 모델링하는 초기 단계를 보여주었으며, 이와 유사한 능력은 로보틱스 등의 다른 분야에도 이점을 줄 수 있다. 그러나 컴퓨터 비전 입력은 극도로 고차원적이며, 이를 처리하는 단순한 접근법은 제한적일 수 있다. 현재의 비전 모델들은 이미지 패치나 프레임 그룹을 요약하는 방식으로 이를 처리하고 있지만, 이는 세부적인 정보를 잃을 수 있다는 단점이 있다. 따라서, 원시 입력 공간을 고려하는 것 외에도, 비전을 위한 foundation model들은 효율적이고 효과적인 모델링을 위한 기본 아키텍처의 디자인을 재검토해야 할 필요가 있다. 또한, 이러한 모델들을 다양한 응용 분야에 적용하기 위해서는 시스템 디자인의 발전이 필요하다. 결국, 더 큰 규모의 동적 비전 입력을 효율적이고 효과적으로 모델링하는 것은 앞으로 해결해야 할 복합적인 연구 과제이다.

**Training, environments, and evaluation.** foundation model의 잠재력을 실현하기 위해서는 그들을 학습하고 평가하는 지원 요소가 중요하다. 현재의 비전 foundation model들은 주로 가장 접근하기 쉬운 RGB 이미지와 텍스트 데이터에 초점을 맞추고 있다. 이는 넓은 범위의 모달리티에서 다양한 입력을 수집한 대규모 학습 데이터셋의 개발을 촉진하고 있다. 입력의 품질은 모델의 학습 효율성에 영향을 미치며, 다른 유형의 foundation model을 활용하는 기법은 품질 향상에 약속적이다. 또한, 정적 데이터셋을 넘어 생태적 설정과 상호작용에 연결된 인간의 지각 이해를 고려해야 한다. 이를 위해, 물리적, 시각적, 생태적 현실성을 포착하는 시뮬레이션 환경의 지속적인 개발이 중요하다. 마지막으로, 생성적 foundation model 출력의 충실성을 어떻게 평가할지에 대한 메트릭 문제가 있다. 표준 메트릭들은 알려진 결함이 있으며, 인간의 판단을 평가에 포함하는 것도 한 가지 방법이지만, 비용이 많이 들고 확장성이 떨어질 수 있다. 이러한 비전 foundation model에 대한 학습, 데이터, 평가 설정의 미해결 과제와 도전은 앞으로 연구의 중심 분야가 될 것이다.

**Concluding remarks.** 이 섹션에서는 컴퓨터 비전과 관련된 foundation model을 탐구하였고, 그것들의 현재와 예상 능력을 맥락화하며, 앞으로의 연구 방향을 제안하였다. 컴퓨터 비전 기법의 발전은 사회적으로 파괴적인 영향력을 가질 수 있으며, 이에 따라 그 위험성을 신중하게 고려할 책임이 생긴다. 컴퓨터 비전 모델에서의 학습된 편향, 개인정보 보호와 감시에 대한 우려, 그리고 딥페이크 이미지와 오정보에 대한 위험은 foundation model의 중요한 문제로 지속적으로 논의되고 있다. 컴퓨터 비전과 foundation model에 대한 도전과 기회가 많지만, 이러한 위험을 동시에 다루는 것이 필수적이다.

### Robotics

로봇이 실제 세계의 다양한 조건을 처리할 수 있도록 하는 것은 로봇 연구의 주요 도전 과제입니다. 이를 위해 일반적인 로봇을 만들기 위한 foundation model의 아이디어가 중요하며, 이는 기존의 foundation model만으로는 충분하지 않다. 여기서는 로봇이 자신의 물리적 형태를 제어하여 다양한 작업을 성공적으로 수행하는 문제에 foundation model을 어떻게 적용할 수 있는지 중점을 두었다. 이는 고차원적이고 폐루프 결정 문제로, 로봇의 행동이 다음에 인식하는 것에 직접적으로 영향을 미친다. 이러한 새로운 유형의 로봇 foundation model은 제조, 건설, 자율 주행, 가정 도움, 개인 보조 등 일상 생활의 주요 측면을 향상시킬 로봇의 잠재력을 증폭시킬 수 있다. 이 논의는 주로 가정용 작업을 위한 이동 조작 로봇에 초점을 맞추고 있지만, 다른 로봇 사용 사례에도 적용 가능하다고 생각된다.

로봇학의 새로운 foundation model을 구축하는 중요한 단계는 작업 지정 및 학습에 대한 기회를 활용하고, 데이터 수집과 안전성, 견고성에 대한 도전을 동시에 다루는 것이다. 사용자가 로봇에게 원하는 작업을 설명하고, 그에 따른 로봇 행동을 생성하는 정책을 학습하는 것이 일반적인 패러다임이다. 이 정책은 작업 표현과 환경 관찰을 로봇 행동으로 매핑하는 함수로 parameterize 된다. 로봇은 작업 조건에 따라 행동하고, 이 행동은 다음 상태와 함께 정책으로 피드백되어 작업이 완료될 때까지 더 많은 행동을 생성한다.

로봇 학습 패러다임을 실제로 구현하는 것은 어려운 과제이다. 사용자의 목표를 명확하게 설명하는 적절한 인터페이스가 필요하며, 이는 종종 모호성을 도입할 수 있다. 이러한 모호성을 해결하고 로봇이 주어진 작업을 수행하도록 목표를 명확하게 지정하는 방법이 필요하며, 비슷한 목표로 일반화가 가능한 일반적인 작업 표현을 만드는 방법도 필요하다. 더 나아가, 새로운 작업과 환경에 대한 정책을 학습하는 로봇을 돕는 방법을 구축해야 한다.

언어와 비전에 대한 foundation model을 적용하는 최근의 발전은 대규모 자가 감독 사전 학습이 일반화를 개선하는 데 있어 잠재적 이점을 제안한다. 다양한 데이터를 활용해 작업 지정에 필요한 로봇 foundation model을 학습하는 것이 가능하다. 다양한 로봇 상호작용 데이터를 이용해 일반적이고 의미 있는 스킬을 학습할 수 있다. 하지만 이런 기회들에도 불구하고, 적절한 데이터 수집이 주요한 장애물로 남아 있다. 로봇학 데이터는 풍부하지 않고, 다양한 환경을 대표하지 못한다. 아직 일반적인 로봇학을 가능하게 하는 가장 유용한 데이터 유형에 대해 합의하지 못했다. 또한, 적절한 규모와 다양성의 데이터를 얻는 문제와 함께, 새로운 환경에서 안전하게 행동하는 방법에 대한 문제도 있다.

로봇학에 대한 새로운 foundation model 구축은 작업 지정과 학습에 대한 기회와 데이터 수집 및 안전한 배포에 대한 도전 사이의 균형을 찾는 것으로 이루어진다. 이는 로봇 foundation model이 어떻게 일반적인 로봇 개발에 도움이 될 수 있는지를 보여주는 동시에, 이러한 시스템을 구축하는데 있어서의 도전을 의미 있게 해결하고, 다중 모달성(인식, 행동, 언어의 통합) 및 인간-로봇 상호작용의 잠재력을 강조한다.

#### Opportunities

로봇 foundation model은 다양한 형태를 가질 수 있다. 로봇학 문제는 각각 다른 입력-출력 특성을 가지므로 일괄적인 모델에 적용하기 어렵다. 이와는 달리, 많은 NLP 문제는 "텍스트 입력, 텍스트 출력"의 일반적인 형태로 표현할 수 있다. 작업 지정과 작업, 환경, 로봇 구현체 간의 학습에 있어서 일반화 가능성에 초점을 맞추고 있다.

**Foundation models for task specification.** 로봇이 일반적으로 작업을 해결하려면 먼저 원하는 작업이 무엇인지 이해해야 한다. 따라서, 범용 로봇을 개발하는 첫 단계는 신뢰할 수 있는 작업 명세를 위한 새로운 foundation model을 구축하는 것이다. 이는 작업 목표, 선호도, 제약사항을 효과적으로 전달하는 과정이다. 작업 명세는 인간이 제공한 작업 설명을 로봇의 작업 완료와 진행을 측정하는 지표로 변환하는 과정이다. 이 신호는 로봇 행동을 최적화하고 실패를 진단하며 인간 피드백을 요청하는데 필수적이다. 로봇 foundation model은 사용자, 환경, 작업에 따라 다양한 작업 설명 방식을 수용해야 한다.

일반 목적의 작업 명세 모델은 새로운 환경과 작업에 적용할 수 있는 능력이 중요하다. 작업 설명을 로봇 학습을 위한 일반화 가능한 보상 신호로 변환하는 것은 아직 미해결 문제이지만, 로봇 foundation model이 잘 해결할 수 있을 것이다. 이 모델은 크고 광범위한 데이터셋에서 학습하여 강건한 보상 신호를 제공해야 하며, 보이지 않는 언어 지시사항과 환경에 일반화할 수 있는 능력을 갖춰야 한다. 이는 새로운 foundation model이 다양한 모달성을 능숙하게 연결하고 광범위하게 일반화하는 능력 때문에 일반 목적의 작업 명세에 매력적으로 보인다.

**Foundation models for task learning.** 로봇 foundation model은 일반적인 작업 명세를 가능하게 하며, 새로운 작업 해결 학습을 더 효과적이고 신뢰성 있게 만들 수 있다. 이러한 모델은 행동, 센서 관찰, 보상 등의 속성에 대한 공동 분포 형태를 취하며, 이 분포의 다른 차원에 조건을 부여함으로써 다양한 추론 문제를 복구할 수 있다.

* *Dynamics modeling*: $p(\text{future observations} | \text{actions, past observations})$
* *Policy learning*: $p(\text{actions} | \text{observations, goal})$
* *Inverse reinforcement learning*: $p(\text{reward function} | \text{observations, actions})$

로봇 foundation model의 학습 목표는 공동 분포의 요소를 자기회귀 방식으로 예측하는 것이다. 하지만, 이것이 유일한 방법은 아니다. 로봇 데이터셋에는 다양한 센서에서 동기화된 관찰과 로봇의 행동이 포함된 라벨이 없는 대량의 데이터가 있다. 이러한 데이터를 활용하여, 로봇 foundation model은 한 센서 모달리티에서 다른 모달리티의 관찰을 예측하거나, 두 개의 감각 관찰 스트림이 같은 시간 세그먼트에서 발생했는지 예측하도록 학습될 수 있다. 이는 고차원 데이터의 저차원 표현을 생성하는 데 도움이 될 수 있다. 이러한 목표는 데이터가 다양하고 의미 있는 행동을 보일 때, 라벨이 없는 데이터에서 강력한 로봇 foundation model의 학습을 돕는다.

언어와 시각 분야에서의 foundation model처럼, 로봇 foundation model도 다양한 데이터, 자기감독 목표, 다양한 모달리티를 활용하여 새로운 환경, 작업, 구현체에 대한 인식과 제어의 적응을 가능하게 할 수 있다. 예를 들어, 새 주방에서 로봇이 요리하려면 주방의 일반적인 특성을 이해하고 적응해야 한다. 이러한 상식 지식, 물리적 사전 정보, 시각적 사전 정보는 새로운 환경에 더 효율적으로 적응하는 데 도움이 될 수 있다. 그리고 이러한 foundation model을 개발함으로써, "달걀 후라이"와 같은 일반적인 기술에 대한 정책을 특정 사용자의 선호도에 맞게 적응시킬 수 있다. 마지막으로, 크로스-모달 표현을 학습하는 로봇 foundation model은 새로운 구현체에 적응하는데 도움이 될 수 있으며, 이런 적응력은 이러한 모델들의 널리 사용되는 중요한 요소이다.

#### Challenges and risks.

일반화를 위해 충분하고 다양한 로봇 데이터셋 수집이 필요하며, 학습된 행동을 실세계에서 안전하게 적용할 수 있는 방법도 필요하다.

**Data needs & challenges.** 로봇이 환경을 인식하고 작업을 수행하는 정책을 학습하는 것은 일반적으로 실세계에서 로봇의 상호작용에 대한 대규모 데이터셋이 필요하다. 하지만, 컴퓨터 비전과 자연어 처리의 많은 학습 작업은 웹에서 쉽게 수집할 수 있는 크고 다양한 오프라인 데이터셋에 의존한다. 이런 배경에서, 대규모 오프라인 데이터를 활용하여 새로운 로봇용 foundation model을 학습시키는 가능성에 흥분하고 있다.

이 목표를 달성하기 위한 한 방법은 원격 조작, 키네스테틱 교육, 자율적인 방법 등을 활용하여 대규모의 데이터셋을 수집하는 것입니다. 이 방법들은 일반화에 대한 유망한 징후를 보여주고 있다. 비전과 언어 데이터셋의 크기로 로봇 데이터 수집을 확장하는 것은 여전히 도전과제이지만, 로봇 데이터셋의 규모와 품질 증가는 로봇용 foundation model 학습에 중요한 역할을 할 것으로 보인다. 또한, 로봇은 환경을 형성하는 능력이 있으므로, 대량의 라벨 없는 데이터를 생성할 수 있어야 한다.

제어 학습의 복잡성 때문에, 로봇 공학에는 대규모 데이터셋이 필요할 수 있다. 인간의 비디오나 기존의 비전과 자연어 데이터셋과 같은 외부 데이터를 활용하는 것이 한 가지 해결책일 수 있다. 이러한 방식은 광범위한 일반화를 가능하게 할 수 있다. 그러나 로봇의 도메인과 웹상의 비디오나 언어 간의 차이를 해결하는 것은 여전히 도전 과제이지만, 도메인 적응과 사전 학습된 비디오 및 언어 모델의 활용이 이 문제를 해결하는 방향으로 진전되고 있다.

시뮬레이션은 로봇이 학습할 수 있는 풍부한 데이터를 제공하지만, 시뮬레이션과 실제 세계 사이의 물리적이고 의미론적인 차이를 극복하는 것은 큰 도전이다. 최근의 연구는 광범위한 도메인 무작위화를 통해, 시뮬레이션에서 배운 기술을 실제 로봇에 전달할 수 있음을 보여주었다. 그러나 이러한 시뮬레이션에서 실제로의 학습은 여전히 열린 문제이다. 시뮬레이션 데이터, 실제 로봇 데이터, 인간의 비디오, 자연어 데이터 모두 로봇 foundation model 학습에 중요할 수 있다.

**Safety & robustness.** 로봇을 위한 새로운 foundation model의 개발과 배포에서는 안전성과 견고성이 중요한 이슈있다. 실제 세계에서 로봇이 환경을 조작하고 상호작용하기 때문에, 예상치 못한 위험한 행동이 발생할 수 있다. 이를 해결하기 위한 한 가지 방법은 환경의 복잡성을 제한하거나 로봇의 복잡성을 높이는 것이다. 또한 로봇은 환경을 자동으로 재설정하여 대규모 데이터 수집에서 끊임없는 학습을 이어갈 수 있다. 이는 부서질 수 있는 항목이 없거나, 에이전트가 부술 수 있는 항목을 보장하고 교체하는 것을 의미한다.

로봇 foundation model의 위험을 줄이기 위해 미래에는 인과 분석 개발, 새로운 안전 평가 도구, 실제와 같은 시뮬레이션 환경 개발 등이 필요할 것이다. 또한, 로봇 모델에 대한 공식적인 안전 보장을 위해 Hamilton-Jacobi 도달 가능성 같은 안전 집합이나 학습을 위한 안전한 경계 개발 등이 도움이 될 것이다. 이런 연구와 개발이 진행됨에 따라 위험을 줄이는 해결책이 결정적으로 나타날 것이다.

**Conclusion.** 로봇 foundation model의 가능성은 무궁무진하지만, 그에 따른 도전과제도 많다. 다양한 환경과 구현체를 대규모로 다루는 데이터 수집과 시스템의 안전성 및 견고성 보장은 큰 난제이다. 그러나 이런 도전을 이제부터 대처하면, 모델 개발 이전에 바람직한 기능을 가진 신뢰할 수 있는 로봇 foundation model을 구축하기 위한 적절한 데이터를 적절한 출처에서 적절한 규모로 수집하는 방법을 발견할 수 있을 것이다.

이 섹션의 핵심은 다중 모달성이다. 로봇 기반 모델은 AI의 다른 부분, 예를 들어 언어와 비전 분야에서의 연구로부터 이점을 얻었고, 계속 그럴 것이다. 하지만 다른 분야에서의 이러한 확장을 고려하면서, 실시간 로봇을 위한 모델 학습 및 배포, 견고한 인간-로봇 상호작용 인터페이스, 그리고 모델의 안전성과 견고성에 대한 이해 등에 대한 복합적인 도전이 나타난다. 기반 모델과 특히 로봇 기반 모델에 대한 신뢰성 있는 생태계와 신중한 연구 방법을 구축하는 것이 이러한 목표를 실현하는 핵심이다.

### Reasoning and search



---

## Reference

* [Paper](https://arxiv.org/pdf/2108.07258.pdf)