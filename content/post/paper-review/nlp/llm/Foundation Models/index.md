+++
author = "Kurt"
title = "Foundation Models"
date = "2024-01-01"
description = "On the Opportunities and Risks of Foundation Models"
categories = [
    "Paper Review"
]
tags = [
    "NLP",
    "LLM",
]
draft = true
+++

## Abstract

AI는 넓은 범위의 데이터에서 학습된 다양한 모델(BERT, DALL-E, GPT-3 등)이 등장하며 패러다임 변화를 겪고 있다. 이런 모델들을 "foundation model"이라 부르며, 그들의 중요성과 불완전성을 강조한다. 이 모델들은 많은 작업에 효과적이어서 동질화를 촉진하지만, 그 결함은 모든 하위 모델에 상속되므로 주의가 필요하다. foundation model의 작동 방식, 실패 시점, 그리고 가능성에 대한 명확한 이해는 아직 부족하며, 이에 대한 연구는 그들의 사회기술적 성질에 맞게 깊은 학제간 협력을 필요로 한다.

---

## INTRODUCTION

이 보고서는 "foundation model"이라는 일반적인 AI 모델 클래스를 기반으로 하는 시스템 구축에 대한 새로운 패러다임을 조사한다. foundation model은 광범위한 데이터에서 학습되어 다양한 downstream task에 적용될 수 있다. 이는 기존의 deep neural network와 self-supervised 학습에 기반하지만, 그 규모와 범위는 우리의 상상력을 넘어섰다. 예를 들어, GPT-3 같은 모델은 막대한 parameter를 가지고 있고, 특정 작업에 대한 명확한 학습 없이도 다양한 작업을 수행할 수 있다. 그러나, 이런 모델들의 특성은 잘 이해되지 않았고, 잠재적인 해를 악화시킬 수 있다. 이러한 모델들이 널리 배포될 예정이므로, 심도 있는 조사가 필요하다.

### Emergence and homogenization

foundation model의 중요성은 "emergence"과 "homogenization" 두 가지 개념으로 요약된다. "emergence"는 시스템 행동이 명시적으로 구축되지 않고 암시적으로 유도되는 것을 의미하며, 이는 흥분과 예상치 못한 결과에 대한 불안을 가져온다. "homogenization"는 다양한 응용 분야에서 기계 학습 시스템 구축 방법론을 통합하는 것을 가리키며, 많은 작업에 대한 leverage를 제공하지만 단일 실패 지점을 만들 수 있다. 이 두 개념은 최근 30년 동안 AI 연구에서 점점 중요해지고 있다.

![](images/figure1.png)

**Machine learning.** 오늘날 대부분의 AI 시스템은 과거 데이터를 학습하여 미래를 예측하는 기계 학습에 의해 구동된다. 1990년대부터 시작된 AI에서의 기계 학습의 부상은 작업 해결 방법을 명시하는 대신 데이터를 바탕으로 학습 알고리즘이 이를 유도하는 새로운 방식을 나타냈다. 이는 "how"가 학습 과정에서 발생하는 것을 의미한다. 또한, 기계 학습은 로지스틱 회귀와 같은 일반적인 학습 알고리즘을 통해 다양한 응용 분야를 통합하는 동질화로 나아가는 한 걸음을 나타냈다.

AI에서 기계 학습이 널리 사용되지만, 자연어 처리나 컴퓨터 비전 등의 복잡한 작업에서는 도메인 전문가가 "feature engineering"을 수행해야 했다. 이는 raw 데이터를 더 고수준의 특징으로 변환하는 과정으로, 기계 학습 방법에 더 적합하게 만드는 역할을 한다.

**Deep learning.** 2010년경, 딥러닝이라는 이름 아래에 deep neural network의 부활이 이루어졌다. 이는 더 큰 데이터셋, 더 많은 계산 능력, 그리고 대담함에 의해 추진되었다. raq 입력에 대한 학습을 통해 고수준의 특징이 발생하였고, 이는 성능 향상을 가져왔다. 딥러닝은 homogenization를 향한 또 다른 전환을 나타냈는데, 맞춤형 feature engineering 대신 동일한 deep neural network 아키텍처가 다양한 응용 프로그램에 사용될 수 있게 되었다.

**Foundation models.** foundation model은 주로 자연어 처리(NLP)에 초점을 맞추지만, 일반적인 AI 패러다임으로 볼 수 있다. 이러한 모델은 전이 학습과 규모의 확장을 통해 가능하게 되었으며, 한 작업에서 배운 지식을 다른 작업에 적용하는 것을 목표로 한다. 주로, 모델은 대리 작업에서 사전 학습을 받고, 그 후에는 미세조정을 통해 특정 작업에 적용된다.

foundation model의 강력함은 전이 학습의 가능성과 규모의 확장성에서 비롯된다. 규모 확장에는 컴퓨터 하드웨어의 개선, 표현력 높은 모델을 훈련시키는 Transformer 아키텍처의 개발, 그리고 대량의 학습 데이터의 활용이 필요하다.

데이터의 가용성과 활용 능력은 매우 중요하며, 주석이 달린 데이터셋을 사용한 전이 학습은 이미 10년 동안 일반적으로 이루어지고 있다. 그러나 주석 작성의 비용은 사전학습의 이점에 제한을 두게 된다.

self-supervised 학습에서는 주석이 없는 데이터에서 사전학습 작업이 자동으로 이루어진다. 이 방식은 레이블이 없는 데이터에 의존하므로 확장성이 뛰어나며, 모델이 입력의 일부를 예측하게 함으로써 한정된 레이블 공간에서 학습된 모델보다 더 풍부하고 유용할 수 있다.

단어 임베딩 이후로, self-supervised 학습은 크게 발전했다. 이는 각 단어를 문맥에 독립적인 벡터로 표현하며, 다양한 NLP 모델의 기반이 되었다. 또한, autoregressive 언어 모델링을 기반으로 한 self-supervised 학습이 인기를 끌었으며, 이를 통해 문맥 속 단어를 표현하는 GPT, ELMo, ULMFiT와 같은 모델들이 생성되었다.

self-supervised 학습의 다음 단계는 BERT, GPT-2, RoBERTa, T5, BART 등이 빠르게 따라왔으며, 이들은 Transformer 아키텍처를 채택하고, 문장의 강력한 bidirectional encoder를 통합하며, 더 큰 모델과 데이터셋으로 확장하였다.

BERT의 등장은 self-supervised 학습에 대한 사회학적 변곡점이었다. 2019년 이전에는 NLP의 하위 분야였지만, 2019년 이후로는 NLP의 핵심 부분이 되었다. 단일 모델이 넓은 범위의 작업에 유용하다는 인식은 foundation model의 시대의 시작을 의미한다.

foundation model들은 NLP 모델의 homogenization를 가져왔고, 이는 높은 지렛대 효과를 제공하지만 동시에 위험성도 내포하고 있다. 모든 AI 시스템이 foundation model의 문제적인 편향을 상속받을 수 있기 때문이다.

연구 커뮤니티 간에 homogenization가 점차 진행되고 있다. Transformer-based sequence 모델링 방법론이 텍스트, 이미지, 음성, 표 데이터, 단백질 시퀀스, 유기 분자, 강화 학습 등 다양한 분야에 적용되고 있다. 이러한 예시들은 다양한 형태의 foundation model을 개발할 수 있는 통합 도구 세트를 가질 미래를 예상하게 한다.

![](images/figure2.png)

접근법뿐만 아니라 실제 모델 역시 여러 연구 커뮤니티에서 통일되고 있다. 이는 언어와 시각 데이터를 학습하는 multimodal 모델의 형태로 나타난다. 일부 영역에서는 데이터가 자연스럽게 multimodal이며, 이는 의료 이미지, 구조화된 데이터, 의료 텍스트 등에서 볼 수 있다. 따라서, multimodal foundation model은 도메인에 대한 모든 관련 정보를 통합하고 다양한 모드를 아우르는 업무에 적응하는 자연스러운 방법이다.

규모의 증가로 인해 foundation model들은 놀라운 발전을 이끌어냈다. GPT-3는 175B 개의 parameter를 가지고 있어, 프롬프트(업무의 자연어 설명)만 제공하면 하위 업무에 쉽게 적응할 수 있는 문맥 내 학습이 가능하다. 이는 특별히 학습되지 않았지만 예상치 못하게 발생한 특성이다.

homogenization와 emergence은 잠재적으로 불안정한 방식으로 상호 작용한다. homogenization는 특정 과제 데이터가 제한된 많은 분야에서 큰 이익을 가져올 수 있지만, 모델의 결함은 모든 적응된 모델에게 그대로 상속된다. foundation model의 힘은 그들의 명시적인 구성보다는 출현적 특성에서 나오므로, 이해하기 어렵고 예측하지 못한 실패 모드를 가진다. 이런 emergence이 foundation model의 능력과 결함에 대한 불확실성을 증가시키므로, 이러한 모델을 통한 공격적인 homogenization는 위험하다. 윤리적 및 AI 안전성 관점에서 볼 때, 위험을 줄이는 것이 foundation model의 추가 개발에서 중요한 도전 과제이다.

#### Naming.

"foundation model"이라는 용어는 지금 목격하고 있는 패러다임의 변화를 설명하는 데 필요한 용어이다. 기존의 용어들은 이러한 모델들의 기술적 면을 부분적으로 포착하지만, 기계 학습을 넘어서는 사람들에게 패러다임 변화의 중요성을 적절하게 전달하지 못한다. foundation model은 그들의 사회적 영향과 AI 연구와 배포에 있어서의 광범위한 변화를 특징으로 하는 독특한 모델 클래스를 지칭한다. 반면에, 사전 학습과 자기 감독 같은 방식은 foundation model이 예고한 기술적 변화를 명확하게 설명하지 못한다.

현재 대표적인 foundation model들 대부분이 언어 모델이지만, "language model"이라는 용어는 이 목적에는 너무 좁다. foundation model의 범위는 언어를 훨씬 넘어선다. "general-purpose model"이나 "multi-purpose model" 같은 용어는 여러 하위 과제에 적용될 수 있다는 점을 포착하지만, 그들이 미완성된 특성을 가지고 있고 적응이 필요하다는 점을 포착하지 못한다. "task-agnostic model"은 학습 방식을 포착하지만, downstream 응용에 대한 중요한 영향을 포착하지 못한다.

"foundation model"이라는 새로운 용어를 도입하여 현재 등장하고 있는 모델과 패러다임을 식별하였다. foundation model은 자체적으로는 불완전하지만, 다양한 과제에 적응하여 공통의 기반을 제공한다. "foundation"이라는 용어는 architectural stability, safety, security의 중요성을 강조한다. 현재로서는, foundation model의 본질이나 품질을 완전히 이해하지 못하고 있으며, 이는 연구자, 모델 제공자, 응용 프로그램 개발자, 정책 입안자, 그리고 사회 전체가 고민해야 할 중요한 문제이다.

### Social impact and the foundation models ecosystem

기초 모델들은 높은 성능 때문에 과학적으로 중요하며, 실제 AI 시스템에 빠르게 통합되어 사람들에게 큰 영향을 미치기 때문에 연구가 필요하다. 예를 들어, 40억 명의 사용자를 가진 구글 검색은 BERT와 같은 기초 모델을 사용하고 있다.

기초 모델의 사회적 영향에 대해 깊이 생각해봐야 한다. 이 보고서에서는 사회 불평등, 경제적 영향, 환경 영향, 오용 가능성, 법적 문제, 윤리적 문제 다양한 측면을 다룬다. 특정 시스템의 사회적 영향을 추론하는 것이 기초 모델의 사회적 영향을 추론하는 것보다 더 쉽다는 점이 반복적으로 나타난다. 기초 모델의 변화무쌍한 성질로 인해, 그들이 제기하는 윤리적, 사회적 고려사항을 책임감 있게 예측하고 다루는 것이 중요하다.

기초 모델에 대한 연구와 배포는 구분되어야 한다. 대부분의 공개적인 정보는 학술 논문이나 데모를 통한 연구에 관한 것이다. 이런 지식의 생산은 중요하지만, 실제로 사회에 영향을 미치는 것은 모델의 배포이다. 배포는 새 제품, 예를 들어 GitHub의 Copilot 같은 것을 통해 이루어지거나 기존 제품을 업그레이드하는 형태로 일어난다. 연구 모델은 광범위한 테스트 없이 알려지지 않은 실패를 가질 수 있어, 배포에 적합하지 않다는 경고를 요구하며, 실제로 사람들에게 영향을 주는 모델은 엄격한 테스트와 감사가 필요하다.

기초 모델의 연구와 배포를 이해하려면 데이터 생성부터 실제 배포에 이르는 전체 생태계를 고려해야 한다. 기초 모델은 AI 시스템의 한 부분이며, 사회적 영향을 고려할 때 사람들이 파이프라인의 양 끝에 위치해 있다는 것은 중요하다. 이러한 관점을 통해, 기초 모델에 대한 다양한 질문들이 실제로는 다른 단계에 대해 답변되어야 함을 알 수 있다.

1. **Data creation:** 데이터 생성은 사람 중심의 과정으로, 모든 데이터는 사람에 의해 만들어지고 대부분 사람에 대한 정보를 담고 있다. 이는 이메일, 기사, 사진 등을 통한 정보 제공이거나, 사람이나 그들의 환경에 대한 측정일 수 있다. 모든 데이터는 소유자가 있으며 특정 목적을 위해 생성되며, 이 목적은 기초 모델 학습을 포함할 수도, 포함하지 않을 수도 있다.
2. **Data curation:** 데이터는 데이터세트로 정리되는데, 이 과정은 선택과 후처리 필터링이 필요하다. 데이터의 관련성과 품질을 보장하면서 법적, 윤리적 제약을 준수하는 것은 중요하지만 어렵다. 이 점은 산업에서는 인식되고 있지만, AI 연구에서는 충분히 인식되지 않고 있다.
3. **Training:** 정리된 데이터셋에서 기초 모델을 학습시키는 것은 AI 연구의 중요한 단계이지만, 이는 전체 과정 중 일부일 뿐이다.
4. **Adaptation:** 기계 학습 연구에서의 적응은 특정 작업을 수행하는 새 모델을 생성하는 것이다. 배포를 위한 적응은 다양한 모듈, 사용자 정의 규칙, 분류기 등을 필요로 하는 시스템을 만드는 것이다. 예를 들어, 유해한 콘텐츠를 생성할 수 있는 모델도 적절한 예방 조치가 취해진다면 문제가 되지 않는다. 이러한 추가적인 응용 특화 로직은 해를 줄이는 데 중요하다.
5. **Deployment:** AI 시스템이 사람들에게 배포될 때 직접적인 사회적 영향이 발생한다. 논란의 여지가 있는 데이터를 기반으로 한 잠재적으로 해로운 기초 모델을 배포하길 원치 않지만, 이를 연구에 사용하여 과학적 이해를 향상시키는 것에는 가치가 있을 수 있다. 대규모 배포에서는 점진적으로 릴리스를 실시하는 것이 표준적인 관행이며, 이는 잠재적인 해를 부분적으로 완화할 수 있다.

이 보고서는 기초 모델에 대한 것이지만, 파이프라인의 다른 단계에서의 결정으로 인한 영향을 간과할 수 없다. 모든 단계에서 주의 깊은 모니터링과 개입이 필요하다. 대형 조직이 전체 파이프라인을 소유할 수 있지만, 각 단계는 다른 조직이 수행할 수 있다. 예를 들어, 응용 프로그램 개발자가 사용할 수 있는 맞춤형 기초 모델을 만드는 전문 회사가 될 수 있다.

**Think ecosystem, act model.** 사회적 영향은 전체 생태계에 따라 달라지지만, 많은 연구자와 실무자가 학습 단계에 집중하고 있기 때문에 기초 모델의 사회적 함의를 이해하는 것이 중요하다. 이는 기초 모델이 완성되지 않은 중간 단계이며, 예측하지 못한 목적으로 다른 엔티티에 의해 다양하게 적용될 수 있기 때문에 어렵다. 이를 위해 필요한 것은 잠재적인 downstream 평가를 대표하는 대리 메트릭과 이러한 메트릭을 문서화하는 데의 헌신이다. 이는 다양한 downstream 사용 사례에 적응할 수 있는 금속이나 플라스틱 같은 재료의 데이터 시트와 유사하다.

기초 모델의 잠재적인 사회적 영향을 파악하는 것은 기술 생태계와 사회에 대한 깊은 이해를 필요로 하며, 도전적이다. 모델의 배포 방식을 이해하지 않고서는 그 해를 완전히 평가할 수 없으며, 사회적, 역사적 맥락을 고려하지 않고서는 자동 메트릭을 정의할 수 없다.

### The future of foundation models

foundation model들은 많은 잠재력을 가지고 있지만, 아직 초기 단계이고 완전히 이해되지 않고 있다. 모델이 안전하게 배포될 수 있는 시점이나, 방법론적 위반에 대한 대응 등에 대한 합의가 부족한 상태이다. 그래서 foundation model의 미래는 불확실하며, 이를 결정할 주체가 누구인지는 아직 미지수이다.

**Disciplinary diversity.** foundation model의 기술은 여러 분야에서 수십 년 동안의 연구를 기반으로 하며, 이러한 기여는 학계와 산업 연구소 모두에서 이루어졌다. 그러나 foundation model을 직접 구축하는 연구는 주로 Google, Facebook, Microsoft, Huawei와 같은 대형 기술 회사와 OpenAI, AI21 Labs와 같은 스타트업에서 이루어졌다. AI2는 이러한 흐름에서 예외적인 경우이다.

기술의 빠른 발전과 중앙집중화로 인한 문제는 기술자뿐만 아니라 인문학자와 사회 과학자의 주목을 필요로 한다. 기술 개발 초기 단계부터 사회적 고려사항과 윤리적 디자인을 반영해야 한다. 학문적 다양성이 문제 해결에 중요하므로, 학계는 foundation model의 개발과 그 생태계에 대한 결정 과정에서 핵심적인 역할을 할 것으로 보인다. 이는 사회적 이익을 증진하고 해를 완화하는 데 필요한 과정이다.

**Incentives.** foundation model의 설계, 개발, 배포는 모든 단계에서 결정을 내리는 데 인센티브 구조를 제공한다. 상업적 인센티브는 사회적 이익과 일치할 수 있지만, 시장 실패와 혁신 가치를 확보할 수 없는 영역에서의 투자 부족을 초래할 수도 있다. 특히, 빈곤하고 소외된 사람들을 위한 기술에 대한 투자 인센티브는 부족하며, 사회적 외부성을 무시하는 경향이 있다. 또한, 넓은 참여를 장려하는 foundation model의 개방적이고 분산화된 생태계를 만드는 것에 대한 인센티브는 거의 없다.

대학의 깊이 뿌리내린 연구 사명은 지식의 생산과 전파, 그리고 글로벌 공공재의 창출이다. 이러한 사명으로 인해 학계는 산업계에서는 우선순위를 두지 않을 수 있는, 사회적 이익을 가져올 수 있는 방향의 foundation model 개발을 주도할 수 있는 독특한 위치에 있다고 봅니다.

**Loss in accessibility.** 접근성의 감소로 인해 학계는 완전히 참여하지 못하였다. 딥러닝 혁명의 한 결과는 재현성과 공개 과학의 증가였다. 코드와 데이터셋 공개가 표준화되었으며, TensorFlow와 PyTorch 같은 패키지는 협업을 용이하게 했다. ML Reproducibility Challenge 등의 이니셔티브와 재현성 체크리스트, CodaLab Worksheets 같은 플랫폼은 재현성 표준을 향상시켰고, 이로 인해 기술 혁신과 진보가 크게 증가하였다.

foundation model은 긍정적인 과학 공개 추세를 되돌리고 있다. 일부 모델(GPT-3 등)은 전혀 공개되지 않으며, 심지어 데이터셋도 공개되지 않는다. 학습 모델은 사용할 수 있지만, 높은 계산 비용과 복잡한 엔지니어링 요구사항으로 인해 대다수 AI 연구자들은 실제 foundation model 학습을 수행할 수 없다.

학계 예산 내에서 작은 모델을 학습시키면서도 의미 있는 연구를 할 수 있다. 스케일링 법칙에 따라 양적인 차이(예: 정확도 상승)를 보이는 경우에는 이런 방식이 실행 가능하다. 그러나 foundation model의 특성상, 문맥 내 학습 같은 기능은 충분한 크기의 모델에서만 나타나므로, 올바른 질문을 하려면 모델의 스케일이 필요하다.

공개된 모델을 연구하는 것은 유용하며, 이는 NLP 내에서 큰 부분집단을 만들어냈다. 기존 모델에 접근하는 것은 downstream 응용 프로그램을 지원하거나 결함을 찾는 데 도움이 되지만, 이것만으로는 결함을 수정하는 더 나은 구조나 학습 목표를 가진 foundation model을 만드는 데는 부족하다. 사회적 인식과 윤리적 설계를 모델에 불어넣는 필요성을 감안하면, 필요로 하는 foundation model은 현재와 매우 다를 수 있으며, 이는 대규모 실험을 요구한다.

EleutherAI와 Hugging Face의 BigScience 프로젝트 같은 커뮤니티 노력들이 큰 foundation model을 학습하려 하지만, 산업과 공개 커뮤니티 사이의 모델 학습 능력 격차는 계속 커질 것이다. 스타트업들이 더 많은 자원을 활용해 큰 모델을 학습할 수 있지만, 대형 기술 회사들은 시장 위치로 인한 인프라, 사용자, 데이터 등의 자원이 훨씬 많다. 이로 인해 foundation model 개발에 대한 진입 장벽은 더욱 높아져, 심지어 빠르게 대응하는 스타트업들조차 경쟁하기 어려워질 것이다. 이는 검색 엔진 개발 추세에도 반영되어 있다.

자원 격차를 줄이기 위해, 정부가 공공 인프라에 투자하는 방법을 고려할 수 있다. 허블 우주 망원경과 대형 하드론 충돌기 같은 빅 사이언스 프로젝트를 본받아, 컴퓨팅 인프라를 구축하면 foundation model에 대한 학계 연구에 큰 도움이 될 것이다. 미국에서는 이런 방향으로 National Research Cloud 이니셔티브를 시작하였다.

volunteer 컴퓨팅을 활용하는 것은 또 다른 접근법이다. 이 방법은 수십억 개의 컴퓨팅 장치가 중앙 서버에 연결하여 계산을 제공한다. Folding@home 프로젝트는 이 방법을 단백질 동역학 시뮬레이션에 성공적으로 적용했고, 최근에는 Learning@home 프로젝트가 foundation model 학습에 이를 활용하려고 하고 있다. 그러나 노드 간의 고지연 연결과 고대역폭 요구 사항은 이를 어렵게 만드는 기술적인 도전 과제이다.

**Summary.** foundation model의 능력과 규모를 확장하는 것에 대한 경제적 동기로 인해 다음 몇 년 동안 기술적 발전이 계속될 것으로 예상된다. 그러나 대부분의 행동이 신흥적인 행동에 의존하는 이러한 기술이 널리 배포될 적합성은 불확실하다. 신중해야 하며, 지금이 foundation model의 책임 있는 연구와 배포를 가능하게 하는 전문적인 규범을 세우는 시기이다. 이를 위해 학계와 산업계가 협력해야 하며, foundation model의 개발과 배포에 대한 기술적이고 윤리적인 지침을 제공해야 한다.

### Overview of this report

2021년 3월, 스탠포드 대학에서는 foundation model에 대한 다양한 관심을 가진 학생, 교수, 연구자들의 커뮤니티를 만들었다. 이 커뮤니티는 AI 연구, 의료와 법률 등의 분야에서의 적용, 그리고 윤리와 경제와 같은 사회적 이슈에 대한 관심을 포괄하였다. 하지만 기술 이해와 윤리적 문제 등에 대한 상호 이해의 차이가 있었고, 이를 해소하기 위해 foundation model에 대한 전체적인 그림을 제공하며, 기회와 위험을 파악하고, 미래의 책임 있는 개발에 대한 비전을 설정하려는 노력을 하였다.

이 보고서는 100명 이상의 다양한 배경의 사람들이 모여 foundation model의 여러 측면을 다루는 실험적인 작업이다. 대부분 기존 연구를 조사하지만, 여러 논의를 통해 한 보고서로 통합하고 모든 학문 간 연결성을 강조하였다.

**Structure.** 이 보고서는 foundation model의 다양한 측면을 논의하는 26개의 섹션으로 구성되어 있다. 이들은 기능, 응용, 기술, 사회의 네 부분으로 나뉘어 있으며, 섹션 간 많은 연결성을 보여준다. 이 연결성은 기술과 기능이 실제 사회적 고려사항에 민감하게 반응하고 응용에서 영감을 얻는 통합적 접근법을 강조한다.

이 보고서는 foundation model에 대한 중요한 주제들을 대부분 다루려고 노력했지만, 이 분야가 빠르게 발전하므로 불가피하게 불완전하게 남을 것이다. 일부 응용 분야(예: 자연 과학, 음악, 금융, 농업)는 포함되지 않았지만, 논의된 분야만큼 영향을 받을 가능성이 있다. 또한, foundation model이 신경과학, 인지과학, 심리학 등과 어떻게 연관되는지 연구하는 것도 흥미롭다.

#### Overview of capabilities.

foundation model들은 다양한 능력을 키워 응용 프로그램을 지원한다. 다양한 모달리티 처리, 물리적 세계에의 영향, 추론 수행, 사람과의 상호작용 등 다섯 가지 잠재 능력을 논의하였다. 마지막으로, 이들 능력의 잠재적 한계에 대한 철학적 논의로 마무리하였다.

**§2.1: Language.** 자연어 처리 분야는 foundation model의 선구자 역할을 하였다. 이 모델들이 표준 벤치마크에서 선도적이지만, 현재 모델의 능력과 언어가 인간 커뮤니케이션과 사고의 복잡한 시스템을 대표하는 능력 사이에는 차이가 있다. 이에 대응해, 언어의 다양성을 강조하였고, 아동의 언어 습득이 foundation model 학습보다 효율적임을 지적하며, 텍스트 외의 신호와 그라운딩이 이 차이를 줄일 수 있음을 검토하였다. 이러한 언어의 특성은 미래의 foundation model 연구 방향을 제시한다.

**§2.2: Vision.** 컴퓨터 비전 분야는 AI에서 딥러닝 적용을 선도하였고, 대규모 주석 데이터셋에 사전 학습된 모델이 다양한 환경에 적용될 수 있다는 것을 보여주었다. 지금은 웹 규모의 raw 데이터에 사전 학습하는 것이 컴퓨터 비전에서 foundation model의 성장을 이끌고 있다. 이 모델들은 표준 작업에 대해 유망한 결과를 보여주며, multimodal과 실제 데이터에 대한 학습은 중요한 도전 과제에 대한 진전을 가능하게 한다. 또한 모델링과 평가의 주요 도전과제, 응용 사례, 사회적 고려사항을 논의하며, 이들이 앞으로 컴퓨터 비전을 위한 foundation model의 영향을 결정하는 데 중요한 역할을 할 것이다.

**§2.3: Robotics.** 로보틱스 연구의 목표는 다양한 환경에서 다양한 작업을 수행할 수 있는 "generalist" 로봇 개발이다. 언어와 비전 분야에서는 풍부한 원시 데이터를 활용한 foundation model이 주도적인 역할을 하고 있지만, 물리적 세계에 연결된 로보틱스는 특별한 도전과제에 직면하고 있다. 로보틱스를 위한 새로운 유형의 foundation model 개발의 핵심 도전은 학습에 적합한 충분한 데이터를 확보하는 것이다. 이를 위해 특정 환경에 한정되지 않는 다양한 데이터와 모달리티를 활용하는 방안을 탐구하고 있다. 이러한 새로운 로봇 foundation model은 작업 지정과 학습을 용이하게 하며, 새로운 응용 분야를 도입하고, 안전성의 중요성을 높일 것으로 기대된다.

**§2.4: Reasoning and search.** AI의 오랜 과제인 정리 증명이나 프로그램 합성같은 추론 및 검색 문제는 전통적인 검색 방법으로는 해결이 어렵다. 하지만 사람들은 직관적으로 작동하며, 작업 간 지식을 전달하여 효율적인 적응과 추상적인 추론을 가능하게 한다. 이러한 점에서 foundation model은 이 차이를 줄일 수 있는 가능성을 제시하며, 다목적성과 강력한 생성 및 multimodal 능력을 통해 복잡한 검색을 제어하는 새로운 방법을 제공한다.

**§2.5: Interaction.** foundation model은 AI 시스템의 개발 및 사용 경험을 혁신적으로 변화시킬 수 있는 잠재력을 가지고 있다. 이 모델들은 적응에 있어서의 효율성으로 AI 응용 프로그램 개발의 난이도를 낮추고, multimodal 및 생성 능력으로 새로운 사용자 상호작용의 가능성을 높인다. 이러한 특성은 개발자들이 사용자의 필요와 가치에 더욱 부합하는 응용 프로그램을 제공하고, 동적인 상호작용과 피드백 기회를 확장하는 데 도움이 될 것이다.

**§2.6: Philosophy of understanding.** foundation model이 학습 데이터에 대해 어떤 이해를 가질 수 있는지에 대해, 자연어를 중심으로 다양한 입장을 탐색하였다. 특히 multimodal 데이터에 학습된 모델의 경우, 미래의 foundation model이 자연어를 이해할 수 있다는 점에 대한 회의론은 성급할 수 있다는 결론을 내렸다.

#### Overview of applications.

현재, foundation model 연구는 주로 컴퓨터 과학과 AI 분야에 집중되어 있지만, 앞으로는 기술 산업을 넘어 다양한 분야에서 AI의 영향력을 확장시킬 잠재력이 있다. 이를 위해, 사회의 핵심 분야인 건강보험, 법률, 교육을 중점으로 살펴보았다. 이러한 영역에서 foundation model을 성공적으로 적용하기 위해서는 특정 능력과 기술 혁신이 필요하며, 데이터, 보안, 해석 가능성, 공정성, 윤리 등의 사회 기술적 문제를 주의 깊게 다루어야 합니다.

**§3.1: Healthcare and biomedicine.** 건강관리와 생물의학 분야는 전문 지식이 필요하며, 이는 제한적이고 비싸다. foundation model은 다양한 형태의 데이터를 활용하여 이러한 영역에서 큰 기회를 제공하며, 전문가의 시간과 지식의 비용을 줄이는 데 도움이 될 수 있다. 하지만, 이러한 모델들은 의료 데이터의 역사적 편향을 악화시키는 등의 위험을 내포하고 있다. 이 잠재력을 책임감 있게 활용하기 위해서는, 데이터, 개인 정보 보호, 모델의 해석 가능성과 설명 가능성 등의 사회 기술적 문제를 깊게 이해하고 적절한 규제가 필요하다.

**§3.2: Law.** 법률 분야에서는 변호사들이 긴, 일관된 서술을 읽고 생성해야 하는데, 이것은 변화하는 맥락을 포함하고 모호한 법률 표준을 해독해야 하는 작업이다. foundation model은 이런 작업에 잘 맞는 생성 능력과 법률 문서라는 풍부한 데이터 덕분에 이 분야에서 유용할 수 있다. 그러나, 다양한 정보 출처를 신뢰할 수 있게 처리하고, 정확한 장문의 문서를 생성할 수 있도록 모델을 개선하는 것이 필요하다. 또한, 개인 정보 보호, 행동의 출처, 생성의 사실성 등에 대한 깊은 고려가 필요하며, 이런 문제들은 foundation model의 핵심 한계를 강조하고 있다.

**§3.3: Education.** 교육은 복잡한 분야이며, 효과적인 교육은 학생의 인식과 목표를 반영해야 한다. foundation model은 교육 데이터를 종합적으로 활용하여 교육에 적용될 수 있는 AI를 제안한다. 이 모델이 교육능력을 향상시킨다면, 문제 생성이나 교사 피드백 등의 새로운 응용 프로그램이 가능해질 것이다. 또한 이는 개인화된 학습과 적응 학습을 강화시킬 수 있다. 하지만, 이러한 기술 적용에는 학생 정보의 개인화, 기술 접근 불평등, 표절 등의 문제도 함께 고려해야 한다.

#### Overview of technology.

더 나은 모델 구조를 만들고, 학습 및 적응 과정을 향상시키며, 시스템을 확장하는 기술에 대해 논의하려 한다. 데이터의 출처와 구성에 대한 이해, 분포 변화에 대한 강건성 및 공격자에 대한 보안, 그리고 수학적이나 경험적 관점에서 foundation model의 작동 원리에 대한 이해가 중요하다.

**§4.1: Modeling.** foundation model을 만드는 데 기여하는 구조적 속성에는 계산 모델의 표현력과 확장성이 있으며, 이는 대부분의 foundation model에서 사용하는 transformer 네트워크를 통해 실현된다. 다음 세대 모델에 필요한 속성으로는 다양한 출처와 도메인의 콘텐츠를 처리하는 다중 모달리티, 획득한 지식을 저장하고 검색하는 메모리 용량, 그리고 새로운 환경에 성공적으로 적용하는 구성성이 있습니다. 이러한 요소들이 foundation model의 전체 잠재력을 실현하는 데 중요하다.

**§4.2: Training.** 학습 목표는 모델이 학습 데이터로부터 학습하고 능력을 얻는 방법을 수학적으로 정의한다. 현재 foundation model 학습은 대부분 직관적으로 선택된 모달리티 특정 목표를 사용한다. 그러나 미래의 foundation model 학습은 체계적인 증거와 평가에 기반한 선택과, 다양한 데이터 소스와 모달리티에 걸쳐 풍부하고 확장 가능한 학습 신호를 제공하는 방식을 반영할 것으로 예상된다. 또한 생성적 대 비판별적 학습, 입력 데이터 표현의 선택 등의 디자인 상의 타협점과 목표의 명시적 표현을 포함하는 미래의 학습 목표의 가능성에 대해서도 논의된다.

**§4.3: Adaptation.** foundation model은 일반적으로 특정 작업에 맞게 적응이 필요한 미완성의 중간 자산이다. 현재는 미세 조정이 주로 사용되지만, 경량 미세 조정 대안과 프롬프팅 기반 방법이 효율성과 정확성을 균형있게 달성할 수 있다는 연구 결과도 있다. 미래에는 foundation model의 결함을 완화하거나 제약조건을 도입하는 등, 적응의 넓은 시각이 필요할 것으로 보인다. 이는 새로운 평가 프로토콜이 필요하게 되며, 이를 통해 적응 방법을 체계적으로 평가하면서 자원과 접근 요구 사항을 통제할 수 있다.

**§4.3: Adaptation.** 평가는 foundation model의 진행 상황을 추적하고, 모델을 이해하며, 능력과 편향을 기록함으로써 맥락을 제공한다. 그러나 foundation model은 특정 작업에서 한 단계 떨어져 있어 표준 기계 학습 평가 패러다임의 한계를 드러낸다. 이를 해결하기 위해, foundation model의 본질적 능력을 측정하고 학습 방식을 이해하는 평가, 적응 자원과 접근을 통제하여 과제 특정 모델을 평가하는 방법, 그리고 정확성 이상의 맥락을 제공하는 평가 디자인(강건성, 공정성, 효율성, 환경 영향 등)을 논의한다. 평가 관행의 개혁을 통해, 다양한 목표와 이해관계자를 충족시키는 평가가 가능해질 것이다.

**§4.5: Systems.** 학습 데이터는 foundation model에 대한 이론적 정보를 제공하고, 모델 아키텍처와 학습 목표는 이 정보의 추출 가능성을 결정한다. 컴퓨터 시스템은 이러한 것들을 실제로 실행할 수 있는지를 결정하며, 데이터와 모델 크기 측면에서 스케일링의 주요 제한 요소이다. 다음 세대의 foundation model을 효율적으로 학습하기 위해 알고리즘, 모델, 소프트웨어, 하드웨어의 공동 설계가 필요하며, 이런 과정은 이미 다양한 형태로 진행 중이다. 또한, foundation model 위에 응용 프로그램을 배포하는 것에 필요한 요소도 고려하고 있다.

**§4.6: Data.** 데이터는 foundation model의 생명력으로, 모델이 획득할 수 있는 능력을 결정한다. 최근 데이터 중심의 AI 요구사항은 데이터 관리와 이해, 문서화의 중요성을 강조하며, foundation model에 대한 투명성 부족 문제를 지적한다. 이를 해결하기 위해, 데이터 시각화와 관리 연구를 기반으로 foundation model을 위한 데이터 허브를 제안하며, 이는 선택, 큐레이션, 문서화, 접근, 시각화와 검사, 품질 평가, 법적 규제 등의 데이터 중심 고려사항과 관련이 있다.

**§4.7: Security and privacy.** 현재 foundation model의 보안과 개인정보 보호는 대부분 미개척 상태이다. 이 모델들은 고위험의 단일 실패 지점으로, 다양한 보안 취약점과 개인정보 보호 위험이 존재한다. foundation model의 일반성은 이러한 문제를 확대시키며, 이를 안전한 foundation model로 보완하는 방향으로 논의하고 있다. 또한, 공개 데이터에서 지식을 전송함으로써, foundation model은 개인정보 보호 응용 프로그램의 정확성 저하를 줄일 수 있다.

**§4.8: Robustness to distribution shifts.** 표준 머신러닝의 한계는 학습 분포와 테스트 분포가 일치하지 않을 때 강인하지 않은 모델을 생성한다는 것이다. 기존 연구에서는 레이블이 없는 다양한 데이터에 학습된 foundation model을 적응시키면 다양한 변화에 대한 강인성이 향상된다고 보여준다. 하지만, foundation model이 강인성에 대한 만병통치약이라고는 생각하지 않으며, 시간에 따른 extrapolation과 허위 상관관계 같은 문제는 완전히 해결되지 않을 것으로 예상한다.

**§4.9: AI safety and alignment.** foundation model이 신뢰성 있고, 강인하며, 해석 가능해야 하는 것이 점점 더 중요해지고 있다. 또한, 모델 능력이 발전함에 따라 foundation model과 큰 규모의 위험, 위험 요소, 피해 사이의 관계를 고려해야 한다. 예를 들어, foundation model을 명확하지 않은 목표나 가치로 배포하지 않도록 정렬하는 것이 중요하며, foundation model의 긴발적인 행동을 예측하는 것이 특정 작업에 대한 적응을 복잡하게 만들 수 있다. 이는 해석 가능성 또는 평가에 대한 새로운 접근 방식을 필요로 한다.

**§4.10: Theory.** 학습 이론은 적용 머신러닝의 다양한 맥락에 대한 폭넓은 기초를 제공한다. 현재 foundation model의 연구는 대체로 경험적이며, 표준 감독 학습 이론이 foundation model을 완전히 설명하기에는 부족하다. 특히, 학습 단계와 적응 단계 사이의 차이는 기존 이론의 불충분함을 보여주는데, 이는 이 단계들이 완전히 다른 작업과 데이터 분포를 대응할 수 있음을 의미한다. 그러나 이 차이를 해결하기 위한 이론적 발전은 제한된 설정에서도 유용한 인사이트를 제공할 것으로 기대하고 있다.

**§4.11: Interpretability.** 해석 가능성은 foundation model의 이해를 돕는 중요한 요소이다. 이는 모델의 행동을 해석하고 설명하는 데 필요하며, 특히 다양한 작업에 유익하고 예상치 못한 특성을 가진 모델의 특성 때문에 중요하다. foundation model과 그 파생 모델 사이의 의사결정 구성 요소를 공유하는 정도를 결정하는 "the one model-many models" 패러다임을 제안한다. 또한, 모델이 생성하는 설명의 타당성과 모델 행동을 이끄는 메커니즘에 대해서도 더 깊이 논의한다. 이 모든 것을 통해 foundation model의 해석 가능성과 그 사회적 영향에 대한 평가를 마무리한다.

### Overview of society.

foundation model의 발전은 다양한 분야에 적용되며, 이로 인해 사회에 큰 영향을 미칠 것으로 예상된다. 이러한 AI 모델들이 흥미롭지만 동시에 고민거리인 이유는 과제에 대한 중립성 때문이다. 특정 시스템의 사회적 영향을 이해하는 것은 상대적으로 쉽지만, foundation model을 개발하면서 가능한 모든 시스템과 사용 사례의 사회적 영향을 어떻게 고려할지는 복잡한 문제이다.

**§5.1: Inequity and fairness.** 기계 학습은 종종 사회적 불평등을 증폭시키는 경향이 있다. foundation model은 이러한 문제를 확대할 수 있으며, 이는 역사적으로 차별 받은 사람들에게 더욱 불공정한 상황을 만들 수 있다. foundation model은 사용자에게 영향을 미치는 응용 프로그램에 적응하도록 설계된 중간 자산으로, 이로 인해 편향과 해가 발생할 수 있다. 이러한 문제를 해결하기 위해, 다양한 원인을 분류하고, 기술적인 개입과 반응적인 구제를 동시에 고려하며, 불공정함이 foundation model 패러다임에서 불가피하지 않다고 주장한다.

**§5.2: Misuse.** foundation model의 오용은 기술적으로 의도된 방식으로 이를 사용하지만, 사회적 해를 끼치는 목표(예: 디스인포메이션 생성, 딥페이크 개발 등)를 가지고 이루어진다. foundation model의 발전은 오용을 위한 더 높은 품질의 기계 생성 콘텐츠를 더 쉽게 만들고 개인화하는 것을 가능하게 한다. 이는 기존의 해로운 콘텐츠 감지 방법을 제한할 수 있지만, foundation model 자체가 자동 오용 감지의 가능성을 제공할 수 있다.

**§5.3: Environment.** foundation model은 계산 비용이 많이 드는 학습 과정에서 생성되며, 이로 인해 대기 중에 탄소가 더 많이 방출되고 환경이 저하된다. 현재의 논의는 큰 학습 비용과 이러한 비용을 반복 사용에 분산시킬 수 있는 가능성에 초점을 맞추고 있다. 이에 대해, 환경적 영향을 계산하는 가정을 식별하여 이 논의를 명확히 하려고 한다. 또한, foundation model의 환경적 영향을 줄이기 위해 더 효율적인 모델과 하드웨어, 에너지 그리드의 필요성, 환경 비용을 평가 요소로 포함시키는 것, 그리고 환경 영향에 대한 cost-benefit 분석을 위한 더 큰 문서화와 측정의 필요성을 주장한다.

**§5.4: Legality.** 현재 foundation model은 불확실한 법적 상태에 있으며, 이 모델의 개발과 사용에 대한 법적 영향은 대체로 불명확하다. AI 기술과 특히 foundation model에 대한 법률 및 규제 체계가 필요하며, 이는 연구, 개발, 배포의 관행을 제어하고 촉진하는 데 중요하다. 알고리즘 도구에 대한 법적 판단이 불확실한 미국을 중심으로, 모델 예측의 책임과 모델 행동에 대한 보호 문제가 중요하다는 것을 강조하며, 이 두 문제를 해결하기 위해 법적 기준이 발전해야 한다고 설명하고 있다.

**§5.5: Economics.** foundation model은 그들의 혁신적인 능력과 다양한 분야에서의 잠재적 응용으로 인해 큰 경제적 영향을 미칠 것으로 예상된다. 이는 생산성, 임금 불평등, 소유권 집중 등의 측면에서 미국 및 전 세계 경제의 미래에 영향을 미칠 것이다.

**§5.6: Ethics of scale.** foundation model의 널리 퍼진 적용은 불평등 증가의 위험 외에도 다른 윤리적, 정치적, 사회적 우려를 불러일으킨다. 이에는 응용 규모와 관련된 윤리적 문제인 동질화와 권력의 집중, 그리고 이를 해결하기 위한 적절한 규범과 출시 전략이 포함된다.

---

## CAPABILITIES

foundation model은 학습 과정에서 생겨난 능력을 통해 다양한 응용 프로그램을 지원한다. 이에는 언어와 시각 능력, 물리적 세계에 영향을 미치는 능력, 추론 및 검색을 수행하는 능력, 그리고 인간과의 상호 작용 능력이 포함되며, 이 모든 것은 자기 감독이라는 기술적 접근법과 철학적으로 연결된다.

### Language

#### The nature of human language.

언어는 인간의 사고, 사회적·감정적 관계 형성, 자아식별, 지식 기록 및 사회적 지능 발전에 중추적인 역할을 한다. 모든 인간 사회에서 발생하는 말하거나 수화하는 언어는 놀라운 다양성과 풍부함을 보여준다. 언어는 복잡하면서도 효율적인 시스템이며, 어린이들은 이를 짧은 시간 동안 습득한다. 이러한 언어의 중요성 때문에, 자연어 처리(NLP)는 인공지능 연구에서 핵심 요소로, 컴퓨터가 인간 언어를 이해하고 생성하는 능력을 부여하는 것을 목표로 한다.

2021년까지, 자연어 처리(NLP)는 foundation model에 큰 영향을 받았다. 첫 세대 foundation model들은 다양한 언어 능력과 광범위한 언어 상황에 대한 적응성을 보였다. 2018년 초기 foundation model인 ELMo와 BERT 소개 이후, NLP 분야는 foundation model을 중심으로 발전하였고, 일반화된 언어 학습을 주요 목표로 삼았다. 이에 따라, foundation model이 언어용 머신러닝 모델 학습의 전반적인 과정을 변화시키며, 보다 넓은 범위의 언어와 복잡한 언어 상황에 적용될 때 직면하는 도전에 대해 논의하고 있다.

#### Impact of foundation models on NLP

foundation model들은 NLP 분야에 큰 영향을 미치고 있으며, 뛰어난 언어 생성 능력을 갖추고 있다. 하지만 그들의 가장 큰 특징은 원시적인 생성 능력이 아니라 놀라운 일반성과 적응성으로, 단일 foundation model이 다양한 방식으로 적응되어 여러 언어 작업을 수행할 수 있다는 것이다.

자연어 처리(NLP) 분야는 전통적으로 복잡한 언어 작업을 위한 시스템을 정의하고 구축하는 데 초점을 맞추었다. 이러한 작업에 능숙한 모델이 downstream 응용 프로그램에 대한 유능한 언어 시스템이 될 것이라는 전망이었다. NLP 작업은 문장이나 문서를 분류하는 작업, 시퀀스 라벨링 작업, 범위 관계 분류, 그리고 입력에 기반한 새로운 텍스트를 생성하는 작업 등을 포함하며, 과거에는 각 NLP 작업에 대해 고유한 연구 커뮤니티가 작업 특정 아키텍처를 개발하였다.

현대적인 접근법은 하나의 foundation model을 사용하고, 각 작업(감정 분류, 엔티티 태깅, 번역, 요약 등)에 특화된 소량의 주석이 달린 데이터로 약간 수정하여 적응 모델을 만드는 것이다. 이 방식은 대부분의 작업에서 특정 작업에 약간 적응한 foundation model이 특정 작업을 수행하기 위해 특별히 만들어진 이전 모델이나 모델 파이프라인을 크게 능가하는 것으로 입증되었다. 예를 들어, 2019년에는 적응된 foundation model이 NY Regents 8학년 과학 시험에서 91.6%를 기록하여 2018년의 73.1%보다 크게 향상되었다.

언어를 생성하도록 학습된 foundation model의 등장은 NLP에서의 언어 생성 역할에 중요한 변화를 가져왔다. 이전에는 일반적인 목적의 언어 생성이 매우 어려운 문제로 여겨졌지만, 현재는 "predict the next word in this sentence"와 같은 간단한 언어 생성 목표를 가진 foundation model을 학습시킬 수 있다. 이러한 생성 모델은 언어에 대한 기계 학습의 주요 수단이 되었으며, 요약과 대화 생성과 같은 언어 생성 작업에 대한 연구를 촉진하였다. 또한, foundation model 패러다임은 구어와 문어 모두에 걸쳐 비슷한 역할을 하게 되었으며, 대규모 음성 오디오 데이터셋에서 학습된 automatic speech recognition(ASR) 모델은 ASR 작업에 적응하게 되었다.

foundation model 패러다임의 변화로 인해, NLP 분야의 연구와 실무는 개별 작업을 위한 맞춤형 아키텍처 개발에서 foundation model을 최대한 활용하는 방향으로 전환되었다. 적응 방법에 대한 연구가 확대되었고, foundation model의 놀라운 성공으로 인해 foundation model을 분석하고 이해하는 연구에 대한 관심이 증가하였다.

#### Language variation and multilinguality.

foundation model은 사전 학습을 통해 얻은 언어 지식을 통해 다양한 작업을 수행할 수 있지만, 이 적응성에는 한계가 있다. 언어는 세계에 수천 가지가 넘는 다양한 언어, 한 언어 내의 다양성, 심지어 한 사람이 사용하는 언어의 변이 등 매우 다양하다. 이런 다양성을 공정하게 대표하고 각 언어의 독특함을 존중하고 정확하게 표현하는 foundation model을 만들 수 있는지는 여전히 해결해야 할 연구 과제이다. 그러나 언어 정보를 학습하고 유연하게 적응하는 능력을 가진 foundation model은 NLP를 더 많은 언어 다양성을 포괄하게 확장하는데 유망하다.

영어를 넘어 비영어 언어에 대한 성공을 확장하기 위해 다양한 언어를 지원하는 foundation model이 개발되었다. 대부분의 세계 언어는 대규모 foundation model을 학습시키기에 충분한 텍스트 데이터가 없지만, 이 문제는 여러 언어를 동시에 학습하는 다양한 언어를 지원하는 foundation model로 해결하려고 노력하고 있다. 이러한 모델은 언어 간에 공유되는 구조와 패턴을 바탕으로, 자원이 많은 언어에서 자원이 적은 언어로 지식을 전달하며, 이로 인해 독립 모델을 학습시킬 수 없는 언어에 대해서도 기초 모델을 가능하게 한다. 이런 접근 방식은 다양한 언어 간에 놀랄 만큼 많은 양의 지식 전달과 병렬 인코딩이 가능함을 실험적으로 입증하였다.

다양한 언어를 지원하는 모델이 얼마나 견고한지, 영어와 크게 다른 언어나 언어 자원이 적은 언어를 얼마나 잘 대표할 수 있는지는 아직 미해결된 문제이다. 이러한 모델들은 학습 데이터에서 가장 많은 자원을 가진 언어와 유사한 언어에서 더 높은 성능을 보이는 경향이 있다. 또한, 다양한 언어를 지원하는 모델에서 언어들이 모델 parameter를 경쟁하며, 이로 인해 하나의 모델이 얼마나 많은 언어 변이를 수용할 수 있는지는 불확실하다. 이런 문제는 학습 데이터의 불균형에서 기인하는데, 영어 데이터가 다른 언어에 비해 월등히 많고, 더 깨끗하며, 더 깊이 있는 언어적 복잡성을 보여주는 예시를 포함하고 있기 때문이다. 그러나 답은 단순히 더 균형잡힌 코퍼스를 만드는 것이 아니라, 불균형한 데이터에도 불구하고 언어 변이를 견고하게 처리하는 데에 있다.

현재의 다양한 언어를 지원하는 foundation model들은 언어의 미묘한 부분을 완전히 모델링하지 못할 수 있음에도 불구하고, 일부 다양한 언어 응용 프로그램에 유용하게 사용된다. 특히, 자원이 적은 언어에 대한 다양한 언어 모델을 적용하는 데 효과적이다. 그러나 연구 커뮤니티는 foundation model이 언어 변이를 어떻게 처리하는지, 그리고 NLP에 공정성과 대표성을 어떻게 가져오는지에 대해 비판적으로 검토해야 하며, 언어 변이를 지우고 학습 데이터의 언어적 다수에 부합하는 foundation model을 단순히 추진하는 것에 안주해서는 안 된다.

#### Inspiration from human language acquisition.

foundation model들은 인간처럼 행동하는 NLP 시스템을 만드는 데 큰 진전을 이루었지만, 그들이 습득하는 언어 시스템과 학습 과정은 여전히 인간의 언어와 중요한 차이를 보인다. 이 차이점의 영향을 이해하는 것은 foundation model의 언어적 한계와 가능성에 대해 알고 있는 연구 커뮤니티를 발전시키는데 필요하다.

인간의 언어 습득은 매우 효율적인 반면, foundation model들은 인간보다 훨씬 많은 언어 데이터를 학습한다. 인간의 언어는 실제 세계에 근거를 두고 있지만, foundation model들은 원시적이고 근거 없는 텍스트의 분포 정보를 학습한다. 이 차이를 이해하고 근거 있는 언어 학습을 발전시키는 것은 foundation model 연구의 중요한 미래 방향이다. 또한, foundation model의 귀납적 편향과 인간의 마음의 귀납적 편향 사이의 관계를 조사하는 것도 중요한 연구 방향이다.

인간의 언어 습득은 체계적이고 일반화 가능한 시스템을 효율적으로 배우는 것이다. 반면, foundation model은 이러한 체계적 추상화를 항상 습득하지 않는다. 실제로, 모델이 한 번 언어 구조를 정확하게 생성했다 해도, 특히 주제가 크게 변했을 때 그 구조의 일관성이 보장되지 않는다. 따라서, NLP는 foundation model에 대한 체계적인 언어 습득 방법을 개발하는 도전을 직면하고 있다.

인간의 언어 학습은 생애 동안 계속되고, 새로운 언어 상황에 유연하게 적응하며 언어 문법을 진화시킨다. 반면, foundation model의 언어 시스템은 학습 데이터에 의해 설정되며, 상대적으로 고정적이다. 대량의 학습 없이 foundation model의 언어적 기반을 바꾸는 방법은 아직 불확실하며, 이는 foundation model의 미래 연구 분야에서 중요한 과제이다.

foundation model들은 NLP 분야를 크게 변화시켰고, 많은 새로운 연구 방향을 제시하였다. 이들은 언어 생성의 이해, foundation model의 효과적인 활용 및 이해, NLP에서의 불평등 증가 가능성, 언어 변화와 다양성의 포괄, 그리고 인간의 언어 학습 동적을 활용하는 방법 등에 대한 연구를 촉진하였다. 그러나 foundation model의 성능과 복잡한 하류 환경에서의 유용하고 안전한 배포를 위한 요구 사항 사이에는 여전히 큰 차이가 있다.

### Vision

비전은 생물체가 환경을 이해하는 주요 방법 중 하나이다. 이를 기계에 적용하는 것은 어려운 문제로 여겨졌지만, 실제로는 AI에서는 어려운 문제가 쉽고, 쉬운 문제가 어렵다는 역설이 있다. 이 역설 중 가장 쉬운 문제는 매일 수 밀리초 동안 복잡한 장면을 해석하는 시각 능력이다.

컴퓨터 비전은 자율주행 차량, 의료 분야의 AI 도구, 멀티미디어 생성 및 편집 도구 등 혁신적인 응용 프로그램에 필수적이다. 이는 교통 체증 해소, 희귀한 의료 사건 감지, 차세대 멀티미디어 도구 개발 등에서 변화를 가져올 수 있음을 보여준다.

컴퓨터 비전 분야는 인간의 인지 능력에서 많은 영감을 얻는다. 여러 고전 이론들은 인간이 부분들을 더 큰 전체로 맥락화하여 실세계를 인식하며, 이는 컴퓨터 비전 기법이 물리적 세계를 점차 더 높은 수준의 추상화로 모델링하게 한다. 또한 인간의 시각은 본질적으로 신체화되어 있으며 상호작용적인 생태환경이 중요한 역할을 할 수 있다. 이러한 아이디어는 세계에 대한 맥락적이고 상호작용적인 인식을 향해 컴퓨터 비전 시스템의 지속적인 발전을 이끌고 있다.

컴퓨터 비전의 foundation model은 다양한 소스와 센서에서 얻은 원시 인식 정보를 시각적 지식으로 변환한다. 이는 ImageNet의 도입과 지도 학습 사전학습의 시작에 따른 딥 러닝 패러다임의 전환을 반영하며, 이는 고전적인 접근법을 넘어 대량의 데이터를 한 번에 학습하고 다양한 작업에 적용할 수 있는 모델로 전환하였다. 이런 아이디어는 여전히 foundation model의 핵심이다.

전통적인 지도 학습 기법의 한계로부터 foundation model이 등장하였다. 이는 비싼 비용과 세밀한 레이블링에 의존하는 대신, 대량의 원시 데이터를 활용해 시각적 세계를 이해하는 자기 지도 학습의 진보를 반영한다. 현재 비전 foundation model의 능력은 초기 단계에 있지만, 일반화 능력 향상 등의 전통적인 컴퓨터 비전 작업에서의 개선이 관찰되고 있다. 장기적으로 보면, foundation model은 명시적 주석의 의존성을 줄이고, 상식적 추론과 같은 핵심 인지 능력의 발전을 가능하게 할 수 있다. 이는 앞으로의 중요한 도전과 연구 전선을 정의하는 데 중요한 역할을 한다.

#### Key capabilities and approaches.

컴퓨터 비전은 기계가 시각적 세계를 이해하고 해석하는 능력을 부여하는 인공지능의 핵심 분야이다. 이는 이미지 분류, 객체 감지, 시맨틱 세그멘테이션 등의 시맨틱 이해 작업, 깊이 추정, 모션 구조 등의 기하학적 및 3D 작업, 그리고 시각적 질문 답변, 이미지 캡션 등의 다중 모드 통합 작업을 포함한다. 이 분야는 지난 수십 년 동안 지속적으로 발전해 왔다.

컴퓨터 비전 작업을 해결하는 주요 방식은 큰 데이터셋에서 모델을 사전 학습한 후, 작업 특정 데이터셋과 도메인에 맞게 모델을 미 조정하는 것이다. 이 접근법은 외부 감독 주석에 의하며, 이는 모델이 다양한 시각적 입력을 확장 가능고, 견고하고, 일반화 가능한 방식으로 캡처할 수 있는 한계를 제한한다. 이에 대한 대안으로, GAN 같은 비감독 학습 기술이 등장하였고, 이는 이미지 컬렉션만으로 고품질의 시각적 콘텐츠를 생성하는 방법을 배울 수 있다. 또한, 변이형 자동 인코딩, 대조 학습 등의 self-supervision을 사용하여 객체와 장면의 시각적 속성을 명시적인 감독 없이 추론하는 신경 모델도 발전하고 있다.

foundation model과 self-supervision은 큰 규모의 시각 데이터에서 학습을 가능하게 해, 범위와 다양성을 모두 증가시켰다. 이로 인해 이미지 분류와 객체 감지 등의 작업에서 향상된 성능을 보고하였고, 이는 학습 중 명시적인 주석 없이, 적응 중 더 큰 샘플 효율성을 보여준다. 또한 DALL-E와 CLIP 가이드 생성과 같은 시각적 합성에서 주목할 만한 발전이 있었다. 단기적으로, 학습 목표 개선과 아키텍처 설계 개선을 통해 foundation model의 능력이 계속해서 개선될 것으로 예상된다.

현재 컴퓨터 비전을 위한 foundation model은 초기 단계에 있지만, 물리적 장면 이해, 시각적 상식과 시간적 이벤트에 대한 추론, 사회적 affordance를 위한 지각 등의 고차 목표에 대한 진전을 보이고 있다. 이러한 작업은 대규모로 주석 처리하는 것이 어려워 도전적이지만, 명시적인 주석에 의존성을 줄이는 foundation model은 이러한 목표에 대한 더 많은 진전을 가능하게 할 수 있다. 언어 이벤트에 대한 상식을 어느 정도 포착한 언어 foundation model의 진전이 비슷한 능력을 시각 입력에 대해 달성하는 가능성을 보여주며, 새로운 아키텍처, 대규모 학습, self-supervision, few-shot 적응 체계의 결합은 이전에 도달하기 어려웠던 능력을 향해 문을 열 수 있다.

#### Central research challenges.

연구 과제는 foundation model이 비전 모델의 통합과 영향을 확대시킬 수 있는 응용 도메인에 초점을 맞추고 있다. 건강 관리와 가정 환경을 위한 주변 지능, 모바일 및 소비자 응용 프로그램, 실체화된 상호작용 에이전트 등이 주요 영역이다. foundation model은 인간 활동과 의료 이벤트의 세밀한 감지, 보조 상호작용의 개선에 잠재력을 가지며, 다중 모드 기반의 강화는 모바일 환경에서의 서비스 상호작용을 개선하고, 비전과 언어 입력에서의 생성 능력의 개선은 컴퓨터 사진술과 콘텐츠 편집에 이점을 줄 수 있다. 로봇 설정에서 이미 입증된 지각 모델은, 대규모의 시선 중심 비주얼 데이터 학습을 통해 비전 장면, 객체, 행동의 더 넓은 분포를 포착하여 진전을 촉진시킬 수 있다.

foundation model이 이러한 응용 설정에 얼마나 더 큰 영향을 미칠 수 있는지는 §2.2.1: 비전 능력에서 개요한 능력이 어느 정도 실현되는지에 달려 있다. 현재, 단기, 장기 예상 능력 사이의 큰 차이를 메우기 위해서는, 비전을 위한 foundation model의 현재의 한계, 그중에서도 그들의 학습과 평가를 다루어야 한다. 아래에는 해당하는 주요 도전 과제의 일부를 나열하였다:

**Semantic systematicity and perceptual robustness.** 인간은 보이지 않는 구성 요소에 대한 이해를 일반화하고, 새로운 객체와 장면의 물리적, 기하학적 특성에 대해 추론하는 능력을 가지고 있다. 현재 foundation model들은 이미지 합성과 세밀한 언어 입력에 대한 일반화에서 초기 성과를 보이고 있지만, 단순한 형태와 색상의 구성 요소에 대한 일반화는 여전히 어렵다. foundation model은 장면과 객체의 기하학적 이해에 대한 초기 단계를 보여주었으며, 다양한 모드(예: 오디오)의 지속적인 통합은 이러한 목표를 위해 유익할 수 있다. 그러나, 초기에 관찰된 능력을 인간 수준의 자연 장면과 객체에 대해 견고하게 일반화하는 기법은 여전히 개방된 연구 과제이다.

**Computational efficiency and dynamics modeling.** 인간은 이벤트의 동력학을 이해하기 위해 필요한 시각적 흐름을 놀랍도록 효율적으로 처리한다. 언어에 대한 foundation model들은 이벤트의 장기적일관성을 모델링하는 초기 단계를 보여주었으며, 이와 유사한 능력은 로보틱스 등의 다른 분야에도 이점을 줄 수 있다. 그러나 컴퓨터 비전 입력은 극도로 고차원적이며, 이를 처리하는 단순한 접근법은 제한적일 수 있다. 현재의 비전 모델들은 이미지 패치나 프레임 그룹을 요약하는 방식으로 이를 처리하고 있지만, 이는 세부적인 정보를 잃을 수 있다는 단점이 있다. 따라서, 원시 입력 공간을 고려하는 것 외에도, 비전을 위한 foundation model들은 효율적이고 효과적인 모델링을 위한 기본 아키텍처의 디자인을 재검토해야 할 필요가 있다. 또한, 이러한 모델들을 다양한 응용 분야에 적용하기 위해서는 시스템 디자인의 발전이 필요하다. 결국, 더 큰 규모의 동적 비전 입력을 효율적이고 효과적으로 모델링하는 것은 앞으로 해결해야 할 복합적인 연구 과제이다.

**Training, environments, and evaluation.** foundation model의 잠재력을 실현하기 위해서는 그들을 학습하고 평가하는 지원 요소가 중요하다. 현재의 비전 foundation model들은 주로 가장 접근하기 쉬운 RGB 이미지와 텍스트 데이터에 초점을 맞추고 있다. 이는 넓은 범위의 모달리티에서 다양한 입력을 수집한 대규모 학습 데이터셋의 개발을 촉진하고 있다. 입력의 품질은 모델의 학습 효율성에 영향을 미치며, 다른 유형의 foundation model을 활용하는 기법은 품질 향상에 약속적이다. 또한, 정적 데이터셋을 넘어 생태적 설정과 상호작용에 연결된 인간의 지각 이해를 고려해야 한다. 이를 위해, 물리적, 시각적, 생태적 현실성을 포착하는 시뮬레이션 환경의 지속적인 개발이 중요하다. 마지막으로, 생성적 foundation model 출력의 충실성을 어떻게 평가할지에 대한 메트릭 문제가 있다. 표준 메트릭들은 알려진 결함이 있으며, 인간의 판단을 평가에 포함하는 것도 한 가지 방법이지만, 비용이 많이 들고 확장성이 떨어질 수 있다. 이러한 비전 foundation model에 대한 학습, 데이터, 평가 설정의 미해결 과제와 도전은 앞으로 연구의 중심 분야가 될 것이다.

**Concluding remarks.** 이 섹션에서는 컴퓨터 비전과 관련된 foundation model을 탐구하였고, 그것들의 현재와 예상 능력을 맥락화하며, 앞으로의 연구 방향을 제안하였다. 컴퓨터 비전 기법의 발전은 사회적으로 파괴적인 영향력을 가질 수 있으며, 이에 따라 그 위험성을 신중하게 고려할 책임이 생긴다. 컴퓨터 비전 모델에서의 학습된 편향, 개인정보 보호와 감시에 대한 우려, 그리고 딥페이크 이미지와 오정보에 대한 위험은 foundation model의 중요한 문제로 지속적으로 논의되고 있다. 컴퓨터 비전과 foundation model에 대한 도전과 기회가 많지만, 이러한 위험을 동시에 다루는 것이 필수적이다.

### Robotics

로봇이 실제 세계의 다양한 조건을 처리할 수 있도록 하는 것은 로봇 연구의 주요 도전 과제입니다. 이를 위해 일반적인 로봇을 만들기 위한 foundation model의 아이디어가 중요하며, 이는 기존의 foundation model만으로는 충분하지 않다. 여기서는 로봇이 자신의 물리적 형태를 제어하여 다양한 작업을 성공적으로 수행하는 문제에 foundation model을 어떻게 적용할 수 있는지 중점을 두었다. 이는 고차원적이고 폐루프 결정 문제로, 로봇의 행동이 다음에 인식하는 것에 직접적으로 영향을 미친다. 이러한 새로운 유형의 로봇 foundation model은 제조, 건설, 자율 주행, 가정 도움, 개인 보조 등 일상 생활의 주요 측면을 향상시킬 로봇의 잠재력을 증폭시킬 수 있다. 이 논의는 주로 가정용 작업을 위한 이동 조작 로봇에 초점을 맞추고 있지만, 다른 로봇 사용 사례에도 적용 가능하다고 생각된다.

로봇학의 새로운 foundation model을 구축하는 중요한 단계는 작업 지정 및 학습에 대한 기회를 활용하고, 데이터 수집과 안전성, 견고성에 대한 도전을 동시에 다루는 것이다. 사용자가 로봇에게 원하는 작업을 설명하고, 그에 따른 로봇 행동을 생성하는 정책을 학습하는 것이 일반적인 패러다임이다. 이 정책은 작업 표현과 환경 관찰을 로봇 행동으로 매핑하는 함수로 parameterize 된다. 로봇은 작업 조건에 따라 행동하고, 이 행동은 다음 상태와 함께 정책으로 피드백되어 작업이 완료될 때까지 더 많은 행동을 생성한다.

로봇 학습 패러다임을 실제로 구현하는 것은 어려운 과제이다. 사용자의 목표를 명확하게 설명하는 적절한 인터페이스가 필요하며, 이는 종종 모호성을 도입할 수 있다. 이러한 모호성을 해결하고 로봇이 주어진 작업을 수행하도록 목표를 명확하게 지정하는 방법이 필요하며, 비슷한 목표로 일반화가 가능한 일반적인 작업 표현을 만드는 방법도 필요하다. 더 나아가, 새로운 작업과 환경에 대한 정책을 학습하는 로봇을 돕는 방법을 구축해야 한다.

언어와 비전에 대한 foundation model을 적용하는 최근의 발전은 대규모 자가 감독 사전 학습이 일반화를 개선하는 데 있어 잠재적 이점을 제안한다. 다양한 데이터를 활용해 작업 지정에 필요한 로봇 foundation model을 학습하는 것이 가능하다. 다양한 로봇 상호작용 데이터를 이용해 일반적이고 의미 있는 스킬을 학습할 수 있다. 하지만 이런 기회들에도 불구하고, 적절한 데이터 수집이 주요한 장애물로 남아 있다. 로봇학 데이터는 풍부하지 않고, 다양한 환경을 대표하지 못한다. 아직 일반적인 로봇학을 가능하게 하는 가장 유용한 데이터 유형에 대해 합의하지 못했다. 또한, 적절한 규모와 다양성의 데이터를 얻는 문제와 함께, 새로운 환경에서 안전하게 행동하는 방법에 대한 문제도 있다.

로봇학에 대한 새로운 foundation model 구축은 작업 지정과 학습에 대한 기회와 데이터 수집 및 안전한 배포에 대한 도전 사이의 균형을 찾는 것으로 이루어진다. 이는 로봇 foundation model이 어떻게 일반적인 로봇 개발에 도움이 될 수 있는지를 보여주는 동시에, 이러한 시스템을 구축하는데 있어서의 도전을 의미 있게 해결하고, 다중 모달성(인식, 행동, 언어의 통합) 및 인간-로봇 상호작용의 잠재력을 강조한다.

#### Opportunities

로봇 foundation model은 다양한 형태를 가질 수 있다. 로봇학 문제는 각각 다른 입력-출력 특성을 가지므로 일괄적인 모델에 적용하기 어렵다. 이와는 달리, 많은 NLP 문제는 "텍스트 입력, 텍스트 출력"의 일반적인 형태로 표현할 수 있다. 작업 지정과 작업, 환경, 로봇 구현체 간의 학습에 있어서 일반화 가능성에 초점을 맞추고 있다.

**Foundation models for task specification.** 로봇이 일반적으로 작업을 해결하려면 먼저 원하는 작업이 무엇인지 이해해야 한다. 따라서, 범용 로봇을 개발하는 첫 단계는 신뢰할 수 있는 작업 명세를 위한 새로운 foundation model을 구축하는 것이다. 이는 작업 목표, 선호도, 제약사항을 효과적으로 전달하는 과정이다. 작업 명세는 인간이 제공한 작업 설명을 로봇의 작업 완료와 진행을 측정하는 지표로 변환하는 과정이다. 이 신호는 로봇 행동을 최적화하고 실패를 진단하며 인간 피드백을 요청하는데 필수적이다. 로봇 foundation model은 사용자, 환경, 작업에 따라 다양한 작업 설명 방식을 수용해야 한다.

일반 목적의 작업 명세 모델은 새로운 환경과 작업에 적용할 수 있는 능력이 중요하다. 작업 설명을 로봇 학습을 위한 일반화 가능한 보상 신호로 변환하는 것은 아직 미해결 문제이지만, 로봇 foundation model이 잘 해결할 수 있을 것이다. 이 모델은 크고 광범위한 데이터셋에서 학습하여 강건한 보상 신호를 제공해야 하며, 보이지 않는 언어 지시사항과 환경에 일반화할 수 있는 능력을 갖춰야 한다. 이는 새로운 foundation model이 다양한 모달성을 능숙하게 연결하고 광범위하게 일반화하는 능력 때문에 일반 목적의 작업 명세에 매력적으로 보인다.

**Foundation models for task learning.** 로봇 foundation model은 일반적인 작업 명세를 가능하게 하며, 새로운 작업 해결 학습을 더 효과적이고 신뢰성 있게 만들 수 있다. 이러한 모델은 행동, 센서 관찰, 보상 등의 속성에 대한 공동 분포 형태를 취하며, 이 분포의 다른 차원에 조건을 부여함으로써 다양한 추론 문제를 복구할 수 있다.

* *Dynamics modeling*: $p(\text{future observations} | \text{actions, past observations})$
* *Policy learning*: $p(\text{actions} | \text{observations, goal})$
* *Inverse reinforcement learning*: $p(\text{reward function} | \text{observations, actions})$

로봇 foundation model의 학습 목표는 공동 분포의 요소를 자기회귀 방식으로 예측하는 것이다. 하지만, 이것이 유일한 방법은 아니다. 로봇 데이터셋에는 다양한 센서에서 동기화된 관찰과 로봇의 행동이 포함된 라벨이 없는 대량의 데이터가 있다. 이러한 데이터를 활용하여, 로봇 foundation model은 한 센서 모달리티에서 다른 모달리티의 관찰을 예측하거나, 두 개의 감각 관찰 스트림이 같은 시간 세그먼트에서 발생했는지 예측하도록 학습될 수 있다. 이는 고차원 데이터의 저차원 표현을 생성하는 데 도움이 될 수 있다. 이러한 목표는 데이터가 다양하고 의미 있는 행동을 보일 때, 라벨이 없는 데이터에서 강력한 로봇 foundation model의 학습을 돕는다.

언어와 시각 분야에서의 foundation model처럼, 로봇 foundation model도 다양한 데이터, 자기감독 목표, 다양한 모달리티를 활용하여 새로운 환경, 작업, 구현체에 대한 인식과 제어의 적응을 가능하게 할 수 있다. 예를 들어, 새 주방에서 로봇이 요리하려면 주방의 일반적인 특성을 이해하고 적응해야 한다. 이러한 상식 지식, 물리적 사전 정보, 시각적 사전 정보는 새로운 환경에 더 효율적으로 적응하는 데 도움이 될 수 있다. 그리고 이러한 foundation model을 개발함으로써, "달걀 후라이"와 같은 일반적인 기술에 대한 정책을 특정 사용자의 선호도에 맞게 적응시킬 수 있다. 마지막으로, 크로스-모달 표현을 학습하는 로봇 foundation model은 새로운 구현체에 적응하는데 도움이 될 수 있으며, 이런 적응력은 이러한 모델들의 널리 사용되는 중요한 요소이다.

#### Challenges and risks.

일반화를 위해 충분하고 다양한 로봇 데이터셋 수집이 필요하며, 학습된 행동을 실세계에서 안전하게 적용할 수 있는 방법도 필요하다.

**Data needs & challenges.** 로봇이 환경을 인식하고 작업을 수행하는 정책을 학습하는 것은 일반적으로 실세계에서 로봇의 상호작용에 대한 대규모 데이터셋이 필요하다. 하지만, 컴퓨터 비전과 자연어 처리의 많은 학습 작업은 웹에서 쉽게 수집할 수 있는 크고 다양한 오프라인 데이터셋에 의존한다. 이런 배경에서, 대규모 오프라인 데이터를 활용하여 새로운 로봇용 foundation model을 학습시키는 가능성에 흥분하고 있다.

이 목표를 달성하기 위한 한 방법은 원격 조작, 키네스테틱 교육, 자율적인 방법 등을 활용하여 대규모의 데이터셋을 수집하는 것입니다. 이 방법들은 일반화에 대한 유망한 징후를 보여주고 있다. 비전과 언어 데이터셋의 크기로 로봇 데이터 수집을 확장하는 것은 여전히 도전과제이지만, 로봇 데이터셋의 규모와 품질 증가는 로봇용 foundation model 학습에 중요한 역할을 할 것으로 보인다. 또한, 로봇은 환경을 형성하는 능력이 있으므로, 대량의 라벨 없는 데이터를 생성할 수 있어야 한다.

제어 학습의 복잡성 때문에, 로봇 공학에는 대규모 데이터셋이 필요할 수 있다. 인간의 비디오나 기존의 비전과 자연어 데이터셋과 같은 외부 데이터를 활용하는 것이 한 가지 해결책일 수 있다. 이러한 방식은 광범위한 일반화를 가능하게 할 수 있다. 그러나 로봇의 도메인과 웹상의 비디오나 언어 간의 차이를 해결하는 것은 여전히 도전 과제이지만, 도메인 적응과 사전 학습된 비디오 및 언어 모델의 활용이 이 문제를 해결하는 방향으로 진전되고 있다.

시뮬레이션은 로봇이 학습할 수 있는 풍부한 데이터를 제공하지만, 시뮬레이션과 실제 세계 사이의 물리적이고 의미론적인 차이를 극복하는 것은 큰 도전이다. 최근의 연구는 광범위한 도메인 무작위화를 통해, 시뮬레이션에서 배운 기술을 실제 로봇에 전달할 수 있음을 보여주었다. 그러나 이러한 시뮬레이션에서 실제로의 학습은 여전히 열린 문제이다. 시뮬레이션 데이터, 실제 로봇 데이터, 인간의 비디오, 자연어 데이터 모두 로봇 foundation model 학습에 중요할 수 있다.

**Safety & robustness.** 로봇을 위한 새로운 foundation model의 개발과 배포에서는 안전성과 견고성이 중요한 이슈있다. 실제 세계에서 로봇이 환경을 조작하고 상호작용하기 때문에, 예상치 못한 위험한 행동이 발생할 수 있다. 이를 해결하기 위한 한 가지 방법은 환경의 복잡성을 제한하거나 로봇의 복잡성을 높이는 것이다. 또한 로봇은 환경을 자동으로 재설정하여 대규모 데이터 수집에서 끊임없는 학습을 이어갈 수 있다. 이는 부서질 수 있는 항목이 없거나, 에이전트가 부술 수 있는 항목을 보장하고 교체하는 것을 의미한다.

로봇 foundation model의 위험을 줄이기 위해 미래에는 인과 분석 개발, 새로운 안전 평가 도구, 실제와 같은 시뮬레이션 환경 개발 등이 필요할 것이다. 또한, 로봇 모델에 대한 공식적인 안전 보장을 위해 Hamilton-Jacobi 도달 가능성 같은 안전 집합이나 학습을 위한 안전한 경계 개발 등이 도움이 될 것이다. 이런 연구와 개발이 진행됨에 따라 위험을 줄이는 해결책이 결정적으로 나타날 것이다.

**Conclusion.** 로봇 foundation model의 가능성은 무궁무진하지만, 그에 따른 도전과제도 많다. 다양한 환경과 구현체를 대규모로 다루는 데이터 수집과 시스템의 안전성 및 견고성 보장은 큰 난제이다. 그러나 이런 도전을 이제부터 대처하면, 모델 개발 이전에 바람직한 기능을 가진 신뢰할 수 있는 로봇 foundation model을 구축하기 위한 적절한 데이터를 적절한 출처에서 적절한 규모로 수집하는 방법을 발견할 수 있을 것이다.

이 섹션의 핵심은 다중 모달성이다. 로봇 foundation model은 AI의 다른 부분, 예를 들어 언어와 비전 분야에서의 연구로부터 이점을 얻었고, 계속 그럴 것이다. 하지만 다른 분야에서의 이러한 확장을 고려하면서, 실시간 로봇을 위한 모델 학습 및 배포, 견고한 인간-로봇 상호작용 인터페이스, 그리고 모델의 안전성과 견고성에 대한 이해 등에 대한 복합적인 도전이 나타난다. foundation model과 특히 로봇 foundation model에 대한 신뢰성 있는 생태계와 신중한 연구 방법을 구축하는 것이 이러한 목표를 실현하는 핵심이다.

### Reasoning and search

AI의 역사를 통해 추론과 검색은 핵심 주제였다. 초기에는 심볼릭 방법을 사용했지만, 복잡한 엔지니어링 노력과 검색 공간에 대한 휴리스틱의 형식화 필요성이 부담스러웠다. 최근에는 뉴럴 네트워크를 활용한 데이터 기반 방법이 뛰어난 결과를 보여주었다. 이 연구는 점점 더 큰 검색 공간으로 확장되고 광범위한 세계를 이해해야 하는 추론 작업을 개요하고 있다. 또한, foundation model이 일반적인 추론을 위해 중심 역할을 해야 한다고 주장한다. 이는 무한한 검색 공간의 통계적 규칙성을 포착하고, 다양한 작업과 시나리오 간의 긍정적인 전이를 가능하게 하며, 다중 모달 환경에서의 지식 구체화를 활용하기 때문이다.

#### What are the current tasks?

추론 문제는 종종 무한한 검색 공간을 제시하며, 시스템은 다양한 개방형 대안을 다루어야 한다. 예를 들어, 이등변삼각형에서 두 각이 같다는 것을 증명하는 경우, 시스템은 각 추론 단계에서 여러 가지 행동을 수행할 수 있다. 이러한 문제를 해결하는 한 가지 방법은 각을 이등분하는 선을 그리고 두 삼각형의 합동을 이용하는 것이다. 그러나 이를 찾기 위해선 광범위한 검색이 필요하다.

수학자는 다이어그램 구조나 유클리드의 정리에만 국한되지 않고, 다양한 수학 분야의 많은 정리를 적용하거나 고차원적인 추측을 만들어내고, 새로운 수학 개념을 형식화하거나 반례를 찾는 등의 활동을 한다. 이는 Go 게임과 같이 구조화된 AI 도전 과제와는 대조적으로, 그들의 검색 공간은 훨씬 더 넓다.

정리 증명, 프로그램 합성, 약물 발견, 화학 합성, 컴퓨터 지원 설계, 조합 최적화 등의 문제들은 무한한 검색 공간을 다루고, 비슷한 구조를 가지고 있다. 이들 문제는 합성의 트리를 구축하며, 이 트리의 노드는 각각 문제의 주요 요소를 나타낸다. 시뮬레이션 환경은 해결사가 솔루션 트리를 구축하고 중간 피드백을 통해 가장 유망한 검색 스레드를 선택하도록 돕는다.

최근에는 추론 문제를 해결하기 위해 학습 기반 접근법에 큰 관심이 있다. 이를 위해 연구자들은 처음에 제한된 검색 공간에서 시작했지만, 이러한 접근법은 해결사가 취할 수 있는 행동의 종류에 제한을 두었다. 대형 언어 모델이 출력 공간을 시퀀스로 모델링하므로, 임의의 행동을 생성할 수 있게 되어 더욱 선호되었다. 이러한 접근법은 단백질 구조 예측, 공식 정리 증명, 정리 추측, 자연어로부터의 프로그램 합성, 코드 수정 등 다양한 분야에 적용되었다. 또한, 모델 크기를 확장하고 언어 모델링의 표준 기법을 적용함으로써 이러한 작업에서의 성능을 크게 향상시킬 수 있음이 밝혀졌다.

#### What’s the role of foundation models?

**Generativity.** foundation model의 생성 능력은 효과적인 추론에 필수적이다. 무한한 검색 공간을 처리하는 대신, foundation model을 통해 최적의 결정 분포를 모델링하고 적절한 후보를 생성할 수 있다. foundation model이 출력 공간을 시퀀스로 모델링하므로, 다음 결정은 완전히 제약이 없다. 이런 유연성은 수학적 추측이나 새로운 프로그램 합성과 같은 창의적 생성을 가능하게 한다. foundation model의 크기를 늘릴수록 이런 통계 구조를 포착하는 능력도 크게 향상된다.

**Universality.** 많은 추론 문제들이 비슷한 구조를 가지고 있어 foundation model이 통합 프레임워크를 통해 다양한 작업에서 유용한 기법을 찾아내고 공유할 수 있다. 이 모델은 다양한 도메인에서 학습되었기 때문에 작업과 도메인 간에 메타 지식을 전달할 수 있다. foundation model 학습은 메타 지식 학습에, 적응 단계는 작업 특정 어휘 학습에 집중하므로, 학습 문제의 복잡성을 줄이고 일반화를 향상시킬 수 있다.

**Grounding.** 추론 문제는 종종 기호적 언어로 표현되지만, 이 기호들은 깊은 의미를 가지고 있다. foundation model은 이런 의미를 이해하고 다양한 데이터 소스(예: 이미지, 텍스트 등)를 통해 이를 표현할 수 있다. 하지만, 다른 모달 간의 연결을 비지도 학습 방식으로 찾아내는 것은 아직 해결되지 않은 문제이다. 또한, foundation model은 심볼릭 도메인 내에서 기호가 가지는 다양한 해석 수준을 학습할 수 있으며, 이는 고급 코드 스크립트의 내부 작동 원리를 이해하는 데 도움이 된다.

#### Future challenges in reasoning.

이 문제들의 복잡성 때문에 고품질 주석 데이터의 수집이 어렵다. 이를 해결하기 위해, 수학에서는 합성 정리를 생성하거나, 자가 감독 태스크를 설계하거나, 더 나은 사전 학습 목표를 설정하는 등 여러 방법이 제안되었다. 하지만, 이런 작업들은 대부분 특정 문제에 맞춰 조정되어 있어, 일반적인 원칙적 접근법은 아직 부족하다. foundation model을 구축하면, 모든 추론 문제에 적용 가능한 자가 감독 태스크를 만드는 통합 프레임워크를 만들 수 있다. 또한, 충분한 확장성이 있다면, 상호작용을 통해 학습 커리큘럼을 안내하거나 데이터 증가를 돕는 등, 사람들이 루프에 참여함으로써 데이터 부족 문제를 완화할 수 있다. 이러한 상호작용 도구는 교육 분야에서도 유용하게 활용될 수 있다.

foundation model의 고수준 추론 능력 향상은 핵심 도전 과제이다. 사람들은 복잡한 문제를 해결할 때 추상적인 추론과 고수준의 계획을 수립하는 데 반해, 기존 모델들은 주로 다음 단계를 예측하는 데 집중한다. 이로 인해 사람처럼 추론하는 foundation model을 학습시키는 데 데이터 수집에 대한 문제가 발생한다. 한 방향은 학습 도중 추상적이고 모듈화된 계층이 자연스럽게 나타나게 하지만, 이 접근법을 더 일반적이고 현실적인 설정으로 확장하는 방법은 아직 미해결된 문제이다.

추론을 위한 좋은 아키텍처는 무엇인지, 이러한 모델들을 이론적으로 어떻게 이해하고 해석할 수 있는지, 그리고 도메인 외 문제에 일반화할 수 있는 견고한 추론 모델을 학습시킬 수 있는지 등, 많은 미해결 문제들이 있다. 이러한 각각의 영역에서 foundation model에 대한 연구는 추론 분야에서 그들의 영향력을 크게 확장할 수 있다고 생각한다.

### Interaction

초기 foundation model들인 GPT-3와 DALL·E는 비전문가도 AI 애플리케이션을 만들고, 텍스트에서 이미지까지 다양하게 활용하는 능력을 보여주었다. 이러한 모델들이 발전함에 따라, AI와 상호작용하는 방식에 큰 변화가 예상되며, 이는 동적이고 생성적인 AI 애플리케이션을 더 빠르게 만드는 데 도움이 될 것이다. 이런 변화는 애플리케이션 개발자와 최종 사용자에게 새로운 기회를 제공하며, 개발자와 사용자 사이의 경계가 흐려지면서 사용자의 필요와 가치에 더욱 부합하는 AI 애플리케이션을 만들 수 있게 될 것이다.

#### Impact on AI-infused application developers’ development process.

foundation model들의 발전은 AI 애플리케이션 개발 방식을 변화시킬 것이다. 머신러닝 알고리즘의 큰 발전에도 불구하고, 새롭고 효과적인 인간-AI 상호작용을 설계하는 것은 여전히 어렵다. 강력한 특정 작업 모델을 만드는 데 필요한 데이터, 컴퓨팅 자원, 기술은 사용자의 필요와 가치를 파악하고 충족하는 반복적인 프로토타이핑 과정과 충돌할 수 있다. 이는 AI의 응답이 예측하기 어렵고, 방대한 출력을 만들어내며, 사람들이 이를 이해하고 활용하는 것을 어렵게 만든다. 이러한 도전을 해결하기 위한 일부 진전이 있었지만, 아직도 극복해야 할 장애물이 많이 남아 있다.

foundation model들은 애플리케이션 개발의 어려움을 줄이고, 비전문가들도 AI 애플리케이션을 빠르게 만들 수 있는 기회를 제공한다. 이 모델들의 강력한 생성적 능력은 상호작용의 품질과 다양성을 향상시킬 수 있다. 그러나, 이런 잠재력을 최대한 활용하기 위해서는 애플리케이션 개발자가 foundation model을 더 효과적으로 관리할 수 있는 방법을 찾아야 한다.

foundation model들의 일반화 능력과 높은 천장은 이들을 예측하기 어렵고 복잡하게 만들 수 있다. 최근의 연구에서는 이런 모델이 의도한 작업을 일관되게 수행하는 것이 어렵다는 것이 밝혀졌고, 이 모델이 어떤 것을 할 수 있는지 이해하는 것은 여전히 활발한 연구 주제이다. 그래서 미래의 연구에서는 foundation model에서 더 예측 가능하고 견고한 행동을 얻는 방법을 계속 탐색해야 한다. 이를 위해 미세 조정, 프롬프트 엔지니어링, 보정, 또는 특정 작업 지정 엔드포인트의 사전 형식화 등의 방법이 사용될 수 있다.

#### Impact on end-user interaction with AI-infused applications.

foundation model들은 사용자가 AI 결합 애플리케이션과 상호작용하는 경험에 변화를 가져올 것이다. 기존의 디자인 프레임워크는 사용자의 능력을 강화하는 데 초점을 맞추고 있으며, 이는 계속 중요하게 적용될 것이다. 사용자의 주체성을 유지하고 그들의 가치를 반영하는 것이 핵심이며, AI가 사용자의 일상을 자동화하는 이점과 사용자의 직접 조작을 기다리는 이점 사이에서 균형을 맞춰야 한다. 또한, 참여형 및 가치 민감형 디자인을 통해 사용자의 가치를 직접 수집하고 반영해야 하며, 이는 모든 이해관계자를 AI 애플리케이션 디자인 과정에 적극적으로 참여시키는 것을 의미한다.

foundation model은 예기치 않은 방식으로 행동하여 사용자와 커뮤니티를 놀라게 하거나 실망시키는 문제를 가지고 있다. 이는 모델의 생성 능력이 커뮤니티의 목표와 상반되는 편향을 드러내거나, 커뮤니티가 인식하지 못하는 방식으로 행동에 반영될 수 있기 때문이다. 따라서 foundation model을 사용하는 그룹들은 모델의 행동을 모니터링하고 적절하게 조정하는 것에 대한 큰 부담이 있다.

AI 결합 애플리케이션 디자인에 대한 기존 프레임워크는 사용자 능력 강화에 집중할 것이지만, foundation model의 강력한 생성 및 다중 모달 능력으로 인해 가능한 상호작용 형태는 크게 다양해질 것이다. 이미 초보 콘텐츠 제작자들이 고품질 멀티미디어를 생성할 수 있도록 하는 foundation model 기반의 소프트웨어 도구가 등장하고 있다. 개선된 foundation model은 더욱 야심찬 도구를 가능하게 하며, foundation model은 정적 멀티미디어를 풍부하게 만들고, 다양한 모달을 혼합하는 인터페이스를 사용한 새로운 형태의 상호작용을 이끌어낼 수 있다.

다양한 애플리케이션에서 foundation model이 어떻게 사용될 수 있는지의 예시를 보며, 새로운 상호작용 형태를 상상해보는 것이 중요해지고 있다. 이는 개별 사용자와 사회에 긍정적인 영향을 극대화하기 위함이다. foundation model이 의사소통 방식, 신뢰와 신원, 글쓰기 스타일을 어떻게 바꿀지, 콘텐츠의 저작권은 어떻게 처리될지, 그리고 이 모델이 우리의 일상, 언어, 문화에 어떤 장기적인 영향을 미칠지 등에 대해 신중하게 고려해야 한다. foundation model은 관찰된 데이터에 기반하여 학습되므로, 과거를 반복하는 것이 아니라 원하는 미래를 향해 나아갈 수 있도록 어떻게 활용할지도 중요한 고려사항이다. 이러한 문제들은 foundation model에만 국한되지 않지만, foundation model이 AI 애플리케이션의 효과적인 생성을 가속화함에 따라 이들 문제는 확대되고 일반화될 것이다.

#### Blurring the line between developers and end-users.

AI 모델 개발자와 최종 사용자 사이의 경계는 명확하며, 대부분의 경우 최종 사용자가 자신의 필요에 맞는 새로운 모델을 개발하는 능력이 부족하다. 일반적인 모델은 경우에 따라 충분하나, 최근에는 이러한 모델이 사용자를 충분히 서비스하지 못하는 경우가 증가하고 있다. 예를 들어, 특정 온라인 커뮤니티를 위해 설계된 텍스트 분류 모델이나 특정 대상 인구를 위한 AI 기반 센서와 로봇 도구는 문화나 필요가 다른 다른 커뮤니티나 사용자에게는 실패할 수 있다. 최근 연구는 사용자가 모델 parameter나 데이터셋을 수동으로 제공하여 AI 모델을 공동으로 만드는 방법을 탐색하고 있지만, 아직 초기 단계이며 대부분 기본적인 모델에 초점을 맞추고 있다.

foundation model이 AI 애플리케이션 구축의 난이도를 낮추면, 사용자가 모델의 개발 과정에 직접 참여하여 그들의 요구와 가치를 모델의 행동과 더 밀접하게 연결하는 기회를 제공할 수 있다. 예를 들어, GPT-3 같은 모델은 적절한 작업 설명이 주어지면 분류 작업을 견고하게 수행할 수 있다. 이를 활용하면, 온라인 커뮤니티는 자신들이 합의한 분류 작업 설명에 따라 콘텐츠를 필터링하는 맞춤형 AI 분류기를 만들 수 있다. 또한, foundation model의 강력한 컨텍스트 내 학습 능력은 사용자 별로 인터페이스를 더 효과적으로 최적화하는 데 도움이 될 수 있어, 인간-컴퓨터 및 로봇 상호작용 문제를 해결하는 새로운 가능성을 열 수 있다.

사용자와 개발자 사이의 경계를 흐리는 잠재력을 실현하기 위해선 foundation model의 기존 편향을 완화하고, 비 ML 전문가들도 모델을 안정적으로 관리할 수 있도록 하는 등의 중요한 도전이 남아 있다. 미래 연구는 foundation model을 상호작용적인 기계 학습 맥락에서 어떻게 활용할 수 있을지, 그리고 기계 학습 경험이 제한된 사람들이 이 모델을 견고하게 활용하도록 어떻게 지원할 수 있을지를 탐구해야 한다. 그러나, 최종 사용자가 AI 애플리케이션 개발에 참여하는 능력은 미래의 애플리케이션과의 상호작용 방식에 대한 새로운 패러다임을 제시하는 흥미로운 기회이다.

### Philosophy of understanding

foundation model이 학습 데이터를 어떻게 이해하는지는 그 모델이 얼마나 지능 시스템에 기여할 수 있는지를 보여준다. 특히, 인간의 지능과 경험에 중심적인 역할을 하는 자연 언어 측면에서 이를 살펴본다.

현재 우수한 AI모델들은 언어를 유창하게 다루지만, "“stochastic parrots"처럼 일관성 없는 행동을 보인다. 이것이 본질적 한계를 나타내는지, 아니면 미래 모델이 실제로 기호를 이해하게 될지는 미지수이다.

이 섹션은 AI foundation model에 대한 질문을 명확히 하고, 그에 관한 논의를 구조화하는 것을 목표로 한다. foundation model의 의미와 학습 방식, 그리고 이런 질문 명확히 하는 것이 모델 발전에 중요한 이유를 논의한다. 마지막으로, 이해라는 개념을 명확히 하며, 이해의 본질과 모델이 이해를 달성했다는 것을 어떻게 판단할지에 대해 다룬다.

미래 AI 모델이 자연어를 이해할 수 없을 것이라는 회의론이 성급할 수 있다는 결론을 내렸다. foundation model만으로 이해력을 달성할 수 있을지는 확실치 않지만, 반대의 주장을 확신할 수 있는 이유도 없다.

#### What is a foundation model?

foundation model에는 정확한 정의가 없으며, 이는 많은 모델들에 대한 비공식적인 라벨이다. 이 모델들은 새로운 연구에 따라 변화하고 성장할 것이다. 이는 이들의 기본 특성에 대한 이해를 어렵게 만든다. 그러나, 모든 foundation model들이 공유하는 중요한 특성은 self-supervision되는 것이다. 이 self-supervision이 모델의 주요 목표인 경우에 초점을 두고 있다.

self-supervision 모델의 목표는 학습 데이터의 기호 시퀀스에서 패턴을 학습하는 것이다. 이로 인해 모델은 그럴듯한 기호 문자열도 생성할 수 있다. 예를 들어, "The sandwich contains peanut"라는 문장을 입력하면 "butter and jelly"를 생성하거나, "The sandwich contains __ and jelly"라는 문장을 입력하면 "peanut butter"를 채워 넣는다. 이 모든 기능은 모델이 학습 데이터에서 패턴을 추출하는 능력에서 나온다.

self-supervision 모델은 기호의 의미에 대한 정보를 직접적으로 받지 않고, 어떤 단어들이 함께 나타나는지에 대한 패턴만 학습한다. 이것은 foundation model이 어떤 것도 이해하지 못할 것이라는 제한을 시사하는 것처럼 보일 수 있다. 하지만, 모델은 텍스트만이 아니라 다양한 기호에 대해 학습할 수 있다. 모델이 노출된 시퀀스의 패턴을 학습한다면, 그것은 foundation model로 간주된다. 이 학습의 일환으로, 모델은 텍스트와 센서 읽기, 픽셀 값의 시퀀스와 데이터베이스 항목 등 사이의 강한 연관성을 표현할 수 있다. 이 연관성은 사는 세계와 사용하는 언어에 대한 중요한 측면을 반영할 수 있다.

#### What is at stake?

이해의 정의를 분석하기 전에, 왜 foundation model이 이해를 달성하는지에 대한 문제에 관심을 가져야 하는지 고민해봐야 한다. 이 모델들은 다양한 기능으로 다양한 목적을 위해 사용될 예정이며, 그 중 일부 목표는 모델의 이해도에 따라 달성될 수 있다.

* **Trust:** 시스템이 사용하는 언어를 이해하지 못한다면 그 시스템의 언어적 행동을 신뢰하기 어렵다는 주장이 있다. 현재는 이해 없이도 시스템을 신뢰하고 있지만, 언어는 인간만이 가지는 특성과 속임수 가능성 때문에 다를 수 있다. 따라서 언어 사용에 대한 신뢰는 이해를 필요 조건으로 간주될 수 있다.
* **Interpretability:** 자연어 이해가 세계에 대한 내부 모델을 유지하고 업데이트하며, 이것이 언어 입력과 출력과 어떻게 연결되는지를 우리가 분석할 수 있다면, 이 시스템의 해석성, 예측성, 그리고 제어력을 크게 향상시킬 수 있을 것이다.
* **Accountability:** 미래에는 인공 에이전트가 생성하는 언어에 대해 책임을 지게 하는 것이 바람직할 수 있다. 이는 책임, 의무, 대리인 등의 개념을 어떻게 인식하느냐에 따라, 언어 이해가 필수 조건으로 부각될 수 있음을 의미한다.

이해가 이러한 문제들 중 어느 하나에서라도 필수적인 역할을 할 가능성만으로도, 이에 대한 이론을 구축하는 데 강력한 동기를 제공한다.

#### What is understanding?

핵심 질문은 foundation model이 자연어를 이해할 수 있는지, 그리고 self-supervision이 이해를 위해 충분한지에 대한 것이다. 이 질문에 답하려면 먼저 이해라는 용어를 명확히 정의해야 한다.

이해에 대한 형이상학과 인식론 사이의 차이를 명확히 하는 것은 중요하다. 형이상학은 에이전트가 이해를 달성하는 것이 원칙적으로 무엇을 의미하는지를 다루며, 인식론은 에이전트가 이해를 어떻게 달성했는지를 알아내는 방법에 관한 것이다. 따라서 인식론은 어느 정도 형이상학에 의존하게 된다.

**Metaphysics of understanding.** 언어 철학은 자연어 이해에 대한 여러 가지 해석을 제공하며, 이 중 세 가지 주요 견해는 AI와 자연어 처리(NLP) 연구와 밀접한 연관이 있다.

* **Internalism:** 언어 이해는 언어 입력에 대응하여 적절한 내부 표현 구조를 찾아내는 것을 의미한다. 따라서, 적절한 종류의 내부 개념 집합이 없다면 언어 이해는 불가능하다.
* **Referentialism:** 대략적으로 말하자면, 에이전트가 언어를 이해한다는 것은 그들이 그 언어의 다른 문장들이 어떤 상황에서 참이 될 것인지를 알 수 있는 위치에 있다는 것을 의미한다. 즉, 단어들은 참조 대상을 가지고 있고 발언은 진실성 평가 가능하며, 이해는 상황이나 시나리오의 제시에 따른 그들의 평가 능력을 포함한다.
* **Pragmatism:** 이해는 내부 표현이나 계산, 참조 등이 기본적이지 않다. 중요한 것은 에이전트가 언어를 올바르게 사용하는 경향이 있는지, 추론이나 대화 행동 등에 대한 적절한 반응을 보이는지이다. 이러한 언어 능력이 바로 이해를 구성한다.

가능성의 공간을 단순화한 이 그림을 통해, 언어 이해의 다양한 해석이 어떻게 다른 목표와 관련되는지 볼 수 있다. 예를 들어, 실용주의적 견해에서는 언어 이해는 시스템에 대한 신뢰나 해석 능력을 보장하지 않는다. 반대로 내재주의적 견해에서는 강한 내부/원인적 해석 가능성이 제안된다. foundation model이 원칙적으로 언어를 이해할 수 있느냐 없느냐는 문제는 어떤 형이상학적 해석을 채택하느냐에 따라 다르게 풀어진다.

내재주의와 참조주의는 언어 부호와 의미를 연결하는 매핑 문제를 정의한다. 내재주의에서는 이것이 표현, 개념 등의 내부 객체일 것이고, 참조주의에서는 단어에서 외부 참조 대상으로, 또는 상황에서 진실 값으로의 매핑이 될 것이다. 만약 모델이 언어적 입력만 받는다면, 이 매핑을 배우는 능력은 제한될 수 있다. 하지만 입력이 이미지, 오디오, 센서 등의 세계적인 데이터를 포함한다면, 이 데이터의 동시 발생 패턴을 통해 필요한 매핑을 배울 수 있을 것이다. 참조주의에서는 이 매핑이 실제 세계와 어떻게 관련되는지에 대한 추가적인 질문이 있지만, 이는 인간 언어 사용자에게도 적용되는 질문이다.

Bender와 Koller는 에이전트 O가 두 사람의 대화를 가로채서 인간처럼 행동할 수 있지만, 인간의 세계에 대한 근본적인 이해가 없기 때문에 실제로 언어를 이해하지 못한다는 주장을 한다. 이는 세계의 복잡성 때문에 텍스트만으로는 완전히 이해할 수 없으며, 이로 인해 발생하는 간극이 결국 이해의 부재를 드러낼 것이라는 가정에 기반을 두고 있다.

Bender와 Koller의 시나리오는 중요한 이해에 필요한 정보가 누락되어 있고, 이는 간단한 행동 테스트로 확인할 수 있다는 것을 보여준다. 하지만 이로 인해 foundation model이 전반적으로 이해하지 못한다는 결론을 내릴 필요는 없다. 학습 데이터의 세부 사항에 따라, 에이전트 O가 디지털 흔적과 언어 단위 사이의 연관성을 학습할 수 있다면, O가 이해를 달성하는 것에 원칙적인 제한은 없을 수 있다.

세 가지 입장에 따른 이해를 학습하는 것이 불가능하다는 명확한 이론적 근거는 없다는 것이 우리의 예비적인 결론이다. 이 가능성이 열려 있으므로, 이제 잠재적인 성공을 어떻게 평가할지를 명확히 하는 어려운 문제에 직면하게 된다.

**Epistemology of understanding.** 실용주의의 장점은 성공을 특정 행동과 동일시함으로써, 성공을 어떻게 테스트할지에 대한 큰 문제를 가지지 않는다는 것이다. 단지 시스템의 행동이 우리의 목표에 부합하는 일반적인 행동 경향을 보여주는지를 확인하면 된다. 하지만, 적절한 목표에 동의하는 것은 어렵고, 특정 제안이 제시될 때마다, 그것들은 항상 이의를 받게 된다.

튜링 테스트의 역사는 많은 인공 에이전트가 테스트를 통과했지만, 그 결과가 널리 인정받지 않았다는 점에서 교훈적이다. 같은 방식으로, NLP에서 제안된 여러 벤치마크 작업에 대해 시스템이 인간 수준을 초과하면 일반적으로 테스트의 결함을 지적하며, 목표 달성을 인정하지 않는다. 이는 내재주의나 참조주의를 테스트의 원래 목표로 설정하는 것이 어렵다는 것을 보여준다.

내재주의나 참조주의를 최종 목표로 설정한다면, 행동 테스트로 이해도를 평가하는 것은 항상 완벽하지 않을 것이다. 행동 테스트는 항상 간극이 있어 미숙한 모델이 빠져나갈 수 있으며, 시스템이 이해를 달성했지만 행동 테스트로 이를 입증할 수 없을 수 있다. 최근 GPT-3와의 경험은 이 도전이 얼마나 큰지 보여주며, 프롬프트 엔지니어링이 전문 지식을 요구한다는 것을 보여준다.

내재주의와 참조주의는 그들의 내부 표현을 연구하고, 정보를 추출하며, 내부 동력을 연구하고, 실험 프로토콜에 따라 원인 추론을 지원하는 조작을 가능하게 하는 구조적 평가 방법을 필요로 한다. 복잡한 foundation model의 내부 작동에 대해 알 수 있는 것은 한계가 있지만, 이러한 방법은 목표가 내재주의나 참조주의와 일치할 때 유용하게 사용될 수 있다.

#### Moving the discussion forward.

foundation model이 언어를 이해할 수 있을지에 대한 질문은 쉽게 해결할 수 없다. 이 문제를 해결하려면 여러 실질적인 견해가 있는 복잡한 형이상학적 질문을 먼저 해결해야 한다. 그러나 이런 토론을 통해 실질적인 결론을 도출할 수 있다: 인공 에이전트에서의 언어 이해를 위해 foundation model을 추구한다면, 모델에 필요한 정보를 제공하는 다중 모드 학습 체제가 가장 실행 가능한 전략일 것이다. 그러나 self-supervision이 충분한지는 아직 미정의 문제이다.

---

## APPLICATIONS

foundation model의 능력은 AI가 사회에서 차지하는 역할을 확장하며 다양한 분야를 개선할 수 있는 잠재력을 보여준다. 이 중에서도 건강관리, 법률, 교육과 같은 사회의 기본적인 기능을 이루는 분야에서의 기회와 도전, 그리고 문제점에 대해 논의할 것이다. 이에는 해석 가능성과 프라이버시와 같은 이슈가 포함된다.

### Healthcare and biomedicine





---

## Reference

* [Paper](https://arxiv.org/pdf/2108.07258.pdf)