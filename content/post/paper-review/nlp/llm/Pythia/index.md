+++
author = "Kurt"
title = "Pythia"
date = "2024-03-16"
description = "A Suite for Analyzing Large Language Models Across Training and Scaling"
categories = [
    "Paper Review"
]
tags = [
    "NLP",
    "LLM",
]
draft = true
+++

## Abstract

Pythia는 70M에서 12B parameter까지 다양한 크기의 16개 거대 언어 모델(LLM)을 포함한 도구 모음으로, 이 모델들은 모두 동일한 순서로 공개 데이터에 대해 학습되었다. 이 모델들의 학습 과정과 진화를 탐구하고자 하며, 각 모델에 대해 154개 체크포인트와 정확한 학습 데이터 로더를 공개적으로 제공한다. Pythia는 기억력, 단어 빈도의 few-shot 성능 영향, 성별 편향 감소 등 여러 연구 분야에서 새로운 발견을 가능하게 하기 위해 설계되었다. 이는 LLM의 학습 역학에 대한 새로운 통찰을 얻기 위한 엄격하게 통제된 설정을 제공한다.

---

## Introduction



---

## Reference

* [Paper](https://arxiv.org/pdf/2304.01373.pdf)
* [GitHub](https://github.com/EleutherAI/pythia)